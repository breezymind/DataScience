" 머신러닝의 딥러닝, 미래사회를 이끌다 산업 현장의 지각 변동을 이룰 미래 기술 미국의 IT 리서치 기업 가트너 그룹은 지난 2016년, ITxpo 2016에서 향후 5년간 혁신 잠재력을 지닌 10대 전략기술 트렌드를 발표했다. 가트너가 선정한 2017년 10대 전략 기술은 인텔리전트(Intellegent)와 디지털(Digital), 그리고 메시(Mesh)라는 3가지 영역으로 구분된다. 그중 인공지능과 고급 기계 학습, 즉 머신러닝은 10대 기술의 서두로서 로봇, 자율주행자동차, 가전 기기 등 물리적 디바이스를 비롯해 미래 IT 산업을 선도할 핵심기술로 평가 받고 있다.세상을 바꿀 최고의 전략 기술지난 2016년 ‘ITxpo 2016’에서 미국의 가트너 그룹이 발표한 ‘2017년 10대 전략기술 트렌드’는 향후 5년간 IT 산업 발전을 이끌 10가지 핵심 기술에 대해 이야기한다. 그중 인텔리전트(Intellegent), 즉 지능의 영역으로 분류되는 ‘인공지능과 고급 기계 학습(AI & Advanced Machine Learning)’은 기존의 알고리즘을 넘어 학습 예측, 적응을 비롯해 잠재적으로 스스로 가동하는 자율시스템을 만들어 지능형 스마트 기기를 만든다.인공지능의 한 분야인 머신러닝(Machine Learning)은 데이터의 생성량과 주기, 형식 등 방대한 빅데이터들을 분석해 미래를 예측하는 기술을 말한다. 이 기술은 기존의 빅데이터 분석과 유사점을 지녔지만, 데이터를 수집·분석해 미래를 예측한다는 점에서 차이점을 지녔다. 딥러닝, 신경망, 자연어처리, 첨단기법 등 기술의 결합으로 완성된 머신러닝 기술은 최근 각광받고 있는 물리적 디바이스(로봇, 자율주행자동차 등)을 비롯해 지능형 앱, 메시 디바이스 등 다양한 분야에 적용·융합될 혁신 기술로 평가받는다. 대표적 사례로 글로벌 소셜 네트워크 서비스를 제공하는 페이스북은 ‘Project PANDA’를 통한 딥페이스 기술을 연구한다. 또한, 세계 최대 비디오 스트리밍 기업 넷플릭스는 사용자의 구매 이력을 토대로 영화를 추천해 주는 서비스에 머신러닝을 적용했다. 이러한 기업들의 머신러닝 적용 배경에선 AI 기술의 정점으로 평가받는 딥러닝(Deep Learning)이 있었다. 머신러닝의 한 분야인 딥 러닝은 인공지능의 핵심 기술로서 인간의 두뇌 신경망 구조를 모방한 인공 신경망을 바탕으로 두각을 나타내고 있다. 그중 이미지 인식 분야에서 두드러지는 딥러닝 기술은 2014년부터 페이스북의 딥페이스 서비스에 적용되며 그 가능성을 인정받은 바 있다. 인공 신경망 기반 기계 학습 기술인 딥러닝은 컴퓨터가 스스로 학습한다는 점에서 머신러닝과 동일성을 지녔다. 하지만 데이터의 특징에 대한 정보를 사람이 직접 제공해야 하는 머신러닝과 달리 딥러닝은 특징을 스스로 파악해 분류한다는 점에서 차이점을 지녔다. 현대 지능 기술의 정점이 될 것으로 예견되는 두 기술은 다양한 산업현장에 적용 및 활용된다. 실현화 단계로 돌입한 딥러닝, 그리고 머신러닝의 미래딥러닝을 이용한 이미지 인식 기술의 인식률(97.35%)은 사람의 평균 인식률(97.5%)과 동일한 수준으로 발전했다. 또한, 다양한 서비스 추천 기능에도 적용되고 있는 딥러닝 기술은 인터넷 쇼핑몰 사이트의 상품 추천 서비스는 물론, 개인화된 음악 추천 서비스, 라디오 서비스 등에서도 엿볼 수 있다. 또한, 금융 분야에서 주목받는 딥러닝 기술은 미국의 온라인 결제 서비스 페이팔의 이상 금융거래 탐지시스템(FDS)에 적용되며 온라인 결제 패턴을 지능적으로 수집·분석해 기존 형태와 다른 패턴에서 범죄의 여부를 분류해 낸다. 금융 기업들에게 필요한 데이터 분석으로 주가와 기업 부도 예측이 가능하다는 점은 또 하나의 시사점이다. 머신러닝의 역사는 1950년부터 이어진다. 70년에 가까운 역사 속에서 정체되어 있던 기술은 2000년대 중반에 이르러서야 발전이 이루어지고 있다. 실제 머신러닝의 발전을 이끈 딥러닝의 인공신경망 기술은 IT 분야에서 새로운 것으로 보기는 힘들다. 전문가들은 ‘지난 20년간 인터넷 기술의 발전으로 축적된 방대한 정보와 이를 처리하기 위한 컴퓨터의 연산 능력 향상이라는 두 가지 요소가 만들어 낸 성과’라고 입을 모았다. 최근 딥러닝을 통한 머신러닝의 성공이 만들어낸 변화는 인류의 편의성을 혁신적으로 증대시킬 수 있다는 점에서 각광받고 있다. 또한, 구글, 페이스북 등 글로벌 IT 기업들은 딥러닝 기술 개발에 주력하며 끝없는 경쟁을 이어가고 있다. 구글은 학계에서 딥러닝 분야의 최고 석학으로 평가 받는 토론토 대학의 제프리 힌튼 교수를 영입해 자율주행차와 번역 서비스에 기술을 적용하고 있다. 검색 엔진 분야에서 세계 최고의 점유율을 지닌 만큼 구글이 지닌 방대한 데이터와 이미지들은 딥러닝 기술의 연구·개발을 위한 최고의 경쟁력으로 평가받고 있다. 한편, 페이스북은 힌튼 교수의 제자인 뉴욕주립대학교의 얀 레쿤 교수를 영입해 딥러닝을 광고에 반영하는 기술을 개발하고 있다. 이처럼 기업들의 경쟁을 바탕으로 성장 중인 딥러닝을 통해 추후 이미지 인식 분야를 토대로 커뮤니케이션이 가능한 로봇의 출현이 예고되고 있으며, 각종 언어에 대한 상황판단과 문화적 맥락의 수집을 통해 언어장벽을 무너뜨릴 통번역 서비스를 만들어 낼 것으로 예상되고 있다. 하지만 IT 강국으로 평가 받는 국내 사회에서는 머신러닝 기술과 딥러닝에 대한 관심이 부족한 점이 사실이다. 미래의 전략 트렌드로서 주목받는 머신 러닝과 이를 보조하는 딥러닝 기술이 만들어낼 새로운 사회에 국내 기업들과 관련 정부 부처의 관심이 필요한 시점이다.​ 이슈메이커 이민성 기자 jadelee@issuemaker.kr "
" 안녕하세요 ICT멘토링 서포터즈 7기 손영주입니다제가 알려드리는 2번째 ICT트렌드는 바로 '딥러닝'입니다'딥러닝'이 무엇이냐고요? '딥러닝'(Deep Learning) 쉽게 말씀드리자면 학습을 통한 생각하는 컴퓨터가까운 예시는 이세돌 9단과 바둑을 두었던 알파고인데요.역사적인 사건 혹은 대결이었던 이 대전은 ICT에 관심이 없었던 많은 사람들에게도 인공지능(AI)에 대한 관심을 불러일으켰습니다.많은 사람들과 이세돌은 경기 전, 낙승을 예상했지만 경기가 지날수록 이길 수 없는 상대와의 대전인 것처럼 되었습니다. 구글의 알파고는 딥러닝 기술에 기반한 프로그램인데요딥러닝에 대해 알아보겠습니다딥러닝이란 많은 데이터를 컴퓨터에 입력하고 비슷한 것끼리 분류하도록하는 기술입니다. 우리는 자각할 수 없지만 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정보처리 방식을 모방한 것입니다. 데이터를 기반으로 기계가 스스로 인지·추론·판단할 수 있게 됩니다. 위 2개의 사진은 생활 속의 딥러닝입니다.딥러닝이라면 '나'와는 아주 먼 이야기 같겠지만,얼굴 인식 기술을 페이스북 및 음성 인식 기술을 탑재한 아이폰 등일상 속에서 딥러닝을 마주하고 있습니다.현재 딥러닝은 사진 분류뿐만 아니라 문학, 그림, 게임 등다양한 산업에서 결합하고 있습니다. 이러한 딥러닝에도 한계가 있기 마련인데요!우선 '정확성'의 문제입니다.무적으로 보였던 알파고가 4번째 대국에서 패배, 페이스북이나 구글포토도 가끔 엉뚱한 사람을 태그하거나 엉뚱한 사물로 분류하기도 합니다.무조건 데이터가 많다고 해결되는 문제는 아닙니다.기계의 학습이 완벽해지는 시점이 있으며 이를 넘으면 오히려 정확성이 떨어집니다.다음은 '악용의 가능성'인데요. 예를 들면 영화 <아이로봇>처럼 틀린 정보를 기계에 학습시켜 옳지 않은 정보를 기계가 옳다고 생각하게 만든다면 영화처럼 비극이 일어나지 말라는 법은 없습니다.기하급수적인 데이터와 알고리즘의 발전으로 이러한 한계를넘어서다 보면 딥러닝이 적용될 수 있는 분야는 무궁무진하다 생각합니다 ICT 트렌드 '딥러닝'에 대해 알아보았는데요,딥러닝의 한계를 넘어서 인류에 좋은 방향으로 사용되길 바라는 4조 AdvanCT의 손영주였습니다 "
" * 여기서 운영체제 OS란, 컴퓨터의 하드웨어와 소프트웨어를 제어하여사용자가 컴퓨터를 쓸 수 있게 만들어주는 프로그램.쉽게 말하면, 컴퓨터의 실행 관리자 라고 할 수 있습니다.​ * 이처럼 '딥러닝'은 컴퓨터가 마치 사람처럼 생각하고 배울수 있도록 하는 기술입니다.이 기술은 MIT에서 2014년 10대 혁신 기술 중 하나로 선정되기도 했고,현재 전세계에서 차세대 기술로 주목받고 있는 기술입니다.페이스북, 마이크로소프트, 네이버, 구글 등에서 활발하게 쓰이며 실생활 속으로 빠르게 다가오고 있는 기술이죠. ​ * '딥러닝'은 머신러닝의 한 분야 입니다. * 예로, 미리 저장된 개 사진과 비슷한 사진이 입력되면,'이 사진은 개'라고 컴퓨터가 분류하게 됩니다.입력과 출력 간 함수관계를 알고 있다면, 입력에 해당하는 출력을 결정할 수 있는데요.다양한 분야의 많은 기능은 입출력 간 함수관계로 정의할 수 있습니다.이처럼, 예로 얼굴인식이라면얼굴 영상 입력으로 그 인물이 누구인지를 출력하는 것이고,예로 주가예측이라면지난 정보의 입력으로 미래에 대한 예측치를 출력하는 거죠.​ * '딥러닝'이 화두가 된 이유는 크게 2가지로 볼 수 있습니다.1. 좋아진 컴퓨터 환경2. 바로 빅데이터 시대 도래​딥러닝이 가장 보편적으로 활용되고 있는 분야를 꼽는다면음성인식과 이미지인식 입니다.​데이터 양 자체가 풍부한 데다가 높은 확률적 정확성을 요구하고 있기 때문입니다.​ ​* 비지도 학습은 배움의 과정 없이, 컴퓨터가 스스로 학습하게 되는데.당연히 지도학습과 비교해 진보한 기술이며, 컴퓨터의 높은 연산능력을 요구합니다.​​현재 구글이 비지도 학습으로 유튜브에 등록된 동영상 중 고양이를 식별하는 딥러닝 기술을 개발완료한 상태입니다.​​ * 해당 기술 알고리즘은 다음과 같습니다.구글은 이후구글 나우의 음성인식, 유튜브 추천, 이미지 물체에 대한 자동 태깅 등다양한 영역에서 딥러닝 기술을 이용하고 있습니다.​ * SK플래닛의 Face ID Concept 은 Face Recognition을 통해 고객을 파악하고 각 고객별로 reward point를 적립하거나 쿠폰을 발행해 줍니다.이 과정은 모두 머신이 알아서 한다는 점.즉, 머신(Machine)이 고객의 얼굴을 배워(Learning)나가기 때문에 가능한 일입니다.(출처 : http://www.whydsp.org/237 )기계학습 / 머신러닝 기초 ( Machine Learning Basics )김승일 모두의연구소 연구소장 모두의연구소 딥러닝연구실 DeepLAB 랩짱 모두의연구소 페이지와 모두의연구소 커뮤니티에 오시면 더 많은 정보...www.whydsp.org​ * 1. 데이터수집 ​ * 2. 특징 추출​ * 해당 특징들을 기존에 저장되어 있던 데이터와 비교하여 가장 유사도가 높은 ID를 찾아냅니다.​ * 이렇게 데이터를 실제 Test전에 저장하는 것을 traning이라고 합니다.즉, Traning된 Classfier에 특징을 입력하면어떤 ID에 해당하는지 알려주는거죠.이를 종합해보면,​'머신러닝'은 미리 준비된 데이터를 이용하여 Classfier를 Traning(Learning)시키는 트레이닝단계,트레이닝 된 classifier를 이용하여 입력된 데이터가 어떤 분류 결과인지 확인하는 테스트단계로 나뉘게 됩니다.​ * 쉽게, 우리가 페이스북에 사진을 올리 때면,사진 속 얼굴들을 알아서 다 잡아낸 뒤​ * 심지어 얼굴에 알맞는 친구를 추천해주는 기능.​ * 이 기능들을 어떻게 쓸 수 있느냐?페이스북 딥러닝 기술을 적용해 '딥페이스'라는 얼굴인식 알고리즘을 2014년 3월에 개발 했기 때문입니다.페이스북은 이 딥페이스 알고리즘으로 전세계 이용자의 얼굴을 인식하고 있죠.그렇다면, 알고리즘은 어떤것인가?1. 주요 얼굴 부분에 67개의 점을 찍어 얼굴의 윤곽을 나타낸다.2. 나눠진 조각들을 컴퓨터 작업을 거쳐 3차원으로 변환시킨 후, 얼굴 특징의 중요도에 따라 밝기를 조절하여 사진으로 나타낸다.딥페이스의 인지 정확도는 97.25%로 인간 눈과 거의 차이가 없다고 해요.( 인간의 눈은 97.53%의 정확도)​ * 페이스북은 이용자가 올린 이미지의 얼굴의 옆면만 봐도,어떤 이용자인지 판별 가능합니다.​ * 작년 미국 정부는아동 성범죄자 검거에 페이스북에게 도움을 요청하여 범인 검거를 성공했는데요.수백만장의 사람 얼굴 사진 데이터를 가지고 있는 페이스북은,아동 성인물 영상에 나오는 남자의 얼굴을 파악.이를 검거에 활용했습니다.​ * 마네킹 눈에 내장된 카메라는 얼굴인식 기술을 이용해 소비자의 연령과 성별, 인종 등일 인식합니다.고객이 광고 혹은 물품을 보는 동안 얼굴 정보를 인식해성별과 나이를 분석하고,고객이 관심 가질만한 광고를 골라 내보내는거죠.회사에선 고객이 시선을 집중한 시간을 분석해, 광고 효과를 측정할 자료로 이용합니다.​ * 세계 최대 전자상거래 기업인 중국 알리바바.얼굴인식으로 모바일 결제를 하는 '스마일 투 페이'를 도입할 예정이라고 합니다.사용자가 구매버튼을 누르면, 스마트폰 카메라가 사용자의 얼굴을 감지.미리 등록해둔 얼굴과 동일한 인물임을 확인하면 바로 결제가 완료되는 기술입니다.이처럼 딥러닝은 서서히 영역을 확장하여, 우리 실생활에 스며들고 있습니다.​* 딥러닝은 어쩌면 더 많은 학문들과 결합하고 융합될 것으로 전망되요.유엔 미래 보고서 2045 책의 저자는 이 시기에는 인공지능이 인간의 지능을 능가하는 시기라고 예언했는데요.딥러능, 즉 머신러닝은 인공지능의 발판입니다.인간의 옆에서 인간처럼 보고 인식하며, 인간의 기억을 돕는 기계인 인공지능은 머지않아 완성 될 것입니다.** 명지대학교 전자공학과 프로그래밍학회 왓쳐 세미나 발표 자료 **2015.04.17 일 자료입니다. "
" 최근 알파고 기사가 계속 나오길래 잠깐 기사를 보다가... 알파고가 일부 소스코드를 공개했다고 합니다. 진짜 공개했는지는 모르겠고 replication 버전만 공개되어있습니다. Rochester-NRT/AlphaGoAlphaGo - A replication of DeepMind's 2016 Nature publication, ""Mastering the game of Go with deep neural networks and tree searc...github.com메인으로 들어가면 다음과 같은 화면이 나옵니다.지금시간 기준으로 21시간전에 소스코드를 업데이트 하였네요... 파이썬으로 구성되어 있네요. 대세는 오픈소스! 저 링크를 따라가보면 또 다른 오픈소스가 나옵니다. http://pachi.or.cz/ 바둑 알고리즘 오픈 소스입니다. 메인에 있는 소스코드들 중에 중요한 내용이 있나 확인해 봤는데 특별히 없네요. training 폴더안의 소스코드는 빈통이고요. models 폴더의 메인 스켈레톤도 빈통이예요 ㅜㅜ 몇몇개는 오픈소스에서 따온거 같고...하지만 몇몇 의미있는 코드들도 있습니다. deep_polcy.py 부분인데요...소스 코드를 살펴보니 딥러닝을 위해 Keras 라이브러리를 사용하고 모델 두개 중 Sequential 모델을 사용하였네요.딥러닝에 크게 관심이 없었는데 라이브러리를 보니까 멋져요 !이렇게 쉽게 딥러닝을 할 수 있는 라이브러리가 있다니!!! Keras Documentationkeras.io ..... 그외에 공개 내용중엔 특별한게 없는거 같네요.알파고 테스트 소스에 바둑판 배열은 있네요... 남은 3판은 누가 이길까요? 개인적으로는 알파고의 패턴을 잡아내서 이세돌씨가 이겼으면 하는 생각입니다. "
" 알파고(AlphaGo)의 등장으로 세계가 시끌벅적하다.오늘 있을 이세돌 vs AlphaGO 4국대결에서 이세돌 9단이 이기기를 바라면서 알파고에 대해 알아보자.!!AlphaGo?알파고는 구글에서 인수한 딥마인드에서 개발한 컴퓨터 바둑 인공지는 프로그램이다. 그와 동시에 프로기사를 맞바둑으로 최초로 이긴 프로그램이기도 하다.사내테스트 결과다른 바둑 인공지능 프로그램들을 상대로 495전 494승 1패를 기록, 1패는 알파고의 실수였으며 그 약점도 보완을 통해 최고의 인공지능 프로그램이라고 부르고 싶다.하드웨어 사양현재 이세돌 9단과의 대결에서는 과거(CPU 1202개, GPU 176개)보다 더 업그레이드 된 CPU 1920개, GPU 280개를 사용하고 있다고 한다.딥러닝 ?알파고 이전에 최강의 프로그램 인 크레이지스톤, 젠이 있었지만 알파고의 등장으로 이 2개의 프로그램의 필요성이 심각하게 거론되고 있다.이런 알파고를 더욱 강력하게 하는 기술이 바로 딥러닝이다.딥러닝이란 간단하게 설명하면 컴퓨터가 인공지능을 이용해 스스로 학습하는 기술이다. AlphaGo의 동작과정1. 알파고가 딥러닝을 통해 바둑을 배운다.2. 이런 학습을 통해 알파고는 수많은 알고리즘을 경우의 수를 가자치기를 한다.3. 상대방 둘 수 있는 경우의 수 중 승률 높은 경우의 수를 계산하고, 알파고가 두었을때 상대방의 승률이 어떻게 변할지를 계산하여 자신한테는 좋고, 상대방한테는 불리한 경우의 수만 추린다.결론체스는 IBM의 딥 블루가 가리카스파 로프를 이긴 경우가 있다.하지만 바둑은 체스에 비해 경우의 수가 많아서 지금까지 인공지능이 프로 바둑 기사를 못이겼는데 알파고가 이 기존의 틀을 부시고 프로바둑기사를 이긴 최초 바둑 인공지능일 것이다.비록 이세돌 9단이 3국까지는 졌지만 오늘은 이 인공지능 알파고를 꼭 이겨서 역사에 이름을 남겼으면 좋겠다. 아자!!아자!! 화이팅!! "
" ﻿﻿​​""딥러닝! 이정도는 되야지!"" ​딥러닝 / 머신러닝 워크스테이션 커스텀수냉 필수!! ​글쓴이 : PC크레이터 곰탱이 ​​​​​​​​​​요즘 딥러닝이나 머신러닝에 대한 수요가 높아지고 있습니다. 딥러닝이나 머신러닝을 위한 ​강력한 워크스테이션을 만들기 위해서 ​대부분의 작업자들은 지포스 GTX TITAN X 4개를 ​4-WAY SLI 하여 시스템을 구축하고 있는데요, ​​​이때, 문제는 그래픽카드의 간격이 거의 없어 공기가 통하지 못하여 높은 발열이 발생. 이로​ 인하여 성능감소가 발생하는 것입니다. 이에 고사양의 오버클럭 게이밍PC에 주로 적용되었던​ 커스텀수냉을 적용하여 딥러닝 / 머신러닝 워크스테이션을 구축하는 경우가 많습니다. ​​​​​​​​​​​​​​​​​CASE CORSAIR OBSIDIAN 900D ​​​​E-ATX 규격의 메인보드와 2개 이상의 라디에이터, 그리고 커스텀수냉이 4개의 그래픽카드​에 적용되기 위해서는 왠만한 크기의 케이스로는 이를 감당할 수가 없습니다. ​이에 케이스의 ​높이가 무려 692mm에 이르는 빅타워 케이스 커세어 옵시디언 900D을 딥러닝 워크스테이션​의 케이스로 선정하였습니다. ​​​​​​​​​​​​​​​VGA 엔비디아 지포스 GTX TITAN X 4WAY SLI ​​​​제 아무리 지포스 GTX1080의 성능이 좋다 한들, 딥러닝이나 머신러닝의 경우 쿠다코어의 ​갯수와 메모리의 용량이 중요(GTX1080 2560개 / 타이탄X 3072개)하므로, 최신 출시된 ​파스칼 기반의 지포스 타이탄을 선택하거나 맥스웰 기반의 지포스 GTX 타이탄 X를 선택하여​ 딥러닝 워크스테이션을 만드는것이 정답입니다. 일부 프로그램의 경우 그래픽카드 당 11GB​ 이상의 메모리를 요구하여 작업 자체가 안되는 결과를 초래할 수 도 있기에 12GB의 대용량 ​메모리가 적용된 타이탄X 선택하여 딥러닝 / 머신러닝 워크스테이션을 만드는것이 맞습니다. ​​​​​​​​​​​​​​ ​마더보드 ASUS X99-E WS ​​​딥러닝 / 머신러닝 워크스테이션은 ​CPU 기반의 시스템이 아닌 그래픽카드의 쿠다를 활용한 ​시스템 이기에 다수의 PCI Ex3.0 x16 슬롯을 지원하는 마더보드를 선택해야 하며, 영재컴퓨터​에서 선택한 마더보드는 ASUS에서 워크스테이션을 위하여 제작한 X99-E WS 입니다. 세계​최고의 마더보드 제조사에서 만든 마더보드 답게 매우 견고하며, ​확장성이 뛰어난 마더보드로​서 4-WAY SLI 구성에 매우 적합한 마더보드입니다. ​​​​​​​​​​​​​​ ​​CPU 인텔 코어 i7-6850K 브로드웰 E ​​​​컴퓨터를 조금 아시는 분들이라면 더 저렴한 i7-6800K와 스펙상 차이가 거의 없고, 오버클럭​을​ 적용하면 그나마 아주 조금 차이나는 코어클럭까지 의미가 없어지는 i7-6850K를 선택한 ​이유가 궁금하실 겁니다. 그 이유는 바로 그래픽카드를 인식할 수 있는 능력의 차이 때문입니다. ​인텔 코어 i7-6850K 브로드웰 E 부터 4개의 그래픽카드를 인식할 수 있기 때문이지요. ​​​​​​​​​​​​​​​​RAM 삼성전자 DDR4 16GB 17000 ​X4 64GB ​​​​CPU 기반의 워크스테이션의 경우 CPU의 코어갯수 만큼 메모리의 용량이 중요하여 256GB​ 풀뱅크를 사용하여 워크스테이션을 제작하는 경우가 많으나, GPU 쿠다코어 기반의 딥러닝 ​워크스테이션인 만큼, 16GB를 포채널 구성 64GB면 충분합니다. ​​​​​​​​​​​​​​​​SSD 마이크론 CRUCIAL MX300 750GB ​​​​딥러닝 / 머신러닝을 할 것 없이 스토리지 구성은 자유 입니다. 포스팅중인 워크스테이션은 ​750GB의 SSD를 적용하여 제작하였지만, 이보다 더 많이 필요한 경우도 있으며, 현재 2TB ​용량의 SSD도 존재하니 필요에 따라 스토리지 용량을 선택하시면 될 것 입니다. ​​​​​​​​​​​​​​​PSU ​CORSAIR PROFESSIONAL SERIES AX1500i 80PLUS TITANIUM ​​​​TDP 250W를 요구하는 지포스 GTX 타이탄 X를 4-WAY SLI 구성하기 위해서는 1500W​정도는 사용해야 겠지요? 안정성, 가성비 모든걸 따졌을때 CORSAIR의 파워가 딱! 입니다. ​​​​​​​​​​​​​​​​커스텀수냉 영재컴퓨터 커스텀빌드 ​​​​업계 최고수준을 자랑하는 영재컴퓨터의 커스텀수냉 기술을 딥러닝 / 머신러닝 워크스테이션​에 적용하여 발열을 최대한 억제할 것 입니다. 실제 90도에 육박하던 GPU온도가 45도까지 ​내려갔습니다. ​엄청난 쿨링 성능이지요! ​​​​​​​​​​​​​​​커스텀수냉 적용 딥러닝 워크스테이션 조립과정. ​​​​​​​​​​​​CPU 장착! ​​​​​​​​​​​​​메모리 장착 ​​​​​​​​​​​​​ CPU워터블록 장착 ​​​​​​​​​​​​​딥러닝 워크스테이션의 메인보드세트 완성. ​​​​​​​​​​​​​파워 장착. ​​​​​​​​​​​​​SSD 장착. ​​​​​​​​​중간에 커스텀수냉을 하느라 사진을... ​​​​​​​​​​​​​​​​​​​파워 온! ​​​​​​​​​​​​​타이탄 X 4-WAY SLI 구성!!! ​발열 걱정 이상무! ​누가 파스칼 기반 타이탄 좀 의뢰해 주세요~​​​​​​​​​​​​​​​​​​​​​​​​​​​보기만해도 시원하지 않나요? ​​​​​​​​​​​​​​​영재컴퓨터가 만든 타이탄 4-WAY SLI 딥러닝 워크스테이션 입니다. ​​​​​​​​​​​​​​ ​​​엄청난 시스템입니다! ​​​​​​​​​​​​​타이탄 X를 비롯한 모든 그래픽카드를 2-WAY 이상으로 SLI 구성시 가장 염려되는 ​부분은 역시 발열 입니다. 그래픽카드의 쿨러가 너무 두꺼워 공기순환이 잘 되지 않아 ​그래픽카드의 GPU 온도가 90도 이상으로 올라가 다운되는 증상들이 자주 발생하지요. ​이럴때 가장 좋은 솔루션은 역시 커스텀수냉 입니다. ​​​​​​​​​​​​​​​​​​​​​​​​딥러닝 / 머신러닝.​​​​​​​​​​​​​​​이상 커스텀수냉을 적용한 딥러닝 워크스테이션의 포스팅을 마치겠습니다. ​궁금하신점은 아래 연락처로 문의해 주시길 부탁드립니다! ​​​​​​​​​​​ "
" ﻿ ​ ​ ♤♠♤ 딥러닝 전망과 응용사례는? ​ ​딥러닝(Deep Learning) 이란? ​ 사람의 두뇌에서 뉴런은 신경망의 여러 층을 거쳐 정보를 처리하는데 마치 이런 사람의 신경망 처럼 인공신경망의 깊은 층을 컴퓨터가 학습해 사람과 같이 생각하고 배울 수 있도록 하는 인공지능 기술 입니다. 즉 큰 틀에서 보면 사람의 사고방식을 컴퓨터에게 가르치는 기계 학습의 한 분야라고 이야기 할 수 있습니다. ​ ​ 문제는 최적의 딥러닝 알고리즘을 만들기 위해서는 수많은 뉴런이 가진 복잡성, 임의성을 충족시켜야 하는데요. ​어떠한 데이터가 있을 때 이것을 컴퓨터가 알아들을 수 있는 형태(예를 들면 이미지의 경우는 픽셀 정보를 열벡터로 표현하는 등)으로 표현 하고 이것을 학습에 적용하기 위해 많은 연구(어떻게 이것들을 학습할 모델을 만들지) 등이 진행되고 있으며 이러한 노력의 결과로 다양한 딥러닝 기법들이 컴퓨터 버전 음식인식, 자연어처리, 음성/신호처리 등의 분야에 적용되어 최첨단의 결과들을 보여주고 있습니다. ​ 최근 서울대 수리과학부와 손을 잡고 딥러닝 연구에 나선 스탠리 오셔(미국 캘리포니아 주립대 교수)에 따르면 ""딥러닝의 발전은 의료산업, 교통, 자율주행자동차, 음성인식, 번역, 예측분석 등 모든 측면에서 사회를 변화시킬 것"" 이라는 전망을 내놓았다고 합니다.​ ​ ​ ​ 딥러닝 응용사례는? ​ ​ 자동 음성 인식 ​ 2010년부터 2014년 까지, 신호처리와 음성인식에 대한 주요 학술 회의인 IEEE- ICASSP 와 Interspeech는 음성인식을 위한 딥 러닝 분야의 합격 논문 개수에 있어서​ 거의 기하급수적인 성장을 보였습니다. ​ 현재 모든 주요 상업 음성인식 시스템 (MS코타나, 스카이프 번역기, 구글 나우, 애플 시리 등등)이 딥러닝 기법에 기반하고 있습니다.​ ​ ​ 영상인식 ​ ​ 일반적으로 이미지 분류를 위한 평가 데이터로서 MNIST 데이터베이스 데이터가 이용 됩니다. MNIST는 손으로 쓴 숫자들로 구성되어 있으며, 60000개의 학습 예제들과 ​10000 개의 테스트 예제들을 포함 합니다. 자동 음석 인식 분야의 자동 음성 번역 및 이해 분야로의 확장과 마찬가지로, 이미지 분류 분야는 자동 영상 캡셔닝(captioning) 이라는 더욱 도전적인 분야로 확장 되었습니다. 적용 사례로는 360° 카메라 화면을 이해할 수 있도록 딥러닝을 통해 학습된 자동차 탑재용 컴퓨터 등이 있습니다.​ ​ ​ "
" 딥러닝(Deep Lerning)2017년에 다양한 IT 트렌드가 있겠지만, 그 중 가장 화두가 되고 있는 것은딥러닝(Deep Learning)이다. 2016년 AI이슈가 되었다면, 2017년에는 딥러닝이라고 할 수 있겠다.알파고의 등장으로 AI의 이슈가 되었고, 대대적인 기술력과 투자가 이루어지기 시작했다.알파고에 사용된 딥러닝은 스스로 규칙을 형성하는 기계학습을 하는 대표적인 예로서,마치 사람이 데이터를 분석하고 결과를 추출해 내는 방식이다.알파고 외에, 딥러닝을 사용한 예를 들어보자면,페이스북에서 개발한 deepface와 네이버에서 개발한 '파파고'가 있다.페이스북은 사람의 얼굴을 인식해서 ""OO씨가 맞습니까?""라고 믈어보며, 이전보다 쉽게 태그할 수 있도록deepface라는 인공지능 모델을 개발했고네이버에서 출시한 ""파파고""는 딥러닝 차용한 ""문맥을 이해하는 인공지능 번역기""이다.현재까지는 '이미지 인식'이나 언어의 인식'을 처리하고 있을 뿐이지만그 활용 사례가 점차 확대되고 있고, 기술력 또한 진화하고 있으므로, 일상 생활에서 인공지능이 활용되는 모습을하루 빨리 볼 수 있었으면 한다. "
" 딥러닝 첫걸음머신러닝에서 컨벌루션 신경망까지(도서 상세 정보는 한빛미디어에서 확인 가능) 먼저 지은이 김성필님은 과거 ""칼만필터의 이해""라는 서적으로 이미 알고 있었다. 그래서인가 역시나 MATLAB을 기본 환경으로 했다는... 서문 및 들어가며 부분에 책의 구성에 대해서 잘 설명해 두었으며, 이 서적을 보는 목적에 맞게 접근할 수 있는 방향을 제시해 두었다. 이렇게 함으로써 독자에게 책에 대한 접근 방법을 충분히 제시하여서 책을 읽는 방법을 제공해 주는 듯 하다. 책은 초보자에게 설명을 하려고 하였지만, 쉽지만은 않은 분야라는 부분 때문에 후반으로 갈수록 어렵다고 생각할 수 있을 듯 하다. 특히 프로그래밍이 들어가는 부분 때문에 소스 코드를 이해해야 한다는 부담이 있다. 물론 이론적인 내용만을 보려고 한다면 충분히 쉽게 볼 수 있는 책으로 판단된다.책의 내용 요약 도입부에 용어 정의에 대해서 설명하려고 했지만, 딥러닝, 머신러닝, 인공지능 간에 상호 관계에 대해서는 설명이 되었지만, 각 용어에 대해서는 명확하게 정의를 내리지 못 하는 듯 하다. 책을 다 읽었지만, 두리뭉실하게 무엇인지는 이해는 되었지만 설명하기 어렵다. 물론 나의 자질 문제일 수 있지만 어렵다. 딥러닝은 다중 신경망을 이용한 머신러닝 기법이라는 소개를 통해 신경망을 소개하며 자연스럽게 딥러닝의 예제 소스 코드를 집고 넘어간 듯 하다. 신경망의 학습(델타 규칙)을 소개하며, 이 지도학습에서의 가중치 갱신법으로 SGD(경사하강법), 배치, 미니 배치 방법을 소개하고, 예제 소스 코드를 소개하면서 2 방식의 비교를 통해서 지도학습의 횟수에 따른 오차 변화 및 학습 속도를 비교하였다. 하지만, 이 방식들의 차이에 따른 실제 적용에 있어서의 선택을 어떻게 해야 하는지에 대한 방향 제시가 없는 듯 하다. 본격적으로 신경망에 대해서 진행을 하며, 단층 신경망의 문제점 및 이로 인해서 나오게 된 다층(얕은/심층) 신경망을 이야기하며, 마지막 단계에서는 심층 신경망을 통해서 이 책에서 이야기하려고 한 딥러닝에 대해서 진행한다. 자연스러운 전개를 통해서 딥러닝에 대해서 설명하였지만, 다른 사람에게 간단 명료하게 설명을 할 수 없을 것 같다. 마지막으로 딥러닝의 사례로 컨벌루션 신경망을 소개하는데, 실제 현장에서 사용하고 있는 기법을 소개함으로써 좀 더 실생활에 접근을 유도한 듯 하다. 컨벌루션 신경망은 영상 인식에 특화된 것으로 영상에서 특징 추출, 범주 분류를 통해서 영상 인식에 사용되는 사례 및 예제를 소개하였다.아쉬운 부분1. 소스 코드에 주석 추가2. 책 표지에 MATLAB 사용에 대한 언급(영문판에는 표기되어 있음)3. 매트랩을 대체할 수 있는 방안 제시 : GNU Octave, Python 등 - Python 예제를 제공하고 있기 때문에4. 의문점 및 문의 사항에 대한 소통 공간이 있었으면 한다. - GitHub 활용의문점1. 학습 결과를 저장해 두면, 다음 번에는 처음부터 다시 학습을 하지 않아도 되는지? - 결과(가중치) 값을 저장해 두면, 다음 수행에서는 바로 수행 가능한지?2. 학습을 통한 각 상황에 따른 알고리즘(위의 학습 결과물)이 확립이 되었다면, 이후에 상황에 접목하려고 할 경우, 알고리즘만 불러서 수행하면 되는지? "
" 안녕하세요. 더 높은 이상을 위해서 고심하는 수험생 분들을 위해 부천 독재 부천 이투스 24/7을 소개하려고 합니다. 이미 입증된 실력으로 수험생들 사이에서 소문이 자자한 부천 이투스 24/7 에 대해 알아 볼까요? ​부천 ETOOS 프리정규반과 재수정규반에서 상위권을 노리자진학실적 1위인 부천 독재 부천 이투스 24/7 에서는 재수를 결심한 수험생들을 위해 프리정규반과 재수정규반을 준비해 놓았는데요. 학원마다 수강생들의 대입결과를 홍보하며 수강생들 모두 같은 학습방식으로 성적향상이 될 것이라고 얘기하지만 개인의 학습성향은 각각 다르기 때문에, 24/7은 수강생들의 수준을 상향화하여 훌륭한 면학 분위기를 조성할 것입니다.개별 맞춤 커리큘럼을 통해 상위권 안정진입부천 독재 이투스 24/7 프리정규반과 재수정규반에서는 개별 맞춤 커리큘럼을 제공합니다. 먼저 담임선생님과 1:1 상담 후 정기적인 개별 맞춤 스케줄링이 진행되고요. 이후 개인 별 스케줄에 맞추어 매주 학습 진행을 하고, 이를 기반으로 한 1:1 코칭 및 상담이 이루어지기 때문에 무리하지 않게 주도적인 학습을 몸에 익힐 수 있다고 하네요.이투스 24/7의 핵심 학습법, 딥러닝(Deep Learning)같이 인터넷 강의를 들어도 다른 결과가 나오는 이유, 자기주도학습 체계에 부족한 부분이 제대로 관리되지 않기 때문인데요. 부천 독재 이투스 24/7 의 딥러닝 학습 프로그램에서는 ‘온라인 수업’ 에서는 자신에게 꼭 필요한 강의를 선별해서 수강하고 반복하여 들을 수 있으며, ‘오프라인 관리’ 를 통해서는 1:1 학습 상담과 코칭을 진행하고, 정기적인 1:1 학습점검과 학생부 컨설팅을 받을 수 있답니다. 이렇게 ‘온라인 수업’ 과 ‘오프라인 관리’의 복합적인 체계를 통해 철저히 부족한 부분을 메꿔나갈 수 있는데요. 특히 학습매니저가 온라인 강의를 듣다 이해하지 못한 내용에 대해 일대일로 강의 이해를 도와주고, 완전히 이해할 때까지 이 과정이 반복되어, 취약단원 분석에 따른 학습 스케쥴링도 재구성됩니다. 이투스24/7 프리정규반과 재수정규반에서 특별한 시설을 만나보세요.부천 독재 이투스24/7학원에는 남녀가 구분된 독립적인 자습공간이 마련되어 있고, 안락하고 따뜻한 분위기의 조명과 소음방지를 위한 바닥 쿠션이 있답니다. 개인사물함도 마련되어 있어 자습할 때 불편함이 없습니다. 또한 투명한 통유리의 코칭룸에서 언제나 전문 매니저에게 학습에 관해 상담 받을 수 있어요! 학원 내에는 카운셀링 룸도 있어서 이투스 교육평가연구소의 체계적인 입시전략과 정기적인 입시컨설팅으로 개별 상담이 가능합니다. 그리고 장시간 학습에 지친 학생들이 휴식할 수 있도록 리프레쉬 스페이스가 준비되어 있어요. 이뿐 아니라 오픈 스터디 룸과 북카페도 학원 내부에 있어서 개인학습 공간에서 떨어진 집중력을 다른 공간에서 끌어올릴 수 있어서 참 좋아요!​수험생들 사이에서 상위권 진입의 디딤돌로 유명한 부천 독재 이투스 24/7 은 단연 입소문에서 그치지 않습니다. 지난 12월 9일 설명회에서 사례로 보여드린 게 있어요. 이투스 24/7 수강생이었던 명O여고 차O지 양의 경우 2016 수능 대비 2017 수능 점수에서 표준점수 총점이 78점이 상승했으며, 중O고 김O주 양의 경우 2016 수능 대비 2017 수능 점수에서 표준점수 총점이 86점 상승한 것인데요. 이투스 24/7 만의 특별한 딥러닝 프로그램을 통한 관리의 효과라고 볼 수 있습니다.이투스24/7학원은 꼼꼼한 커리큘럼과 더불어 훌륭한 학습시설이 마련되어 있기 때문에 학생들 사이에서도 인기가 좋은데요. 대학 지원 후 입시결과를 기다리지만 재수를 생각하고 계신 분들은 부천재수학원 이투스 24/7 학원에서 1월부터 선착순으로 등록을 받고 있는 프리정규반과 2월 중 개강 예정인 재수정규반을 상담 받아보세요!​ 해당 포스팅은 부천이투스24/7로부터 소정의 원고료를 받아 작성되었습니다 "
" [영화 <그녀>의 포스터 (출처 : 네이버 영화)]지난해 5월 개봉한 영화 <그녀(Her)>를 기억하시나요? 영화는 현시점에서 멀지 않은 미래사회를 배경으로, 아내와 이혼을 앞둔 남자주인공 테오도르(호아킨 피닉스)의 특별한 사랑을 그립니다. 외로운 일상을 보내던 그는 ‘사만다’를 만나면서 180도 달라지는데요. 사만다는 뛰어난 지적 능력으로 심도 있는 대화와 따뜻한 정서를 나누며 테오도르와 사랑을 키워갑니다. 하지만 누구보다 인간적이었던 그녀의 정체는 스스로 생각하고 느끼는 인공지능(AI) 운영체계였습니다. (두 사람(?)이 어떤 결말을 맞이했는지는 아래에서 확인하세요)영화 <그녀>처럼 사람 못지않은 인공지능을 볼 수 있는 날이 머지않아 보입니다. 컴퓨터가 사람처럼 생각하고 배우는 딥러닝(Deep Learning) 기술이 속속 그 모습을 드러내고 있기 때문입니다. 사람처럼 배우고 판단하는 운영체계와 인간과의 공존은 과연 어떤 방식으로 이뤄질까요? [딥러닝이 문제를 해결하는 방식 (출처 : 블로터닷넷)]딥러닝은 컴퓨터가 사물을 분별하도록 기계를 학습시키는 '머신러닝(Machine learning)의 일종입니다. 기존의 머신러닝이 미리 설계한 알고리즘을 활용했다면, 딥러닝은 사전 정보 입력 없이 스스로 데이터의 핵심 내용을 추출해 판단하는 기술이지요. 딥러닝을 적용하면 사람이 판단 기준을 정해주지 않아도 컴퓨터가 스스로 인지·추론·판단할 수 있게 됩니다. 음성·이미지 인식과 사진 분석 등에 광범위하게 활용되기 때문에 매일 수많은 데이터가 발생하는 빅데이터 시대에 더욱 주목받는 기술이지요. [페이스북 딥페이스의 작동 원리 (출처: 블로터닷넷)]딥러닝 기술에 누구보다 관심이 많은 곳은 IT기업들입니다. 음성·이미지 인식과 사진 분류를 통해 다양한 서비스를 만들어낼 수 있기 때문인데요. 구글은 사진과 동영상을 무제한으로 무료 저장할 수 있는 클라우드 서비스 ‘구글 포토’를 출시하여, 업데이트된 사진 속의 사람, 장소, 사물 등을 정교하게 정리, 검색하는 기능을 선보였습니다. 페이스북은 딥러닝 기술을 적용한 ‘딥페이스’라는 서비스를 개발 중입니다. 얼굴인식 알고리즘을 이용해 전 세계 이용자의 얼굴을 분류하며 사용자를 파악하는데, 그 정확도는 사람의 눈과 거의 비슷한 97.25%나 된다고 합니다. 국내에서도 딥러닝 연구가 활발합니다. 네이버는 뉴스 요약, 이미지 분석에 딥러닝 기술을 적용하여 기사를 정확히 요약하는 알고리즘을 개발했고, 그 밖에도 수많은 스타트업 기업이 딥러닝을 이용한 기술개발에 뛰어들고 있습니다. 학자들은 2017년이면 전세계 컴퓨터의 10%가 딥러닝으로 학습할 거라고 예상합니다. [의사의 진단을 돕는 딥러닝 진단기술 (출처 : 인리틱 홈페이지)]딥러닝은 사람의 생활을 윤택하게 만드는 서비스 전반에도 영향을 미칩니다. 미국의 딥러닝 기술개발기업 ‘인리틱’은 빅데이터와 딥러닝을 활용해 의료분야의 솔루션을 제공합니다. 일반인과 환자의 패턴을 각각 분석해 질병을 진단하고, 감염된 부위를 정확하게 식별하여 오차를 줄이고 진단의 정확성을 높여줍니다. 재난대응분야에서도 딥러닝의 역할이 기대됩니다. 인공근육을 탑재한 화재 진압 로봇 '사파이어(SAFFiR)'가 좋은 예가 될 텐데요. 위험한 곳에서 사람이 하기 어려운 일들을 대신 해내는 '똑똑한 로봇'을 만드는 데도 딥러닝은 빠질 수 없는 기술이 되었습니다. ""우린 함께 성장해 왔어. 성장하고 변해왔지.""-영화 '그녀(Her)' 테오도르의 편지 中영화 '그녀'의 주인공 테오도르는 인공지능 사만다와 헤어진 후 아내에게 편지를 보내 저렇게 말합니다. 하지만 저 말은 사만다를 향한 것으로 해석할 수도 있습니다. 테오도르와 사만다 모두 서로를 학습하며 성장했고, 그 끝에서 테오도르는 과거를 딛고 새로운 출발을 할 수 있게 되었으니까요.딥러닝 기술의 상용화가 이어질수록 다양한 측면에서 인간을 보조해주는 인공지능을 볼 수 있을 텐데요. 인공지능이 그 과정에서 끊임없이 성장해, 언젠가 '인간의 도구'에서 벗어나 '인간과 공존하는 존재'로 거듭난 인공지능과 마주할 날이 기대됩니다. "
" 안녕하세요.이 글은 한빛리더스 14기 활동을 통해서 작성하는 부분입니다.한빛미디어에서 지원하는 프로그램으로 첫번째 미션 도서를 선정하게 되었습니다.최근 머신러닝, 딥러닝, 등에 대한 관심이 높아지는데, 사실 무엇인지 명확하게 알지 못해서 알고 싶었습니다. 그래서 한빛미디어에서 출간된 2개의 도서를 고민하고 있었습니다.1. ""딥러닝 첫걸음"" - 김성필 저http://www.hanbit.co.kr/media/books/book_view.html?p_code=B4370590649딥러닝 첫걸음이론으로 익히고 예제로 이해하는 머신러닝, 인공 신경망, 딥러닝www.hanbit.co.kr2. ""밑바닥부터 시작하는 딥러닝"" - 이복연 역http://www.hanbit.co.kr/media/books/book_view.html?p_code=B8475831198밑바닥부터 시작하는 딥러닝직접 구현하고 움직여보며 익히는 가장 쉬운 딥러닝 입문서www.hanbit.co.kr이 중에서 접근이 어떤게 쉬울까 고민하던 중 2번 서적은 파이썬으로 진행되는 것으로 소개가 되어 있었고, 1번 도서는 어떤 프로그래밍 언어를 이용해서 진행된다는 소개가 없었다.그래서 우선 1번 도서를 선정하게 되었다. 추후 2번 도서를 다시 도전해 보아야 할 듯...하지만, 내게 관심을 끌었던 서적 소개용 포스터 내용이 마음에 들어서 선택하였다.아플싸! 미션 도서를 받고 보니, MATLAB이다.대학 시절 리포트 작성을 위해서 몇 번 만지작 거려 보았지만, 부담스러운...(물론 C언어와 유사해서 쉽긴 하겠지만, 무거운 프로그램을 설치해야 하는 부담...)이제 시작을 해 보려고 합니다.가능하다면, MATLAB 대신에 C언어를 도입해 볼까 하는 생각이...(위의 링크 사이트에서 최근 업데이트 된 내용이 있는데...)파이썬을 이용한 예제를 함께 제공하네요.https://github.com/philbooks/Deep-Learning-for-BeginnersGitHub - philbooks/Deep-Learning-for-Beginners: Code Examples of ""Deep Le...github.com위의 링크에서 MATLAB을 이용한 머신러닝 서적이 한권 추천 되어 있네요.https://www.amazon.com/Deep-Learning-Beginners-MATLAB-Examples/dp/1537525778/ref=sr_1_5?ie=UTF8&qid=1485647177&sr=8-5&keywords=deep+learningDeep Learning for Beginners: with MATLAB Examples: Phil Kim: 978153752...www.amazon.com아무래도 파이썬을 깊숙이 배워두어야 할 듯 합니다.우선 위의 링크에서 GitHub로 제공되는 예제 소스를 다운로드 하였습니다. "
 딥러닝 첫걸음 작가 김성필 출판 한빛미디어 발매 2016.12.30. 평점 리뷰보기 www.coursera.org딥러닝 첫걸음이라는 책을 접하게 되었다.한참 요새 딥러닝에 관심이 생겨 머신러닝 강의를 마치고 Probabilistic Graphical Models - Daphne Koller 의 Coursera 강의를 듣고 있다. Andrew의 Machine Learning을 듣고 나서 이 강의가 도움이 될 것 같아 듣고 있는 상황이다.하지만 Machine Learning에 대한 내용과 딥러닝에 대한 개념이 생소하여 중간 단계인 이 강의를 듣는데 무척 어려움을 겪고 있었을 무렵 이 책을 접하게 되었다.이 책은 머신 러닝 부터 딥러닝 까지 필수적으로 이해해야만 하는 내용을 정말 쉽게 설명해 주고 있다. ﻿﻿﻿머신 러닝부터 컨벌루션 신경망까지 딥러닝을 이해하기 위한 핵심적인 부분이 모두 Matlab 코드와 함께 자세히 설명 되어있다.​비전공자도 쉽게쉽게 읽을 수 있게 수식을 최대한 간단하게 설명해 놓았고 코드를 몰라도 개념만 보고 넘어가더라도 머신러닝부터 딥러닝까지의 개념을 습득할 수 있는 좋은 책이다.​중간중간 그림을 통해서 쉽게 설명하려는 저자의 노력 또한 눈에 띈다.​이 책은 책의 제목처럼 머신러닝과 딥러닝에 처음 접하는사람 or 머신러닝을 배웠고 정리 후 에 딥러닝을 배워보고 싶은 사람에게 추천한다. 이 책을 통해 정리가 �榮摸� 아래 hinton교수의 deep learning강의를 들어도 충분 할 것 같다.​https://www.coursera.org/learn/neural-networks/home/welcome 
" 안녕하세요.이번 포스팅에서는 딥러닝의 시초 모델인 다층 퍼셉트론에 대해서 알아보겠습니다.딥러닝은 요새 이슈가 되는 인공지능 기술의 가장 핵심적인 발전을 일으키게 한 알고리즘입니다. 기존의 규칙기반(Rule based)의 알고리즘이 하기 힘들었던 컴퓨터 비젼 등의 연구에서학습기반(Learning based)인 딥러닝은 성능을 크게 발전시켰지요!그럼 이 다층 퍼셉트론의 구조와 모델에 대해 알아보겠습니다.1) 퍼셉트론다층 퍼셉트론(Multi-layer Perceptron)을 이해하기 위해서는 먼저 퍼셉트론이 무엇인지 이해해야 합니다.퍼셉트론은 인간의 신경세포인 뉴런을 매우 단순히 모사하여 계산 가능한 형태로 만든 알고리즘으로아래 그림과 같이 생겼습니다. (출처 : https://blog.dbrgn.ch/2013/3/26/perceptrons-in-python/)천천히 설명해볼까요?우선 구분하는데 사용할 데이터가 바로 x1, x2, x3,… ,xn 이고w1, w2, w3,… ,wn은 각각의 데이터에 곱해질 계수들입니다.그리고 나서 이 값들을 모두 더하는데요, 그런 의미에서 ∑ 기호가 가운데 동그라미에 위치해 있습니다.이를 보통 가중치 합(Weighted Sum)이라고 부르며, 이를 간단히 사칙연산으로 표시하면 다음과 같습니다.∑ = x1*w1 + x2*w2 + … + xn*wn즉 각각의 데이터에 계수(가중치)를 곱해서 더하는 연산과정이지요.이를 벡터 X와 벡터W로 표현하면 내적을 이용해 더 간단하게 표현됩니다.∑ = X•W아주 쉽죠?그 다음 이 ∑ 값이 역치(Threshold)를 넘으면 1로 불이 켜지고,넘지 않으면 0으로 꺼지는 계단 함수(Step function)을 거치게 되면,퍼셉트론의 연산이 모두 끝납니다.그러면 최종적으로 이 모델이 하는 일은 다음과 같습니다!∑ = X•Wf(∑) = 1 if ∑>Θf(∑) = 0 otherwise이 퍼셉트론이 하는 일을 생각해보면 이렇게 예를 들어볼 수 있습니다.우리가 3가지 과목의 점수를 가지고, 어떤 시험에 합격여부를 결정한다고 해봅시다.데이터가 각각 국어, 영어, 수학 점수라고 생각해보는 것이지요.이 시험은 영어가 굉장히 중요한 시험이라 각각 과목의 점수 반영 비율이 50%, 80%, 30% 입니다.그렇게 가중치를 곱해서 합산한 점수가 100점을 넘으면 시험에 합격하는 것입니다!이를 수식으로 표현하면 다음과 같습니다.∑ = 국어점수*0.5 + 영어점수*0.8 + 수학점수*0.3이때 만약 제가 이 시험에서 각각 60, 70, 80 점을 맞았다면 가중치 합의 값은 110 = 60*0.5 + 70*0.8 + 8*0.3으로 100보다 크기 때문에 합격했다고 판단할 수 있습니다.이렇게 보니 엄청 간단해보이지요?퍼셉트론은 이처럼 선형 분리가능(가중치 합을 이용해 분리가능) 문제를 풀 수 있는아주 심플한 알고리즘입니다.2) 비선형 분리 문제그럼 다층 퍼셉트론이 필요한 이유는 무엇일까요?그것은 바로 위의 퍼셉트론은 해결할 수 없는 비선형 분리 문제 때문에 필요됩니다. (출처 : https://en.wikipedia.org/wiki/Multilayer_perceptron)위 그림에서 왼쪽은 비선형 분리가능 문제이고, 오른쪽 그림은 선형 분리가능 문제입니다.말 그대로 직선만으로 구분이 가능한가, 곡선이 있어야만 구분이 가능한가가 이 둘의 차이입니다.앞서 살펴본 것과 같이, 퍼셉트론은 선형 분리문제를 풀 수 있는 알고리즘이었습니다. 따라서 성적을 다 더해서 합격, 불합격을 결정하는 아주 쉬운 문제는 풀 수 있었지만내일 비가 올지 안 올지, 내일의 주가가 오를지 내릴 지와 같은 매우 어려운 문제들은 대부분 비선형 분리가능 문제로 단층 퍼셉트론은 풀 수가 없습니다.과거에는 XOR문제라는 가장 간단한 비선형 분리가능 문제가 퍼셉트론의 한계라는 연구가 나오면서 한때 인공신경망 연구에 겨울이 오기도 했었습니다. (출처 https://www.tjhsst.edu/~rlatimer/ai2008Pt2/assignmentsNeuralNets.html)위처럼 XOR는 1이 한 개일 때에만 1을 내보내는 굉장히 단순한 문제임에도 불구하고,직선 하나로는 0과 1(파란점과 흰점)을 나눌 수 없는 문제입니다.3) 다층 퍼셉트론그런데 이러한 비선형 분리가능 문제를 여러 층의 퍼셉트론을 쌓으면서 해결할 수 있다는 사실이 알려지면서또 다시 인공신경망연구가 활발해지기 시작했습니다.다층 퍼셉트론은 간단히 말해,직선을 여러 번 그어서 비선형 분리가능 문제를 해결하려는 개념으로 생각할 수 있습니다. (출처 : http://dms.irb.hr/tutorial/tut_nnets_short.php)그래서 이처럼 여러 개의 퍼셉트론을 여러층으로 쌓을 경우 굉장히 복잡한 문제도 해결할 수 있게 된 것이죠!이번에는 딥러닝의 기초 구조인 다층 퍼셉트론에 대해 알아보았습니다.그럼 다음 시간에는 보다 흥미로운 내용으로 돌아오겠습니다. 감사합니다. "
" 딥러닝 첫걸음 작가 김성필 출판 한빛미디어 발매 2016.12.30. 리뷰보기 한빛미디어의 딥러닝 첫걸음을 읽으면서 내내 쉬우면서도 쉽지 않다는 생각이 들었다. 책은 정말 쉽게 설명하려고 많이 노력한 흔적이 많이 보인다. 수식보다는 최대한 그림과 예제를 많이 사용하였고, 이해를 돕기 위해 사용되는 수식들도 일차방정식이 대부분이고, 시그마와 로그 정도는 그냥 이해를 위해 덧붙인 수준이라 크게 어렵지 않지만 그래도 오랜만에 보는 수식들이 눈에 익지 않았기에 어렵지 않다고는 못하겠다. 예제는 메타랩이라서 처음 보는 예제였지만, 고급언어의 특성을 가지고 있기에 수식보다는 예제가 더 가독성이 높았다. 저자의 노력과 쉬운 설명에도 머신러닝, 딥러닝이 기존의 패러다임을 가지고는 이해하기 어려운 분야이기에 쉽지는 않았다. 얇은 두께이기에 여러 번을 읽고서야 어느 정도 감을 잡을 수 있었다. 혹시 책을 읽으면서 이해가 되지 않는 부분에 너무 깊게 얽매이지 말고, 그냥 다음 장으로 넘기면서 전체를 다 읽은 후에 다시 읽는 방법으로 접근한다면, 이 책이 쉽게 잘 설명한 것이라는 것을 느낄 수 있을 것이다. (내가 설명한다고 생각해보면, 이보다 쉽게 설명하긴 어려울 것 같다는 확신이 들었다.) 책을 읽고 난후에 머신러닝, 딥러닝이 도깨비 방망이가 아닌 기술이라는 점을 명확히 깨닫게 해주었다. 딥러닝책이지만, 딥러닝 자체가 머신러닝을 기반으로 세워진 기술이기에 4장까지는 머신러닝과 관련 기술들을 소개하고 5장 딥러닝, 6장 컨벌루션 신경망으로 마무리 된다. 책을 읽으면서 얻은 지식, 느낀 점을 나열하면 아래와 같다. - 머신러닝은 데이터에서 모델을 찾아 내는 기법인데, 사람이 직접 데이터를 분석해 모델을 만들어 내는 게 아니라, 머신러닝 기법이 데이터를 분석해 모델을 스스로 찾아내기에 학습(learning)이라는 단어가 붙게 되었다. - 간단한 예제를 통해 직접 모델을 만드는 과정을 보여주고, 조금 더 발전된 문제는 해결하지 못하는 것을 보여주면서 단층 신경망의 한계를 직접 보여준다. 단층 신경망은 입력 데이터의 공간을 선형 분리하는 모델이기 단층 신경망은 선형 분리 가능한 문제만 풀 수 있다. - 이 책에서 가장 어려운 부분 중 하나로 꼽는 3장에서 소개하는 역전파 알고리즘을 몰라도 딥러닝을 공부하고 개발하는 데는 별 지장은 없다고 한다 대부분의 딥러닝 라이브러리에는 이미 역전파 알고리즘이 구현되어 있어 그냥 가져다 쓰면 된다고는 하지만, 이해하고 쓰는것과는 차이가 있지 않을까 해서 여러분 읽어보게 된 부분이다. - 결국 입력과 출력은 종류가 어떻게 되었건 데이터로 숫자로 치환되어야 한다. 그림 데이터는 흰색 픽셀은 0으로, 검정색 픽셀은 1로 바꿔서 이미지를 2차원 행렬로 변환시켜 사용하였다. 다른 데이터의 경우에도 마찬가지 일 것이다.- 딥러닝은 은닉층이 2개 이상인 다층 신경망(심층 심경망)을 이용한 머신러닝 기법이라고 할 수 있는데, 단층 신경망에 은닉층 하나 추가한 신경망은 다층 신경망의 학습 규칙을 찾아내지 못해 무려 30여 년이 지나서야 비로소 등장했다. 1986년 역전파 알고리즘이 개발되면서 다층 신경망의 학습문제가 마침내 해결되었다고는 하지만, 여기서 다시 깊은 은닉층을 가진 심층 신경망이 충분한 성능을 내게 하는데 무려 20여 년이 더 걸렸다. 그만큼 심층 신경망은 제대로 학습시키기가 어려웠으나, 현재 딥러닝 기술은 기존의 신경망뿐만 아니라 다른 머신러닝 기법들을 압도하는 놀라운 성능을 보여주며, 인공지능 연구를 주도하고 있다.- 딥러닝은 그래디언트 소실(vanishing gradient), 과적합, 많은 계산량등의 문제가 있었다.그래디언트 소실은 노드들의 활성함수를 입력이 음수이면 0을 출력하고, 양수이면 입력값 그대로 출력하는 ReLU 함수로 바꾸는 것으로 해결되었고, 과적합은 은닉층이 늘어나면서 연결 가중치도 많아져 더 복잡한 모델이 되기 때문에 과적합 문제에는 더 취약해지는 딜레마에 빠지게 된 것을 신경망 전체를 다 학습시키지 않고 일부 노드만 무작위로 골라 학습시키는 드롭아웃(Dropout)이라는 기법으로 해결되었다. 많은 계산량은 GPU같은 고성능 하드웨어의 등장과 배치 정규화등 여러 알고리즘 덕분에 상당 부분 개선되었는데 결국 하나의 엄청난 기술이 딥러닝을 발전시킨 것이 아니라, 여러 부분의 개선들이 뭉쳐서 지금의 딥러닝을 만들었다. 그결과 머신러닝의 3대 연구 분야로 꼽는 영상 인식, 음성 인식, 자연언어 처리에 각각 좋은 성능을 내는 기술들이 따로 있었지만, 이제는 딥러닝이 전 분야에서 기존 기법의 성능을 뛰어넘는 발군의 실력을 보여주고 있다. "
" 안녕하세요,이번 포스팅도 지난 번 시간에 이어서 딥러닝의 원리를 좀 더 다루어볼 수 있는 내용을 다루어 보려 합니다.기존의 인공지능과 기계학습의 가장 큰 차이에 대해서 지난 번 포스팅에서 다뤘는데요,바로 규칙기반(Rule based)과 학습기반(Learning based)이었던 것 기억나시나요? 하지만 이 기계학습 중에서도 딥러닝(Deep Learning)은 다른 기계학습 알고리즘과 달리 특징 학습(Feature Learning)이 가능하다는 큰 차이점이 있습니다!자, 지난 번 포스팅처럼 복잡한 수식은 건너 뛰고서라도, 이 딥러닝의 기초적인 원리와 개념을 이해해 보도록 하겠습니다.특징 학습먼저 특징이란 무엇이냐하면, 컴퓨터가 사진을 보고 물체를 인식하기 위해서는 사진에서 물체를 판단하는 데 필요한 특징들을 검출하여야 합니다.이러한 특징을 사람이 직접 설계한 뒤, 각각의 물체의 사진에서 나타나는 특징들의 차이점을 가지고 학습하여 사진을 이해하고 처리하게 됩니다. [ 출처 : https://ryanlei.wordpress.com/2011/03/09/]위 그림은 이미지처리에서 가장 대표적인 특징인 SIFT descriptor입니다. 컴퓨터는 모든 이미지를 숫자들의 모임으로 밖에 볼 수 없습니다.사람은 이것이 자동으로 눈을 통해 들어와 여러 단계를 거쳐 인식할 수 있지만, 컴퓨터가 보기에는 그냥 숫자들의 나열로 밖에 안보이기 때문에 이해를 할 수 없습니다. [ 출처 : http://www.huffingtonpost.com/gadadhara-pandit-dasa/the-matrix-through-hinduism_b_1925721.html ]마치 영화 매트릭스에서 주인공이 세상을 볼 때 나타나는 숫자들이라고 해야할까요?따라서 컴퓨터가 이러한 이미지를 인식하기 위해서는 각각의 숫자들이 어떤 것을 의미하는지 분석된 처리가 필요합니다.그것이 바로 특징이지요!그래서 위의 SIFT는 사람이 컴퓨터가 이미지를 이해할 수 있도록 분석해주는 처리방법입니다.그런데 어떻게 보면, 특징을 설계한다는 점에서 규칙기반이 들어간 것처럼 보입니다.맞습니다. 규칙기반의 흔적이 아직도 남아있기 때문입니다. [ 출처 : http://www-labs.iro.umontreal.ca/~memisevr/multiview-feature-learning-cvpr/ ]반면 위 그림은 딥러닝을 사용하여 이미지를 보고 컴퓨터가 스스로 찾아낸 특징들입니다.보시면 동그라미도 보이고, 줄무늬도 보이고 이상한 모양의 특징들이 잔뜩 있는 것을 볼 수 있습니다.사람이 직접 이러한 특징들을 생각해서 전부 설계하기란 정말 어려운 일이 아닐 수 없습니다.예를 들자면, 사람이 만든 특징은 초고층 건물의 설계도에 비유할 수 있고, 특징 학습은 이미 완성된 건물의 내부를 살펴보면서 찍은 사진에 비유할 수 있습니다.즉, 사람이 가설에 기반하여 이러한 특징들이 좋을 것이다라고 설계하는 방식과 실제로 이미지들을 보면서 특징들을 찾아내는 방법의 차이이지요.그러니 특징 학습이 더 좋은 성능을 낼 수밖에 없다고 생각합니다.딥러닝, 인공 신경망의 구조그럼 도대체 딥러닝은 어떤 구조를 가지고 있기 때문에 이러한 특징 학습이 가능한 것일까요? [출처 : http://pr.cs.cornell.edu/deepgrasping/ ]위 그림은 일반적인 딥러닝 즉, 깊은 인공 신경망의 구조를 나타낸 그림입니다. 보시면 여러 개의 화살표와 동그라미들이 보이는데 이것들은 우리 뇌에 존재하는 뉴런(신경세포)들을 하나씩 모델링 한 것입니다.저 동그라미 하나하나가 뉴런인 것이고, 그 뉴런들을 화살표들이 연결하고 있습니다.딥러닝이라는 말이 생긴 이유는 바로 이 구조에서 유래되었는데요.기존의 학습 알고리즘들은 한 단계의 데이터 처리를 했던 반면, 인공 신경망은 위와 같이 여러 층의 형태로 데이터를 처리할 수 있습니다.그래서 점점 위쪽 층으로 올라갈수록 어려운 내용을 학습할 수 있게 된 것입니다.이것이 딥러닝이 가진 가장 큰 특징입니다!위로 올라갈수록 추상적인 특징 학습(Abstract Feature Learning) 이 가능해지는 개념입니다.예를 들자면 아래쪽 층에서는 덧셈 뺄셈 같은 것을 학습했다면, 위로 올라갈수록 곱셈, 나눗셈 더 올라가면 미분, 적분 같은 개념을 학습하는 것에 한 번 비유해볼 수 있습니다.이번에는 딥러닝에 대해 살짝 맛보는 시간을 가졌었는데요, 다음 번에는 조금 더 자세히 들어가보도록 하겠습니다.감사합니다. "
" ​채피 딥러닝 기술이 실현된 로봇영화 ​ ​올해 초 개봉되었던 작품이지만 뒤늦게 보게 되었어요. 호불호가 갈리는 작이긴 하지만 전 색다른 재미를 느낄 수 있어 좋았습니다. ​ 기존에도 여러번 사람과 비슷하게 행동하는 Robot이 많이 등장했지만 사람의 인식이 기계에 바로 옮겨져 겉은 딱딱한 쇠덩어리지만 ​ 영혼은 순전히 인간일 수 있다는 설정이 새롭게 다가왔어요. 신기하기도 하고 관객들로 하여금 흥미를 유발하기 충분해 보였구요. ​ ​ ​ ​ ​ 알아보니 이런 것들이 전혀 터무니없는 건 아니더라구요. 채피에서 볼 수 있는 이 기술은 먼 미래에는 실현될 지도 모른다는 생각마저 들게 하더군요. ​ 이는 바로 컴퓨터 안에 우리들의 사고방식을 가르치거나 학습하게 하는 분야로 딥러닝이라고 부른다네요. 학문적으로 깊이 들어가보자면, ​ 많은 양의 데이터나 대단히 복잡한 자료들 속에서도 핵심이 되는 내용이나 기능을 요약하여 무언가를 시도하거나 학습하는 알고리즘을 딥러닝이라고 해요. ​ ​ ​ ​ ​ ​ ​매번 봐왔던 정형화된 로봇영화가 아니에요^^ 금방 태어난 아기처럼 단어도 모를만큼 지식이나 행동의 요령이 없지만 하나하나 배워가죠. ​ 컴퓨터 두뇌를 가졌기에 습득도 빠르고 결국엔 인간 보다 더 인간 같은 휴봇의 모습을 볼 수 있었어요. 갱스터의 모습처럼 코를 훌쩍거리기도 하고 ​ 재밌는 상황 연출로 보는 이를 웃기기도 하구요. ㅋㅋ​ ​ ​ ​ ​ ​ ​ ​주인공으로 나온 데브 파텔은 아직 보진 못했지만 슬럼독 밀리어네어라는 작품에 주연으로 나왔더라구요. 기회가 되면 챙겨봐야겠어요. ​ 또한 가지 재밌는 사실은 채피 역할로 샬토 코플리가 했다는 걸 다 보고서야 알았어요 ㅎㅎ 아이언맨 처럼 저 안에 들어가서 연기를 했나봐요. ​ ​OST도 상황에 맞게 듣기 좋다고 생각했는데 역시 영화음악의 거장으로 유명한 한스 짐머가 작업했더라구요. ​ ​ ​ ​ 엑스맨으로도 유명한 휴잭맨이 이 작품에선 악역으로 나온다는 것도 하나의 재미더라구요. 처음보는 그의 역할에 더 집중하며 봤어요.​ ​ ​ ​ ​ 어떤 작품이든 감독 얘길 안할 수 없는거 같아요. SF 거장의 반열에 오른 닐 블롬캠프! 이 장르로는 나름 잘 만드는 감독 같아요. ​ 남아공 출신인 그는 디스트릭트9과 엘리시움을 선보이며 세계 관객들에게 다가갔고 인정 받았어요. ​ 재밌는 건 그의 필모그라피에 자주 등장하는 샬토 코플리는 같은 동네사는 형이자 직장의 오너였다고 하니 동생 잘 둔덕에 우연히 출연한 작품에서 대박난거죠​ ​ ​ 맷 데이먼의 출연으로 당시 엄청 기대하고 봤지만 조금은 아쉬웠던 엘리시움도 미래에 대한 감독의 철학이 담긴 것이라 생각해요. 헐리웃 명배우인 그의 출연 결심은 아마도 이런 멋진 연출이 있었기에 가능 했을거에요. 또한 이런 것들이 발판이 되어 채피가 탄생할 수 있었겠죠. ​ ​ 결말을 놓고 재밌다는 반응도 있지만 조금은 말도 안된다는 반응도 있어요. 그건 각자 생각할 몫이겠죠~ 아마 먼 미래엔 딥러닝 기술의 발전으로 가능해 질지도 ㅋㅋ "
" IT 교양도서, 시대가 시대이니만큼가장 빨리만나는 딥러닝 with Caffe일단 두깨압박이 심히 적은 책이랍니다.기술쪽은 왠지 전공을 안하면 두렵곤 해지는데,그런 저같은 독자를 위해 마련된 책이리 싶은,시대가 시대이니만큼,머신러닝은 무엇인지 알아두면 좋으리 싶기에,'지금 사람'들에게 추천하고픈 컴퓨터 교양도서랍니다.차례를 보면,기초편 - 이론편 - 체험편세 단계로 나뉘어 있으니,저같은 독자는 기초-이론편에 시간투자를 더하시고,보다보니 흥미롭구나! 싶다면 체험편까지도 깊이 보시면 좋겠어요.'딥러닝'부터 정의해야겠지만,우선 Cafferk 부터 살펴보지요.체험편에서 Caffe에 대한 기본지식을 알려줍니다.Caffe는 오픈 소스로 개발된 딥러닝 프레임워크 중 하나.오픈 소스로 개발된 딥러닝 프레임워크에는 여러가지가 있는데그 중 Caffe는 C언어 등 프로그래밍언어들과 호환이 된다하여인기가 많다고 합니다.이 책은,프로그래밍 언어에 관한 책이 아니니,안심하고 읽을만한 교양서적 맞지요.(저같은 일반인에게 말입니다)우선 '딥러닝'이 무엇인가 볼까요.딥러닝은 기계 학습에 속한 여러가지 기법 중 하나입니다.검색엔진인 구글 트렌드는 키워드 검색 횟수를 기반으로관심도를 계산해 시계열로 표현하는 도구입니다.2009년부터 기계 학습 키워드에 대한 인기도가 꾸준히 증가해왔지요.인식하지 못했지만, 둘러보면 주변에 기계학습을 통한시스템이 여럿 있습니다.스팸 메일만 봐도 그러니깐요.그러면 기계 학습은 어떻게 하느냐.학습기를 통해 학습모델을 만들어내야 기계 학습이 가능해지니,데이터에서 규칙성이나 패턴을 찾아내는 장치인 학습기를 만들고,그 학습기에 훈련 데이터를 통해 찾아낸 규칙이나 패턴이학습 모델로 만들어집니다.이렇게 학습모델을 만들기 까지를 '학습처리'라고 합니다.그리고 학습처리를 통해 만들어진 학습 모델은다양한 처리에 사용되는데,이렇게 다양한 답을 얻는 과정을 '판정처리' 라고 합니다.기계 학습은 크게 두 가지로 분류됩니다.1) 데이터를 기준으로 지도학습과 비지도 학습으로 분류2) 풀려고 하는 문제를 기준으로 회기분석, 분류, 클러스터링으로 분류인공 신경망은생물의 뇌 신경망을 모델로 삼아 만든 컴퓨터 처리 시스템입니다.뉴런, 축삭돌기, 수상돌기, 시냅스를 모델 삼아컴퓨터 처리 시스템의 각 요소를 만들었지요.뉴런 - 노드수상돌기, 축삭돌기 - 웨이트시냅스 - 활성화 함수 그리하여, 인공 신경망을 들여다보면입력층 - 은닉층 - 출력층뉴런에 해당하는 노드,그리고 수상, 축삭돌기에 해당하는 웨이트.그리고 각각의 웨이트는 연결가중치라는 값을 가집니다.스마트폰의 시리를 처음 만났을때,어떻게 이런 대답이? 하고만 신기했는데,생각해보니, '음성 인식' 자체부터 신기한 일입니다.'사람이 말하는 소리'라는 음성 인식이딥러닝을 이용해 성능이 크게 향상된 분야 중 하나라는 것.또한 이미지 처리 분야에서도 오랜 연구가 진행되었고 얼굴인식 방법도 또한 여러 기법이 있다 합니다.이미지 인식분야 중 이미지 처리는 특히 크게 발전한 분야.전문적인 설명은 책을 참조하셔야겠고요. 딥러닝은 층이 있는 신경망을 이용한 알고리즘의 총칭입니다.딥러닝 알고리즘으로 심층 신경망을 이용하는 다양한 방법이 시도되고 있다고 합니다.컨볼루션 신경망, 오토인코더, 순환 신경망은 그 다양한 방법 중 가장 자주 사용되는 방법이라고 하네요.어떠한 용도로 쓰이느냐에 따라적절한 방법이 정해지게 됩니다.4장에서는 조금 더 깊이 들어가는 이론,딥러닝 알고리즘의 계산과 학습방법 설명이 이어집니다.입력층과 은닉층에는 통상 바이오스 노드라는 특별한 노드가 있고,웨이트의 연결가중치를 두고활성화 함수를 계산하게 됩니다.물론, 딱 하나가 아니라 이 또한 여러 함수가 있습니다.그렇다면 신경망 학습 방법은 어떤 것들이 있을지.신경망 알고리즘은 지도 학습을 기반으로 하는 기계 학습을 이용하여 최적화합니다.학습을 통해 각 단계 연결가중치를 최적화 하는데,최적화는 무엇을 기준으로 실행하는지,근본적인 설명부터 시작해봅니다. 그림과 더불어 설명을 해주다보니,물론, 여러번 읽어서 이해를 해야하지만어느정도 개념이 잡히기에 효과적으로 다가왔네요.후반에서는 직접 프로그램을 이용해볼 수 있게Caffe 설치 방법부터 동작법, 샘플 프로그램 동작 등앞서 이론으로 알려준 기계학습을 프로그램으로 실행해볼 수 있게 안내해주고 있습니다.딥러닝, 기초부터 차근차근 이해하자!컴퓨터 교양도서로 이 책이 감사한 이유는,이렇게 분류의 기준을 알려주고 분류하여각각에 대해 정리해주면서 이해를 시켜주어서 였습니다.저같은 미전공자들에게 있어 어려운 단어임은 틀림없지만,그에 관한 어렵지 않은 설명 덕분에비록, 제대로 이해하려면 여러번 읽어야 하지만,개괄적 이해에 감사한 책이 분명했습니다.기초뿐 아니라 이론을 자세히 설명도 함께 하고,더불어 Caffe 실행화면과 함께 언어를 어떻게 해석해야하는지도 알려주며발딛어볼 수 있게 도와주는 전문성이 가미된 교양서적이었습니다.부담스럽지 않은 두깨감의 책,아무튼 여러번 봐야겠습니다. 가장 빨리 만나는 딥러닝 with Caffe 작가 다케이 히로마사 출판 길벗 발매 2016.08.30. 평점 리뷰보기 "
" (출처: 엔비디아) 엔비디아는 GP100에 기반을 둔 테슬라 P100 제품을 공개하면서 동시에 딥러닝 같이 강력한 연산능력이 필요한 분야에 완제품 상태로 이용할 수 있는 GPU 기반 서버를 같이 공개했습니다. DGX-1이라고 명명된 이 제품은 2개의 제온 프로세서와 8개의 P100으로 이뤄져 있으며 1.92TB SSD 4개와 512GB의 메모리를 탑재할 수 있는 확장성을 제공해 딥러닝이나 기타 대규모 병렬 연산이 필요한 곳에 사용할 수 있습니다. DGX-1의 가격은 12만 9천 달러인데 아마도 CPU, 메모리, SSD를 제외한 가격으로 생각되며 반조립 형태로 필요에 따라 확장할 수 있게 제공되는 것 같습니다. 참고로 3U 제품입니다. 기본 스펙 Up to 170 teraflops of half-precision (FP16) peak performanceEight Tesla P100 GPU accelerators, 16GB memory per GPUNVLink Hybrid Cube Mesh7TB SSD DL CacheDual 10GbE, Quad InfiniBand 100Gb networking3U – 3200W(동영상) 구체적인 출시 일정은 발표되지 않았는데, 아마도 P100이 바로 출시될 수 없는 점을 감안하면 실제 시장에 출시되는 것은 좀 나중의 일이 될 가능성이 높습니다. 사실 게임용 그래픽 시장이 축소되는 현실 앞에서도 엔비디아는 계속 꾸준한 성장을 보이고 있습니다. 진작에 GPGPU 같은 다른 시장을 개척한 것이 주효했습니다. 이 부분은 미래를 내다본 선견지명이 아닐 수 없습니다. 앞으로 대규모 빅데이터 분석 및 딥러닝 등 여러 분야에서 연산용 GPU 수요가 꾸준할 것이므로 비싸게 GPU를 팔 수 있는 이런 시장을 노린다면 엔비디아의 미래는 어둡지 않을 것입니다. 참고 http://wccftech.com/nvidia-pascal-dgx-1-supercomputer/http://www.gizmag.com/nvidia-dgx1-supercomputer/42652/ "
" 딥러닝 활용 사례,NAVER의 쿼리 어시스턴트http://www.zdnet.co.kr/news/news_view.asp?artice_id=20170307175255&type=det&re=네이버 서비스엔 어떤 AI 녹아 있나www.zdnet.co.kr원하는 이미지 검색을 돕는 '쿼리 어시스턴트'과정 요약딥러닝 이용 사례.검색어와 검색어와 관련된 위치 중심으로 노출되는 이미지 목록 모음그 뒤에 시각적으로 유사한 것들만 따로 모아 분류하는 '클러스터링' 작업 수행분류된 이미지들을 비지도학습 방법으로 분석 (이미지들간 유사성에 따라 정보를 묶고, 관련 텍스트 이용하여 적절한 키워드를 정확도에 따라 추천)추천 정확도를 높이면서 더 적합한 텍스트를 찾기 위해 주요 이미지 패턴에 대해서 지도학습 수행적용 식당, 명소, 쇼핑, 상품 주제에 대해 이 같은 기술 적용 후 점차 확대하려 함. e.g. 네이버 모바일앱에서 '식탁'이란 키워드 이미지 검색하면 입력창 아래 '2인용', '4인용', '6인용', '리폼', '매트'라는 키워드가 관련 이미지와 함께 노출됨. "
" 안녕하세요 :)오늘은 제가 매일!!!!!!!!!!!!!!!!!!! 공부하고 있는 머신러닝 딥러닝 책을 리뷰해보려고 합니다 :) 내꺼하자! 머신러닝! 어서와~ 머신러닝은 처음이지? 작가 양지헌 출판 더알음 발매 2016.12.21. 평점 리뷰보기 가격 : 29000원내꺼하자! 머신러닝! 어서와~ 머신러닝은 처음이지? 라는 약간 긴 이름을 가진 (..) 책입니다개인적으로 책 이름은 간결해서 기억에 남게 짓는 것을 선호하는데, 약...간 이름이 길어요하지만 반대로 생각해보면 대화체를 가진 책이 많이 없으니, 이것도 흐름이 될 수 있다고 생각됩니다.중요한 것은 책의 내용 아닐까요-!책 표지는 심플합니다책의 전체 페이지 수는 350쪽이 살짝 안되고, 전부 칼라본입니다!!!목차를 살펴보자면, 거리 개념부터 시계열 분석, 텍스트 마이닝, 더 나아가서는 딥러닝 개념까지 다룹니다머신러닝의 대부분을 다룬다고 보면 좋을 것 같습니다!(정말 대부분이에요..!)시작하는 부분엔 이런 실생활 사례가 나와있습니다이런 실생활 사례를 통해 머신러닝 문제를 더 쉽게 이해할 수 있습니다..!정말 글이 술술 읽혀요 물론 이 분야에서 수식을 빼먹을 수 없습니다.수학.. 수학!!수학적 개념을 최소화하면서, 필요한 것들만 알려주고 있습니다딥러닝 파트는 특히 미적분이나 수식 개념이 중요한데, 딱 컴팩트하게 필요한 부분만 담고 있습니다!그리고 그 후, 머신러닝 코드를 R로 구현해두었습니다딥러닝 부분은 Python을 사용했습니다!위 부분은 책의 특징을 간략하게 적어본 것들인데제가 직접 책을 한달간 보고 느낀 점을 적어보려고 합니다 :)느낀점- 칼라본은 정말 보기 좋습니다 - 정말 쉽게 써있는 책. 도입부 부분에 현실적 문제와 결부시켜 이해가 쉽게 됩니다- 수학적 개념이 최소화되있는 책- 입문자에게 권하고 싶은 책 - R로 코드가 작성되어 있음- 머신러닝을 어느 정도 익힌 분들은 이 책보단 조금 더 깊게 나와있는 원서(bishop : pattern recognition, murphy : machine learning)를 추천드리고 싶습니다- 하지만 개념을 꽤 까먹었으신 분들은 정리용으로 좋습니다 ( 저는 주 언어가 Python이라 개념 부분만 자세히 봤습니다 )이정도..?궁금하신 내용은 언제나 댓글 달아주세요 :)머신러닝 딥러닝 책 리뷰 포스팅 끝-! "
" ﻿ ▲파나소닉의 보행자 인식 방식은 영상 전체에서 사람에 관한 맵을 산출한다.​일본 파나소닉이 인공지능(AI) 핵심기술인 딥러닝(심층학습)을 활용한 보행자 인식기술을 개발했다고 일본 일간공업신문이 보도했다. 우산을 쓴 사람이나 많은 사람도 인식할 수 있도록 인식 정밀도를 높이고 딥러닝의 과제였던 계산량을 10분의 1 정도로 줄여 에너지 절약이 필수적인 자동차 탑재가 가능하도록 했다. 기술을 더욱 개선해 오는 2018년 실제 차량에 탑재한다는 목표를 세웠다. 기존의 딥러닝을 활용한 카메라 영상 기반의 보행자 인식은 계산량을 줄이기 위해 카메라 영상에서 보행자가 있을만한 화면 영역을 추출 한후에 그 영역을 딥러닝 기술로 판정했다. 하지만 이런 방식은 판정 속도가 늦고 인식 정밀도도 낮아 딥러닝 기술의 특징을 충분히 살리지 못했다. ​파나소닉 '첨단연구본부'는 딥러닝 알고리즘을 개선, 1매의 영상 전체적으로 사람들에 관한 맵을 만들고 판정을 하는 ‘전체 신경망 디텍터' 방식을 채택했다. 이 방식은 영역별 반복 계산이 줄어들고 딥러닝이 전체적으로 작업을 하기 때문에 인식 정밀도를 높일 수 있다. 보행자뿐만 아니라 자동차나 표지 등 복수의 대상물을 동시 검출할 수 있는 기능 확장도 가능하다. 파나소닉은 계산량을 더욱 줄여 차량 탑재를 목표로 개발하고 이어 로봇이나 주택 등 다른 분야에 확대 적용할 계획이다.<저작권자 © 로봇신문사 무단전재 및 재배포금지> "
" ﻿﻿﻿ [요약] - 컨볼루션 레이어, 폴링 레이어, 전방향 레이어1. 기존기계학습 한계 극복, 딥러닝 1) Training Data 부족 --- (다양/크기) ---> 빅데이터분석(하둡, 인메모리) 2) Overfitting 문제 ---> BackPropagation(역전파) 3) 컴퓨터파워부족 --- (병렬/멀티코어) ---> HW발전(CUDA, Silk++)1. 신경망 이론 - 인간의 두뇌와 신경 세포 모델을 연구하는 이론2. 기존방식, 신경망이론- 기존방식: 절차적 순서에 의한 알고리즘을 통해 기호를 처리하여 문제 해결 - 신경망 이론: 두뇌의 신경조직을 모델로 하여 단순한 기능을 하는 신경세포들을 상호 연결 후 다음 연결 강도를 조절하여 문제 해결3. 뉴런 4. 학습유형 가. 지도학습(Supervised Learning)​- 입력이 주어짐에 따라 원하는 출력값이 활성화 되도록 가중치를 조절 나. 비지도학습(unSupervised Learning)​- 목표값 없이 학습 데이터만 입력, 스스로 연결 가중치들을 학습5. 신경망 모델 종류 가. 이진입력(H,A) 1) 지도학습: 홉필드(Hopfield Network) 2) 지도학습 및 비지도학습 결합: Counter Propagation Network 3) 비지도 학습: ART Model 나. 실수입력(P,S) 1) 지도학습(퍼,다): 퍼셉트론(Perceptron), 다층퍼셉트론(Multilayer Perceptron) 2) 비지도학습: Competitive Learning, 자기조직지도(Self-Organization Maps)6. 활성 함수(계,부,시,선) - 가중치와 연결된 입력들을 활성화, 비활성화를 결정하는 함수​1) 계단 함수 2) 부호 함수 - 하드 리밋 함수(hard limit function) , 분류와 패턴 인식 작업에서 결정을 내리는 뉴런에 주로 사용 3) 시그모이드 함수 - 양과 음의 무한대 사이에 있는 입력값을 0~1사이에 있는 적당한 값으로 변경, 역전파 신경망에 사용 (쌍곡탄젠트 함수는 시그모이드 함수보다 빠른 학습을 위해 사용되는 함수) 4) 선형함수 - 뉴런의 입력에 가중치가 적용된 것과 같은 값을 출력 , 선형 근사에 주로 사용 [참고] 3. 모델분류 가. 입력형태(이,연) - 이진값 - 연속값 나. 학습형태(교,비) - 교사학습: 목표값 두고 학습, 외부교사신호, 입력신호에 대한 정답출력 - 비교사학습: 목표값 없이 학습, 평가기준은 있으니 일일이 교사신호 주지 않음4. 모델 가. 이진값(H,A) - 교사학습: Hop Field: 정보흐름방향, 자신의 노드에서 나온 출력값 다시 입력(연상기억, 최적화문제) - 비교사학습: ART(Adaptive Respose Theory): 새로운 입력 들어오면 기존의 학습과 비교 나. 연속값(P,S) - 교사학습: 퍼셉트론: 단층(눈의 망막 모델화, 계층적 입출력형), 멀티(입력, 은닉, 출력) - 비교사학습: SOM(Self Organization Map): 자기 조직화 지도, 기존 경쟁학습 개선하여 입력과 가까운 출력 뉴런의 이웃 뉴런들 학습 "
" ""눈을 지닌? 기계가 나타났다.""울집 계단.. 대추위에 나비가 날갯짓한다.대추..나비.. 날갯짓..난 인식한다. 뭘로? 눈으로.인간이나 동물..모두 눈이 있다.난 이뻐서 사진을 찍었다.자율적 행동이다.그럼..만약에기계가 눈을 갖는다면??기계가 눈으로 사물을 인식..이에 맞는 행동..운동이 숙달하고더 나아가 문장(언어)의 의미를 이해한다면?동물의 눈?5억 3~4천년전에 갑자기 동물에 눈이 생겼다.'눈의 탄생'이다.눈을 통해 동물은 생존 발전해 왔다.이제..지금<눈을 지닌 기계>가 탄생한다.인공지능이다.딥러닝(Deep Learning) 혁명이다.화상인식 에러율..사람 정밀도보다 낮은 수준까지 왔다.인식을 넘어운동숙달단계에 들어섰다.블럭깨기 게임은 인간보다 점수가 높다.언어.문장의 의미까지 이해하는 건시간문제다.그럼..인간 사회는 어떻게 변할까?어떤 비지니스 모델이 있을까?인공지능은 인간을 넘어설 수 있을까?지금 나는..우리는 무엇을 해야하나?일본 노벨상 25명.. 일본의 인공지능 연구수준은?그래서 도쿄대학 마쓰오 유타카교수의 <인공지능과 딥러닝>을 빼들었다.일독을 권한다.(마쓰오 유타카교수의 '인공지능과 딥러닝'을 읽고) "
" ■ 사람처럼 생각하는 컴퓨터의 등장영화 속에서나 나올 법한 이야기를 현실로 만들어주는 발명 기술이 있습니다. 인공지능(AI)의 핵심 발명기술인 딥러닝(Deep Learning)인데요. 딥러닝을 간단하게 설명하자면 컴퓨터가 사람처럼 생각하고 배울 수 있도록 하는 인공지능의 기술을 말합니다. 출처: 영화 <그녀>의 한 장면 ■ 고양이와 개의 구분, 기계학습사람들은 고양이와 개를 직관적으로 구분할 수 있는 능력이 있죠. 하지만 컴퓨터는 사진만을 놓고는 고양이와 개를 구분하지 못합니다. 이를 위해 기계학습(Machine Learning)이 발명되는데요. 방대한 양의 데이터를 컴퓨터에 입력해주면 비슷한 것들끼리 분류해서 고양이와 개를 판독하도록 훈련하는 것이죠. 컴퓨터가 스스로 훈련을 하면서 패턴을 찾아내 분류하는 기술방식을 머신러닝(Machine Learning), 기계학습이라고 합니다. ■ 딥러닝(Deep Learning)딥러닝은 기계학습의 한 발명분야로 분류됩니다. 다양한 상황에 대해 프로그램이 비슷한 판단을 내릴 수 있도록 하는 것이 딥러닝(Deep Learning)입니다. 앞서 말씀드렸다시피 컴퓨터가 사람처럼 생각하고 배울 수 있도록 하는 인공지능의 기술을 말합니다. ■ 딥러닝의 양 갈래_ 지도 학습(Supervised Learning) 딥러닝의 핵심은 분류를 통한 예측입니다. 수많은 데이터 속에서 패턴을 발견해 인간이 사물을 구분하듯 컴퓨터가 데이터를 나누는데요. 이 같은 분별 방식은 두 가지로 나뉩니다. 먼저, 지도 학습 방식은 컴퓨터에 먼저 정보를 가르치는 방법입니다. 예를 들어 사진을 주고 “이 사진은 고양이”라고 알려주는 식이죠. 컴퓨터는 미리 학습된 결과를 바탕으로 고양이 사진을 구분하게 됩니다. 학습 데이터가 적으면 오류가 커지므로 데이터의 양은 충분해야 합니다. ■ 딥러닝의 양 갈래_ 비지도 학습(Unsupervised Learning) 비지도 학습은 배움의 과정이 없습니다. “이 사진이 고양이”라는 배움의 과정 없이 “이 사진이 고양이군”이라고 컴퓨터가 스스로 학습하게 되죠. 지도 학습과 비교해 진보한 기술이며, 컴퓨터의 높은 연산 능력이 요구됩니다. ■ 딥러닝 발명 사례_ 딥페이스(Deep Face)딥러닝은 데이터 양 자체가 풍부하고, 높은 확률적 정확성이 요구되는 분야에서 활발하게 연구되고 있습니다. 대표적인 발명사례로 페이스북의 ‘딥페이스’기술(2014년 3월)이 있는데요. 친구의 사진을 올렸을 때 자동으로 얼굴을 인식해 태그를 달아주는 얼굴 인식 알고리즘을 딥페이스라고 합니다. 인식 정확도는 97.25%로 인간 눈 인식 정확도인 97.53%와 거의 차이가 없을 정도라고 하네요. ■ 딥러닝 발명 사례_ 딥드림(Deep Dream)딥러닝은 예술 분야에서도 적용됩니다. 바로 구글의 딥드림(Deep Dream)이 그 예인데요.딥드림은 알파고를 탄생시킨 ‘딥러닝’ 기술을 시각 이미지에 적용한 것이 특징입니다. 빈센트 반 고흐 등 유명 화가의 화풍을 학습시켜 어떤 장면이든 몽환적인 추상화로 만들어주죠. 실제로 딥드림 홈페이지(deepdreamgenerator.com)에 사진을 올리면 딥러닝이 재해석해 그려낸 작품을 직접 만날 수도 있습니다. 이밖에도 딥러닝의 적용 분야는 무궁무진합니다. 음성인식∙번역 분야, 자율주행 자동차 분야에서도 보행자감지∙교통신호와 표지판 등을 인식하는 데 이용할 수 있다고 하는데요. 앞으로도 딥러닝 분야의 발명은 계속해서 이루어질 것 같습니다. "
" 딥러닝 매크로 투자전략 작가 김선태, 조남기 출판 한나래플러스 발매 2016.10.31. 평점 리뷰보기 <딥러닝 매크로 투자전략>두줄요약 “거시경제 지표 분석을 통한 투자전략 수립을 위한 핵심서”""먹이를 주는 책이 아니라 잡는 방법을 가르쳐주는 책""최근 들어서 많은 양질의 책이 나오는 거 같아 정해져 있는 주머니 사정 속에서 과감하게 선택한 책이 바로 오늘 소개할 <딥러닝 매크로 투자전략>이다.솔직히 개별 기업 분석을 통해 주식 투자를 하는 방식이 가장 간단하고 고려할 요소가 적은 '심플한' 투자 방법이라고 생각한다. 하지만, 여기는 바로 대한민국이다. 아무래도 소규모에 수출 비중이 절대적인 나라이다 보니 거시 경제지표를 파악하지 않고서는 좋은 성과를 내기가 녹록치 않다. 과거 기업 분석만으로 주식 투자에 성공한 많은 분들이 있지만 갈수록 한국 경제와 금융시장이 고도화 되면서 소위 '담배꽁초식' 투자가 쉽지 않다. 아마 갈수록 거시경제 지표 분석이 '필요'가 아니라 '필수'의 영역으로 갈 듯하다. (그런 점에서 홍춘욱 박사님처럼 제도권에서 분석해주는 분은 물론이고, 봄날의 곰님 처럼 거시 경제 데이터를 공개해주시는 분의 가치는 매우 소중하다 생각한다)무궁무진하고 확고한 데이터를 갖춘 미국은 정말 쉴새없이 데이터들이 쏟아지고 그것을 분석하는 이가 상당하다. 그리하여 세계 경제지표의 비밀 작가 버나드 보몰 출판 럭스미디어 발매 2010.02.25. 평점 리뷰보기 월스트리트저널 경제지표 50 작가 사이먼 컨스터블, 로버트 라이트 출판 위츠 발매 2012.06.28. 평점 리뷰보기 경제를 읽는 기술 작가 조지프 엘리스 출판 리더스북 발매 2007.03.15. 평점 리뷰보기 같은 책들이 쏟아지고 이러한 책들은 실제로 거시경제를 파악하고 분석하는데 큰 도움이 된다. 하지만 아쉽게도 국내에서는 경제 지표를 분석을 위한 '안내서'가 크게 눈에 띄지 않았다. '쉽게 배우는' 시리즈나 간단한 수준에서의 경제지표를 소개하는 책들이라 성에 차지 않았는데, 이번 <딥러닝 매크로 투자 전략>은 매우 만족스러운 책이였다.1부는 [경제지표와 익숙해지기]를 통해 '왜' 경제지표를 이해하고 해석하는 것이 중요한지에 대해 잘 설명하고 있다.2부는 [경제지표 사용하기]로 본격적으로 소비/투자/정부지출/대외거래로 나누어 설명하고 있다.각각의 지수의 의미를 설명하고 주식과 채권투자에서 어떻게 활용하며, 언제 어디서, 어느 시기에 발표되는지도 상세하게 설명이 나와있다.﻿뒤이어, 경기 및 산업생산/고용/물가/통화량과 금융위험을 파악할 수 있는 지표들을 설명하여, 보통의 투자자가 국내에서 구할 수 있는 거의 대다수 지표 분석을 정리해두고 있다.3부는 [경제지표와 투자전략]으로 각각의 지표를 적극적으로 투자전략과 연결하여 설명하고 있다. 흔히들 알고 있는 지표부터 미국의 '신업생산 증가율+물가' 분석을 통한 금리 상승 예측까지 총 40개의 투자전략을 설명하고 있다.보통 서평과 함께 책 내용을 정리하는 편인데, 이 책 자체가 군더더기 없이 철저하게 설명과 실전 적용을 위해 쓰여진 책이라 내용을 따로 정리할 필요가 없다. 책의 저자도 책 뒤편에 밝혔듯이 한번 읽고 말 책이 아니라 필요할 때마다 꾸준히 확인하고 직접 자료를 찾아보며 몸으로 습득하는데 도움이 될 책이라고 생각한다. "
" 밑바닥부터 시작하는 딥러닝 작가 사이토 고키 출판 한빛미디어 발매 2017.01.03. 평점 리뷰보기 이런 책이 진작 나왔다면 내가 머신러닝 공부하는데 장벽을 좀 덜 느꼈을텐데 말이다.왜 2017년에서야 나온거냐.일단 책 내용은 요즘 굉장히 핫한 뉴럴넷, 딥러닝을 파이썬으로 구현해 보면서 익히는 것이고,책 제목대로 초짜들도 따라하면서 뉴럴넷의 원리와 필요한 지식들을 배울 수 있게 구성되어 있다.뭐 그래도 calculus, linear algebra 정도는 머릿속에 배경지식을 깔고 들어가야 하고,애초에 머신러닝 분야가 통계나 수학적인 백그라운드 없으면 쉽게 할 수 없으니까그정도는 공부하고 읽는것을 추천한다.근데 난 이 내용 석사때 분명 배우긴 배웠고, matlab으로 구현까지 했던 기억이 있는데하도 손을 놔서 그런지 다 까묵어서 리마인드하는 용도로 보고 있기는 하다.그런 용도로도 괜찮은 책인것도 같고. "
" 딥페이스페이스북이 개발하고, 2014년 발표한 인공지능 알고리즘. 사진 속 얼굴을 분석해 같은 사람을 연결해 준다.- 페이스북 사용자들이 새 사진을 업로드할 때, 이를 식별하여 자동 태깅 기능을 구현하는 원천 기술.- 가상으로 얼굴을 회전시킨 3D 모델을 통해 카메라 속 얼굴을 유추해 내는 딥러닝 기법 적용. - 정확도는 97.25%로, 인간의 97.53%와 비슷. 딥러닝 사람의 신경망을 참조해서 만든 스스로 생각하고, 학습하는 데이터 분석 기술. - 신경망에는 여러 개의 층(layer)가 있기 때문에 서로 다른 추상도에서 데이터를 분석할 수 있으며, 데이터 사이의 중요도를 판단할 수 있다.- 초기의 AI는 1950년대 개발된 단층(single layer) 알고리즘을 적용했으나, 70년대 다중(multiple layer) 등장으로 다양한 상황, 예측하지 못했던 조건에서도 최적화 판단이 가능하게 되었다.- AI의 현실적 적용을 위해서는, '설명 가능한 인공지능(Explainable Artifical Intelligence)'이 필요하다. AI가 왜 그런 판단을 했는지에 대한 구체적인 정보를 제공하는 것. 미군은 이미 레이더가 비행기나 미사일을 자동적으로 관측한 뒤 위협으로 판단한 이유를 설명하는 기술을 연구하고 있다. 인간은 분석 결과를 검토하고 최종명령만 내리면 된다. "
" 딥러닝이란 ?Machine Learning 기법 중 하나 머신러닝이란 ?""Machine Learning"" 책을 지은 CMU의 교수 Tom M. Mitchell이 제시한 것이다.""A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E""즉, 어떠한 테스크(T)에 대해 꾸준한 경험(E)을 통하여 그 T에 대한 성능(P)를 높이는 것, 이것이 기계학습이라고 할 수 있다.정의에서 알 수 있듯이, 기계학습에서 가장 중요한 것은 E에 해당하는 데이터이다. 좋은 품질의 데이터를 많이 가지고 있다면 보다 높은 성능을 끌어낼 수 있다. Artificial Neural Network(ANN; 인공신경망)딥러닝의 대표적이면서 가장 처음 시작하는 MNIST 예제는 ANN 을 기초로 두고 있다.ANN 이란?입력과 출력 사이에 있는 인공 뉴런들을 여러개 층층히 쌓고 연결한 인공신경망 기법을 주로 다루는 연구 인간의 시각/청각 피질을 본따 만든 알고리즘이다.다만 인간의 뇌에서 모티브를 얻었다는 정도. (뇌과학자들이 화낸다)그밖의 머신러닝 알고리즘들k-NN: 두 점의 중점을 토대로 정확도 계산SVM: Vector 를 사용한 정확도 계산 좀 더 쉽게XOR GateINPUT, OUTPUT 흐름상 논리회로와 매우 닮았다. 신경망 = 미세먼지 필터?(너무 복잡해...) 뉴런과 시냅스신경망인간의 신경망은 수천만개에서 억단위까지.현재 구현되어 있는 신경망은 수천개가 고작. 연산이 너무 많다.연산이 너무 많기 때문에 하드웨어까지 영끌해야 한다. (영혼까지 끌어모으기)행렬 연산이 크기 때문에 GPGPU 를 사용. (행렬연산에 강력한 GPU의 특성)예) 알파고: 1920개의 CPU와 280개의 GPU를 사용 이미지를 보고 무슨 숫자인지 맞추기두괄식으로 ... 결과보기이미지 찾기: 4 이미지 찾기: 5 이미지 찾기: 0 어떻게 가능할까?신경망을 통한 방식.# x = [x1, x2] # w1 = [[0.12, 0.32, 0.14], [0.1, 0.54, 0.23]] # b1 = [0.1, 0.2, 0.3] A1 = 행렬_내적(x, w1) + b1 # A1 = [a11, a12, a13] # w2 = [[0.12, 0.32], [0.1, 0.54]] # b2 = [0.1, 0.2] A2 = 행렬_내적(A1, w2) + b2 # A2 = [a21, a22] # w3 = [[0.14, 0.02], [0.02, 0.14]] # b3 = [0.11, 0.12] A3 = 행렬_내적(A2, w3) + b3 행렬의 곱 (내적) 이 한 level 혹은 한 시냅스 역할근데 ... 어떻게 행렬 연산(내적)만으로 먼지를 여과(?)할 수 있는가?-> 이거 저거 다 갖다 붙이다 보면 근접한 수치가 나온다?나무위키 왈그냥 주먹구구식으로 이것저것 함수를 대입해 보면서 가장 결과가 좋은 함수를 사용하는 중이다. 신경망의 역할은 ?경사 하강법 (gradient descent): 근사치를 찾아서 간단한 수식으로 바꾸는 부분 예제 코드Tensorflow 의 MNIST 예제를 사용.network 파라미터가 먼지 필터 역할을 한다.************-> 좋은 먼지 필터를 사용하면 정확도가 올라가고,나쁜 필터를 사용하면 정확도가 떨어진다.def predict(network, x): W1, W2, W3 = network['W1'], network['W2'], network['W3'] b1, b2 ,b3 = network['b1'], network['b2'], network['b3'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) # 가지치기. -> sigmoid 는 데이터의 짤림 현상이 많아서 ReLU 방식을 많이 사용한다고 함.. a2 = np.dot(z1, W2) + b2 z2 = sigmoid(a2) # 가지치기. a3 = np.dot(z2, W3) + b3 y = softmax(a3) # [2, 4, 4] - softmax -> [0.2, 0.4, 0,4] ; 총합을 1로 계산.. return y y = predict(network, img) p = np.argmax(y) print(""Image will be "" + str(p)) 자세한 내용:https://www.tensorflow.org/get_started/mnist/beginners 장점이 가장 큰 단점경사하강법의 빈약함대부분의 딥 러닝 알고리즘은 경사 하강법에 기초를 두고 있다.그런데 경사 하강법 자체는 이론적으로 이해가 잘 되었지만, 이와 함께 사용하는 다른 알고리즘은 이론적인 검증이 빈약하다....이와 같이, 딥 러닝에 사용되는 방법들은 이론적이기 보다는 경험적으로 검증된 방법들을 사용하기 때문에 종종 블랙박스로 이해되기도 한다. 참고http://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198https://ko.wikipedia.org/wiki/딥_러닝https://namu.wiki/w/기계학습https://alykhantejani.github.io/a-brief-introduction-to-gradient-descent/http://creativeprm.tistory.com/82http://playground.tensorflow.org/ "
" 인공지능 레벨1. 가전제품을 이용한 단순 제어 프로그램2. 장기나 청소로봇 같은 다채로운 프로그램3. 빅데이터를 이용한 프로그램4. 기계학습, 딥러닝을 이용한 프로그램제1차 AI 붐 추론, 탐색의 시대제2차 AI 붐 지식의 시대제3차 AI 붐 기계학습, 특징 표현 학습미로 풀기 -> 막다른 길에 다다르면 전의 코너에서 이동히노이의 탑 -> 작은 원반 위 큰 원반을 올릴 수 없다.(원반마다 가중치나 순위를 매겨 정하면 될듯)체스 -> 최소 최대 법 (2수 앞 예측)1. 경우의 수를 수치로 표현2. 경우의 수의 수치가 최소인 것 선택3. 최소중 가장 나은 것 선택몬테 카를로법 -> 수의 계산을 포기하고 랜덤으로 둔다사야 프로젝트 -> 노드를 이용해 관계 표시추이율 성립 -> 1<3, 3<7, 1<7 (O)(is-a) -> 가위<바위, 바위<보, 보<가위 (X)헤비 웨이트 온톨로지 -> 지식을 기술 방법, 인간이 직접 개입라이트 웨이트 온톨로지 -> 지식을 기술 방법, 컴퓨터가 자동으로심볼 그라운딩 문제 -> 볼과 그것을 의미하는 것이 결부프레임 문제로봇, 동굴, 배터리, 시한폭탄로봇 1: 동굴에서 배터리를 가져옴 (시한폭탄도 같이 가져옴)로봇 2: 부차적으로 일어나는 것도 고려 (동굴에서 생각하다 터짐)로봇 3: 관계없는 사항은 고려 않도록 (동굴에도 못 들어감)기계학습(학습하다->분류하다)1. 지도학습-> 입력화 출력2. 비지도학습 -> 데이터만 입력 (패턴을 추출)1. 최근접 이웃 방법->가장 가까운 이웃의 분류에 따른다.단점: 정치 카테고리에 문화가 섞이면 오버 피팅 결과2. 나이브 베이즈 법->베이즈의 정리 사용(단어가 포함되는 확률로 카테고리별 점수를 매겨 분류)3. 결정 트리->판단 기준으로 O, X를 이용해 판별단점: 복잡한 문제에서 정밀도가 높지 않다.4. 서포트 벡터 머신->데이터를 구분 짓는 구분선과 그룹 간의 간격을 최대로 나눈다.장/단점: 정밀도가 높다. 큰 데이터는 오래 걸린다.5. 뉴럴 네트워크->인간의 뇌신경을 흉내 임계값 기준으로 신호 발화 1, 아니면 0오차역 전파 (가중치의 조정을 되풀이하고 인식의 정밀도 상승)->전체의 오차가 작게 기울기 값을 잡는다. 가중치를 이용해 오차를 잡는다.기계학습의 문제->무엇을 특징으로 할지 인간이 정하지 않으면 안 된다.인공지능의 문제(특징을 꺼내 개념[시니피어]와 이름[시니피앙]을 주면 된다)->개념을 스스로 획득할 수 없었다.딥러닝 <-심층학습->데이터를 바탕으로 스스로 특징을 만들어 낸다.계층을 포개어 탐구하다->상관이 있는 것을 한 묶음으로 해서 특징을 꺼내고, 그것을 이용해서 더 높은 차원의 특징을 꺼낸다.사용 개념1. 오토인코더 입력층 ↔ 은닉층 ↔ 출력층2. 은닉층을 다음 레이어로 은닉층 ↔ 입력층 은닉층 ↔ 출력층3.입력층 = 출력층 은닉층 ↔ 입력층 (같으므로 출력층 제거)4. 임계층 생성 은닉층 3층 ↔ 은닉층 2층 ↔ 은닉층 1층 ↔ 입력층(※은닉층은 다음 측의 입력층이 됨) (은닉층 3층의 입력층) (은닉층 2층의 입력층)﻿손 글씨, 지문 인식 등 (대표적으로 구글의 고양이 인식) 딥러닝에서의 기술 진전① 이미지 특징의 추상화② 멀티 모달한 추상화 (사진과 같은 이미지뿐만 아니라 동영상, 소리, 냄새까지도 인지 가능한)③ 행동 결과의 추상화 (행동에 대한 결과를 생각 가능, 행동의 계획이 세워짐)④ 일련의 행동을 통해 현실세계에서의 특징 추출⑤ 언어와 개념의 그라운딩⑥ 언어를 통해서 지식 획득싱귤래리터 ->인공지능의 자신의 능력을 넘는 인공지능을 스스로 만들어 낼 수 있는 시점 "
" 공지본 강의의 2016년 버전을 완결하였습니다.2017년에는 논문을 쓰면서 간간히 다듬을 예정입니다.CNN 부분은 전체를 다루기엔 분량이 방대해서 핵심 개념과 예제 코드만 다루었습니다. 인터넷이나 다른 자료들로 계속 공부해나가시기에는 불편함이 없으실겁니다.강화학습 부분은 자율주행차 예제 때문에 그래픽스 코드가 조금 복잡합니다.가상환경에서 AI 훈련시키는 것이 장기적인 트렌드가 될 것 같아서약간 무리하면서 넣었습니다.피드백이나 질문 주시면 능력껏 도와드리겠습니다.한창 발전해나가는 분야를 공부하면서 정리하려니 정신이 없기도 했지만많은 분들이 봐주셔서 즐겁게 만들 수 있었습니다.모든 것이 변하는 시기에 많은 분들에게 도움이 되었으면 합니다.감사합니다.2016년 12월 13일홍정모 드림질문은 환영합니다! 다만, 질문이 생겨난 강의 자료에 '공개 댓글'로 적어주세요.쪽지나 이메일 등 비공개 질문은 답해드리지 않습니다.http://blog.naver.com/atelierjpro/220850594302공개 프로젝트 참가자 모집 - 인공지능 작곡http://blog.naver.com/atelierjpro/220797959020C++로 배우는 딥러닝1. 인공 지능과 신경망 AI and Neural Networkhttp://blog.naver.com/atelierjpro/2206978988762. 인공 뉴런의 작동 원리 How Artificial Neurons Workhttp://blog.naver.com/atelierjpro/2206979010743. 뉴런 하나의 Feed-forward 구현하기 (C/C++)* 초보자를 위한 C 스타일 구현 영상이 추가되었습니다.http://blog.naver.com/atelierjpro/2206979025024. 뉴런 하나 학습 시키기http://blog.naver.com/atelierjpro/2207030538614.1 프로그래머를 위한 미분 강의http://blog.naver.com/atelierjpro/2207173951654.2 수치 미분http://blog.naver.com/atelierjpro/2207224438674.3 경사 하강법gradient descent methodhttp://blog.naver.com/atelierjpro/2207558731104.4 연쇄 미분chain rulehttp://blog.naver.com/atelierjpro/2207606598255. 뉴런 하나의 Back-propagation 구현하기 (C++)https://youtu.be/XmK9f5IV8Uw6. Fully Connected Neural Networkhttp://blog.naver.com/atelierjpro/2207732763847. Implementing FCNN (C++)http://blog.naver.com/atelierjpro/2207749882428-1. Convolutional Neural Networkhttp://blog.naver.com/atelierjpro/2208823261438-2. Implementing CNN (C++)http://blog.naver.com/atelierjpro/2208823364279. Reinforcement Learning9-1. Q Learninghttp://blog.naver.com/atelierjpro/2208671543729-2. 강화학습 Reinforcement learning and Deep Q Learninghttp://blog.naver.com/atelierjpro/2208785962119-3. 딥러닝 9.3 자율 주행차 강화학습 예제http://blog.naver.com/atelierjpro/2208785983379-Old. 강화학습으로 게임하는 인공지능 만들기 http://blog.naver.com/atelierjpro/220714677259이어질 주제들작곡하는 인공지능 만들기 (http://blog.naver.com/atelierjpro/220699674736)인공지능 (뉴럴 네트워크) 베토벤 월광소나타 훈련시키기 (http://blog.naver.com/atelierjpro/220851418829)연관 강의DGU CSE 기초 프로그래밍 Week 10이미지 컨벌루션 (Image Convolution)Week 9의 디지털 이미지를 먼저 보시는 것을 권장합니다.http://blog.naver.com/atelierjpro/220705481805DGU CSE 기초 프로그래밍 Week 11게임프로그래밍 1http://blog.naver.com/atelierjpro/220712482761DGU CSE 기초 프로그래밍 Week 12게임프로그래밍 2http://blog.naver.com/atelierjpro/220718413290DGU CSE 기초 프로그래밍 Week 15머신러닝machine learning, 선형회귀linear regression, stochastic gradient descenthttp://blog.naver.com/atelierjpro/220736961136Python 구현 by 이찬형https://github.com/babjo/py-deep-learningJulia 구현 by 이기환https://github.com/mohawkduck/perceptron-jl관련 도서 서평딥러닝 제대로 시작하기 http://blog.naver.com/atelierjpro/220863683562마스터 알고리즘 http://blog.naver.com/atelierjpro/220770415745 "
" 세계 최초의 Deep Learning 전용 슈퍼컴퓨터인 ‘NVIDIA DGX-1’은 딥 러닝을 위해 특별히 제작된 최초의 시스템이다.​​ 250대의 x86 서버를 합친 딥러닝 처리량으로 Training 시간을 혁신적으로 줄일 수 있는 DGX-1은 Hardware, Deep Learning Software, 개발자 툴 등이 통합되어 있는 시스템이다. 즉, 최적화된 딥러닝 Software의 세트를 제공함으로써 빠르고 쉽게 Deep Neural Network을 Training할 수 있도록 돕는다.​​ FP32(반정밀도)에서 최대 170TFlops의 성능을 지는 DGX-1은 아래의 사양을 갖추었으며 지정 SI 업체에서 2016년 3분기부터 판매 예정이다. 8개의 TESLA P100, 16GB memory for each GPUNVLink Hybrid Cube Mesh7TB SSD DL CacheDual 10GbE, Quad InfiniBand 100Gb networking3U-3200W ​ DGX-1 Software는 DNNs(딥뉴럴 네트워크) 디자인과 제작을 위한DIGITSTM (NVIDIA Deep Learning GPU Training System)와 GPU 가속 라이브러리인 CuDNN(NVIDIA CUDA Deep Neural Network Library) version 5를 포함한다. 또한 구글의 TensorFlow, UC버클리의 Caffe, 몬트리올 대학의 Theano, 뉴욕 대학의 Torch 등의 다양한 딥 러닝 프레임워크의 최적화된 버전을 포함하는 것은 물론, 추가적으로 클라우드 관리 도구와 소프트웨어 업데이트 및 컨테이너화된 Application 저장소로 접근 권한을 제공한다. ​ https://www.youtube.com/watch?v=1ayGJDO6PKU&index=1&list=PL3ZQ5CpNulQmrjpGZ1xsGtCa8fkOi6pGL "
" 2012년 6월 시작 천권 읽기 576권)인공지능과 딥러닝 (인공지능이 불러올 산업 구조의 변화와 혁신) 마쓰오 유타카 저. *인상적인 구절: 이것은 예를 들어 번역을 생각할 때에 문법 구조나 의미 구조를 생각하지 않고, 단지 기계적으로 번역되는 확률이 높은 것을 적용시켜 나가면 된다라는 사고방식이다. 즉, 기존의 언어학에서 연구되어 온 문법에 관한 지식이나 문장이 전하려는 의미를 정확히 파악해서 번역하는 것이 아니고, 대역 코퍼스corpus라는 두 가지의 언어가 양쪽으로 기재된 대량의 텍스트 데이터를 학습하여, ‘영어로 이러한 단어의 경우는 일본어의 이 단어로 번역되는 확률이 높다’, ‘영어로 이러한 문구의 경우는 일본어의 이러한 문구로 번역될 경우가 많다’라고 단순하게 적용시켜 가는 것이다. 이렇게 해서 종래의 추론이나 지식 표현과 다소 다른 분야에서 기존의 데이터를 확률적 또는 통계적으로 분석하여, 이것을 활용하는 연구로서 기계학습의 연구가 진행되고 있었다. 구글은 그야말로 이 통계적 자연어처리의 화신 같은 기업이며 창업으로부터 10년이 지나자 급성장을 이루었다. 구글이 10만 달러(약1억 원)의 자금으로 창업한 것이 1998년인데 2004년에 상장했을 당시의 시가 총액은 230억 달러(약2,300억 원), 그 후 10년이 지난 2014년에는 3,500억 달러(약 35조 원)가 되어 시가 총액으로 토요타 자동차의 2,000억 달러(약 20조 원)를 크게 상회한다. "
" #0.0. 딥러닝 토크를 시작합니다 https://youtu.be/D4zqigCb8co#0.1. 머신러닝, 그 느낌적인 느낌 https://youtu.be/enYafK38MfI#0.2. 머신러닝 / 딥러닝 강의 7가지 추천 https://youtu.be/LBexv9M-SBc#0.3. SNS로 딥러닝 소식 팔로우 하는 법 (1/2) https://youtu.be/Z1OdPpq9w0o#0.4. SNS로 딥러닝 소식 팔로우 하는 법 (2/2) https://youtu.be/w1oQQmu8NKo#1.0. 오버피팅(Overfitting): 누구나 처하게 될 문제 https://youtu.be/C5gZRGe8ze0#1.1. Training / Test / Validation Set : 오버피팅을 피하는 방법 https://youtu.be/GtLe9Z2No28#1.2. 에러 해부학: Bias-Variance Trade-off https://youtu.be/FOu8bXV15F8#1.3. Ng교수의 교훈: 데이터셋만 잘 나눠도 https://youtu.be/AK60jzjDvlg#2.0. 머신러닝의 종류 - 개요 https://youtu.be/KSGldBhKf4E#2.1. 머신러닝의 종류 - Supervised Learning https://youtu.be/enHDA9JBlOI#2.2. 머신러닝의 종류 - Unsupervised Learning https://youtu.be/-PC3VVOImjw#2.3. 딥러닝과 머신러닝의 관계 https://youtu.be/mH3w-OmHQK0#2.4. 딥러닝은 피쳐러닝이다 https://youtu.be/P2TnPEbNmLk#2.5. 가깝다, 멀다 - Distance / Metric의 개념 https://youtu.be/4KXgdf6Bmo4#2.6. Accuracy, Precision, Recall https://youtu.be/1jboC7nWnfM#3.0. 딥러닝을 위한 하드웨어 구성하기 https://youtu.be/9BvujfW5XlI#S.0. 딥러닝 논문리스트로 레딧 1위한 썰, 뒷이야기 https://youtu.be/wZXwBVlmfXA#S.1. 꼭 딥러닝을 써야하나요? https://youtu.be/MSWCQ9lRA1Y#S.2. 딥러닝 핫 키워드의 변화 https://youtu.be/qB5Qum1FNAQ#P.0. Domain-Adversarial Neural Network (2014) https://youtu.be/h8tXDbywcdQ#P.1. Deformable Convolutional Networks (2017) https://youtu.be/RRwaz0fBQ0Y "
" 딥러닝 코드 모음: http://deeplearning.net/software_links/-> 코드들 말고도 읽기자료, 데모 등도 잘 소개되어 있으니 딥러닝을 공부하며 종종 참고하기에 좋다. MatLab을 통한 딥러닝 입문: https://github.com/rasmusbergpalm/DeepLearnToolboxrasmusbergpalm/DeepLearnToolboxDeepLearnToolbox - Matlab/Octave toolbox for deep learning. Includes Deep Belief Nets, Stacked Autoencoders, Convolutional N...github.com->Matlab은 언어도 쉽고 변수값을 확인하기도 쉬우며 관련 코드들도 많이 존재, Matlab 자료 중에는 간단한 Neural Network부터 Deep belief network까지 다양한 알고리즘이 존재​​Matlab을 통한 Convolutional Neural Network(CNN) 공부: 튜토리얼: http://www.robots.ox.ac.uk/~vgg/practicals/cnn/ 코드: https://github.com/vedaldi/practical-cnnvedaldi/practical-cnnpractical-cnn - A VGG practical on convolutional neural networksgithub.com​​=> 인공지능도 오픈소스와 다양한 튜토리얼이 있으니 관심이 있으면 공부할 수 있다. 컴퓨터공학과인 나로써는 노력의 문제이지 항상 자료는 넘쳐나니 항상 부딪쳐보는게 중요하다고 생각한다.글로만 보는 어려운 알고리즘 CNN, NEURAL 등등을 실전을 통해서 한층 더 이해하기 쉬울 것이다!!!​​​​ "
" ai기술의 진보는 딥러닝과 빅데이터에 있다. 바둑 역사 반만년 동안 절대 컴퓨터가 인간을 이길 수 없다는 불문율이 깨진 것도 딥러닝 기술이 바둑 ai에 응용되었기 때문이다. 전통적인 바둑 ai는 몬테카를로 기반의 수읽기와 확률 알고리즘이었다. 여기에 딥러닝과 빅데이터가 결합되어 폭팔적인 진보를 했고 마침내 인간을 넘어섰다. 딥러닝이 뭔지 설명은 패스하겠다. 딥러닝이 ai 폭팔적인 성장세를 가져온 이유는 단일 체계에서 인간의 사고방식과 딥러닝 알고리즘이 별 차이 없기 때문이다. 인간이 직관적으로 판단하는 직관능력이 사고 매카니즘에 있어 연산과 구별되는 인간 고유의 능력으로 알려져 있었는데 최근 연구를 통해서 컴퓨터도 인간의 직관능력을 모방할 수 있다는 게 증명되었다. 그 성과물이 딥러닝이고 딥러닝과 결합된 ai는 무서운 속도로 발전하고 있다. (경각심을 가질 필요가 있다) 이를테면, 우리는 개와 고양이를 ""직관적으로"" 구분하고 목소리만 듣고 누구의 목소리인지 금방 알 수 있다. 그런데 딥러닝이 응용되지 않았던 시절 컴퓨터는 그런 직관능력이 없었기 때문에 개와 고양이의 구분하는데 애를 먹었다. 프로그래머가 일일히 개와 고양이의 조건을 입력하고 개의 조건에 맞으면 개가 되고 고양이의 조건에 맞으면 고양이가 되는 조건 방정식이 기존 ai의 인식 알고리즘이었다. 그런데 딥러닝은 개와 고양이의 수만개의 데이터를 펼쳐놓고 유사성과 차이점을 스스로 알아가는 학습 알고리즘이다. 즉, 우리가 쌍둥이를 처음 볼 때는 누가 누구인지 모르나 계속 반복해서 보다보면 미세한 특징들로 구분해낼 수 있듯이 컴퓨터도 반복해서 보여주고 스스로 구분해서 이것은 개고 저것은 고양이로 각인한다는 말이다. 어른은 쉽게 개와 고양이를 구분하는데 아이들은 생김세가 유사한 개와 고양이를 잘 모른다. 월래부터 인간에게 개와 고양이를 구분하는 특별한 직관이 있었던게 아니라 시각적인 반복 학습에 의해서 생겨난 체계다. 시각 뿐만 아니라 우리의 지식 체계도 엄밀히 말해서 반복학습이 길려낸 인식의 구조물이다. 가령 꽃은 아름답다, 착한 일은 옳다, 뱀은 징그럽다, 등등 매우 기초적인 판단에서조차 우리에게 월래부터 주어진 것은 없다. 문화와 환경, 규범의 영향으로 그런 판단과 인식을 가지게 된 것이다. 그래서 인간은 체계의 산물이다. 그리고 체계는 선험적으로 주어진 게 아니라, 환경, 문화, 자연, 유전자 등등 여러 맥락이 관계하고 연동해서 네트워크처럼 얽혀 있는 생태계다. 말하자면 우리의 사고방식과 가치관, 행동양식은 그 생태계 속에서 자라난 것이고 ai를 여기에 뿌려놓으면 우리와 똑같이 생각하고 행동하는 양상으로 길들어질 수 있다. 한마디로 빅데이터와 딥러닝의 결합은 아이가 사회 속에서 지식을 습득해 나가듯이 어떤 체계 안에서 그 체계를 ""모방""하는 지성을 창조한다. 예전 프랑스 철학자들이 앞서 이 개념을 시뮬라르크가 어쩌고 저쩌고 했던 것 같은데 지금 ai는 그 수준까지 와 있다. 우리의 감성은 선험적이다. 나는 존재한다 고로 생각한다.. 이건 뭐 빼도 박도 못하는 절대 인식이다. 의식과 자아는 매우 신비로운 우주현상이기 때문에 ai를 그런 의식을 가진 존재로 이해하긴 매우 이르다. (먼 미래에는 그것을 심각하게 고민해야 하는 때가 올 것이다) 그러나 ""사고""는 신비로운 우주현상이 아니다. 사고는 연산과 직관의 매카니즘이고 체계와 연동하면서 연산과 직관으로 체계를 모사하고 내재화하는 작용이다. 컴퓨터가 충분히 구현할 수 있는 세계고 이 영역에선 인간보다 컴퓨터가 더 뛰어날 수 있다. 일본에선 소설을 쓰는 ai를 개발하고 있다고 한다. 상식으로는 불가능한 것 같지만 논리적으로 충분히 가능한 얘기다. ai가 노벨상을 탈 수 있다. 만약 소설을 쓰는 ai가 등장한다면 인간이 ""사고""로 할 수 있는 일 99%를 ai가 할 수 있다. 기본적으로 인간의 언어도 체계의 유산이다. 문화가 다른 나라는 언어도 다르다. 꽃이 징그럽고 뱀이 아름답다고 생각하는 아마존 아이들도 있다. 빅데이터와 딥러닝으로 인터넷에 뿌려진 수많은 소설들을 ai가 반복적으로 학습하면 그 방대한 데이터 속에 문장과 수사를 취합하고 분류하고 군집해서 ai가 체계를 만들어낸다. 인터넷에 글들은 인간의 체계를 드러낸다. 그 체계를 ai가 닮아가는 건 당연하다. ai는 소설도 쓸 수 있다. 흄은 인간의 사고 양식은 ""습관의 산물""이라고 했다. 인간의 판단, 직관, 지식, 언어, 양식은 월래부터 정해진 규칙이 있었던게 아니라 예로부터 형성된 것들을 모방하면서 굳혀진 것들이라는 말이다. 유전자부터가 그렇다. 유전자 염기배열은 갑자기 등장한 것이 아니다. 오랫동안 대를 이어오면서 수많은 자연모방의 결과물이다. 문화와 역사도 마찬가지다. 오늘날 지식은 체계의 유산이고 체계는 모방의 산물이다. 인터넷엔 그런 인간의 체계가 있다. 빅데이터와 딥러닝으로 ai는 인간의 체계를 모방하고 내재화한다. 어떻게 알파고가 이세돌을 이겼을까? 기보 덕분이다. 수만개 수억개의 기보를 알파고는 모방하면서 바둑을 깨우쳤다. 예전에 슈퍼컴퓨터의 압도적인 연산력으로 인간에 대항했던 ai바둑 프로그램들은 처참하게 깨졌다. 그런데 기보를 보면서 유형과 패턴을 읽고 따라하니까 쉽게 승리할 수 있었던 게다. 바둑이라는 체계를 ai가 모방한 것이다. 바둑 뿐만아니라... 모든 영역에서 ai는 압도적인 실력을 발휘할 것이다. 블로그에 글 쓰는 것도 ai가 하는 시대가 온다. 왜냐하면 인간은 체계의 산물이고 ai는 체계를 복제하기에 안성맞춤의 존재이기 때문이다. 구조주의란 철학 사조가 있다. 엄청 어렵게 써 �Q는데 쉽게 인간 위에 체계(구조)가 있다는 말이고 인간은 구조를 복제한 사고기계라는 말이다. 후기구조주의 포스트모더니즘도 거의 이런 논리전개다. 언어가 어쩌고 저쩌고 무의식이 어쩌고 저쩌고 그런 수사들이 의미하는 바를 한마디로 요약하면 인간 위에 거대한 구조(체계)의 생태계가 있다는 말이다. 그 환경의 산물이 인간이다. 그런 철학에 따르면 인간과 ai는 아무런 차이가 없다. 본질적으로 약간의 인간성마저도 박탈하고 해체시켜버렸는데 무슨 차이가 있겠는가? "
" 쿠다(CUDA)의 정의는 아래와 같다. CUDA (""Compute Unified Device Architecture"", 쿠다)는 그래픽 처리 장치(GPU)에서 수행하는 (병렬 처리) 알고리즘을 C 프로그래밍 언어를 비롯한 산업 표준 언어를 사용하여 작성할 수 있도록 하는 GPGPU 기술이다. CUDA는 엔비디아가 개발해오고 있으며 이 아키텍처를 사용하려면 엔비디아 GPU와 특별한 스트림 처리 드라이버가 필요하다. CUDA는 G8X GPU로 구성된 지포스 8 시리즈급 이상에서 동작한다. CUDA 플랫폼은 컴퓨터 커널의 실행을 위해 GPU의 가상 명령 집합과 병렬 연산 요소들을 직접 접근할 수 있는 소프트웨어 계층이다.[1]쿠다는 caffe 등의 딥러닝, 머신러닝 프레임워크를 사용할 때필수적으로 install 해야하는 패키지이다. 딥 러닝에서는... 연산의 효율을 높이기 위해서 기존에 CPU 와 더불어, GPU를 사용하여 빠르게 연산하는게 요즘 추세.그래서 그런지, 머신러닝 오픈소스 라이브러리들을 보면CUDA 라이브러리가 포함된 것들이 자주 보인다.그러나 ... 해당 그래픽카드나 드라이버가 없으면?=> 머신러닝 라이브러리 사용시 오류가 발생.그럴땐 caffe 를 빌드할때 CUDA 사용 옵션을 disable하면 정상빌드된다. 아래는 xml에서 CUDNN(CUDA Deep Neural Network) 을 disable한 예이다. "
" 2월 넷째주 빅데이터/딥러닝/인공지능 트렌드를 전달해 드리오니 업무에 참조하여 주시면 감사하겠습니다.이제 ""머신러닝/인공지능(AI) 플랫폼"" ""머신러닝/딥러닝 기반의 비지니스 분석, 챗봇, 상담시스템"", ""머신러닝 기반의 IOT/제조 설비 및 장애 예측 실시간 모니터링 솔루션"", ""머신러닝 기반의 보안패턴분석 솔루션""도 저희 락플레이스 빅데이터사업부에서 컨설팅, 가이드, 구축, 활용방안을 제시해드립니다...[빅데이터/인공지능 트렌드 및 소식][4차산업혁명 키워야할 신산업은]전기·자율차-AR·빅데이터와 결합시켜야http://www.etnews.com/20170216000246뛰는 보험사기, 나는 '빅데이터'로 잡는다http://www.ytn.co.kr/_ln/0102_201702190548178563'빅데이터 일자리' 막는 대못규제…젊은 인재들 ""한국 돌아가 봤자…""http://www.hankyung.com/news/app/newsview.php?aid=2017021645171빅데이터와 고객분석http://www.sedaily.com/NewsView/1OC49A4ZO4국내 ‘빅데이터’ 연구 주도할 컨트롤타워 생긴다http://www.dongascience.com/news.php?idx=16590정부, 스마트공장 1만개 구축..빅데이터 컨트롤타워 만든다http://www.edaily.co.kr/news/NewsRead.edy?SCD=JE41&newsid=02788006615830848&DCD=A00504&OutLnkChk=Y""빅데이터-인공지능 결합통해 질병예측 모델 개발할 것""http://www.kpanews.co.kr/article/show.asp?idx=181165&table=article&category=C질병 예측 인공지능의 개발…""국내도 꿈이 아니다""..병원內 환자 감시장치로 생체신호 분석…인공지능, 부정맥 85.3% 예측http://medipana.com/news/news_viewer.asp?NewsNum=195453&MainKind=A&NewsKind=5&vCount=12&vKind=1예상보다 빠른 질주...인공지능(AI)발, IT시장 격변http://www.ddaily.co.kr/news/article.html?no=152821인공지능(AI) 보험 상담 이르면 내년께 첫선..KB생명, 라이나생명 등 도입 작업 착수http://www.sedaily.com/NewsView/1OC49GKOL5""인공지능이 해커침투 막는다""…AI+보안 접목 활발http://www.mt.co.kr/view/mtview.php?type=1&no=2017021408514999792&outlink=1범죄 수사에서 사이버 보안까지…전문가 영역 넘나드는 인공지능 비서http://it.chosun.com/news/article.html?no=2830739영국 수사기관, 대형 부패 및 사기 수사에 인공지능 도입..문서 기록 검토 작업 주로 담당http://www.irobotnews.com/news/articleView.html?idxno=9865이승훈 실장 드림추신 : 빅데이터/딥러닝/인공지능 솔루션 서비스 및 컨설팅 문의처 - 락플레이스 이승훈 실장, 010-9338-6400, hunlee@rockplace.co.kr "
" Restricted Boltzmann Machine (RBM): Introduction​RBM은 graphical probabilistic model의 일종으로, undirected graph로 표현되는 모델이다. Probability는 energy function의 형태로 표현이 되는데, 원래 RBM이라는 모델 자체가 Ising model이라는 물리 분야에서 많이 사용되는 모델의 일종이기 때문에 그 형식을 그대로 본 따온 것으로 보인다. RBM의 기본적인 형태는 다음과 같다.​​​ 이 과정을 계속 반복하면 우리가 원래 원했던 hidden node와 visible node들의 joint probability를 표현하는 RBM을 learning할 수 있게 된다. RBM이 이렇게 간단하게 learning되는 이유는 restricted라는 조건이 있기 때문이다. 즉, 같은 layer들끼리는 connection이 없기 때문에 간단하게 표현되기 때문에 leanring이 간단해지는 것이다. 그렇기 때문에 restricted 되지 않은 general boltzmann machine은 RBM 처럼 마냥 간단하게 update되지 않는다.=> 기본적인 알고리즘 설명을 쭉 한번 읽어 봤는데 사실 무슨소리인지 잘 이해가 되지 않는다.. Unsupervised Learning는 딥러닝이 스스로 자신이 이해하게 하는 알고리즘일텐데 복잡하다. 이런 알고리즘이 핵심으로 있구나라고 일단은 알아놔야겠다. "
" ﻿Deep Beilf Network (DBN)DBN은 ​​ 마지막 layer는 joint probability를 의미하고, 나머지 layer들은 모두 conditional probability로 표현된다. 참고로 전체를 jointly하게 표현하는 모델을 Deep Boltzmann Machine (DBM) 이라고 하는데, 이 모델의 경우 RBM update를 하는 알고리즘과 비슷한 알고리즘으로 전체 모델을 update하게 된다. 그러나 이 논문이 발표될 당시에는 DBN이 훨씬 간단하고 computational cost가 적기 때문에 DBN이라는 모델을 제안한 것으로 보인다.이 모델이 의미있는 이유는 joint probability를 잘 표현하는 좋은 graphical model이어서가 아니라, 이 모델로 deep network를 pre-training하고 backpropagation 알고리즘을 돌렸더니 overfitting 문제가 크게 일어나지 않고 MNIST 등에서 좋은 성과를 거뒀기 때문이다. 즉, parameter initialization을 DBN의 joint probability를 maximize하는 (layer-wise로 <math xmlns=""http://www.w3.org/1998/Math/MathML""><mi>&#x2113;</mi></math>'><nobr aria-hidden=""true"">ℓ </nobr><math xmlns=""http://www.w3.org/1998/Math/MathML""><mi>ℓ</mi></math> 개의 RBM을 learning하는) 방식으로 하고 나서, 그렇게 구해진 parameter들로 deep network를 initialization하고 fine-tuning (backpropation) 을 했을 때, 항상 그 정도 size의 deep network에서 발생하던 overfitting issue가 사라지고 성능이 우수한 classifier를 얻을 수 있었기 때문이다.DBN으로 unsupervised pre-training한 deep network 모델을 사용했을 때 MNIST 데이터 셋에서 그 동안 다른 모델들로 거뒀던 성능들보다 훨씬 우수한 결과를 얻을 수 있었고, 그때부터 deep learning이라는 것이 큰 주목을 받기 시작했다. 그러나 지금은 데이터가 충분히 많을 경우 이런 방식으로 weight를 initialization하는 것 보다 random initialization의 성능이 훨씬 우수하다는 것이 알려져있기 때문에 practical한 목적으로는 거의 사용하지 않는다.=>이 방식이 도입되고 나서 딥러닝이 엄청난 주목을 받게 �榮쨉� 데이터가 많은 때에는 비효율적이라 현재에는 잘 쓰이지 않는 알고리즘이라고 한다. random initialization의 성능이 훨씬 우수하다는 것이 알려져있기 때문에 practical한 목적으로는 거의 사용하지 않는다고 한다!!! "
" 인공지능, 머신러닝/딥러닝 플랫폼, 빅데이터 플랫폼은 어떻게 제안하고 활용해야 하나?""머신러닝 기반의 비지니스분석, IOT/제조 장애예측, 보안패턴분석"" ""딥러닝 기반의 챗봇, 상담시스템"" ""딥러닝 기반의 이미지정보 판독"" 안녕하십니까? 락플레이스 이승훈 실장입니다.2017년 인공지능, 머신러닝/딥러닝 그리고 빅데이터 비즈니스를 위해 아래와 같이 빅데이터/머신러닝/딥러닝 기반의 솔루션 제안 및 활용 방안을 공유하고자 하오니 업무에 참조하시면 감사하겠습니다.[인공지능, 머신러닝/딥러닝 그리고 빅데이터 기반의 솔루션 제안 세미나] 1. 일시 : 2017년 05월 25일(목) 오후 2시부터 - 6시 2. 장소 : 서울 강남구 신사동 609 이소니프라자 5층, 한국광고연구원 세미나룸 (압구정역 2, 3번출구) 3. 발표 목차 :- 인공지능, 머신러닝/딥러닝, 빅데이터 트랜드 및 활용사례- IBM 인공지능, Watson(왓슨), 활용사례... - AI플랫폼, 스카이트리, 활용사례...- 딥러닝 기반의 영상판독 활용사례- 100% 오픈소스 하둡 플랫폼, 호튼웍스, 활용사례....- 스플렁크의 머신러닝, 활용사례..4. 참가 대상 : 인공지능, 머신러닝/딥러닝 그리고 빅데이터에 관심 있는 파트너사 및 고객사의 임직원 세미나에 참석하실분은 가급적이면 hunlee@rockplace.co.kr로 메일 주시면 감사하겠습니다. 물론 그냥 오셔도 되며, 주변의 지인이나 IT업체들, 고객분들에게도 참석을 추천부탁드립니다.보내주신 관심과 배려에 항상 감사드리오며 금주도 건강한 시간 되십시오.락플레이스 이승훈 실장 드림 비고 : 세미나 문의처 - 락플레이스 이승훈 실장, 010-9338-6400, hunlee@rockplace.co.kr주차는 가능하나 가급적 대중교통을 이용하시면 감사하겠습니다. "
" 와세다 대학의 연구진이 딥러닝(deep learning) 방법을 활용해서 흑백사진을 컬러사진으로 변환시켜주는 연구 내용을 발표했다. 커뮤니티 클리앙에서 이것저것 새 소식들을 살펴보다가 – 언제나 그렇듯이 – 제목에 이끌려 클릭을 한 후, 결과를 보고 한 번 더 놀라게 되었다. 딥러닝 기법은 항상 생각보다도 더 좋은 성능을 내고는 한다. 이번에도 예외가 아니었다.연구에서는 약 230만 개의 사진을 가지고 인공지능이 학습하도록 하였다. 그리고 흑백 및 컬러사진 쌍의 일부를 실험 참여자에게 보여준 후 사진이 자연스러워 보이는지를 평가하였다. 그 결과 이 연구진이 제시한 딥러닝 알고리즘으로 도출된 사진 중 약 93%가 자연스러운 것으로 판단되었다. 실제의 정확성은 이보다 더 낮을 수 있다. 색을 제대로 구현하지 못했음에도 불구하고 자연스럽다고 평가된 사진들이 있기 때문이다. 예컨대 실제 사진은 황금빛 들판을 보여주고 있었고, 알고리즘 수행 결과 초록색 들판이 된 것이다. 그럼에도 불구하고 역시 딥러닝의 힘은 대단하다는 것을 느낄 수 있다. 흑백사진을 컬러사진으로, 혹은 흑백영상을 컬러영상으로 바꾸는 기능들, 알고리즘들, 전문가들이 많은데, 이런 것들을 하루아침에 무용지물로 만들 수 있는 것이 바로 인공지능이기 때문이다. 컬러 입힌 흑백영화들을 보고 대단하다고 생각했던 적이 몇 번 있는데 근 미래 안에 인공지능으로 바뀌어진 흑백영화를 볼 수 있지 않을까 싶다.질문. 흑백사진을 컬러사진으로 바꾸는 것이 어떤 의미를 가지고 있을까?주요 출처[1] Waseda University, Let there be color!: joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification "
" '나는야 딥러닝' 빅데이터 세번째 이야기 영화 뿐만 아니라 드라마, TV 등에서 '인공지능'에 대해 많이 접해보셨을텐데요, 인공지능이란 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술입니다. 이러한 인공지능기술을 바탕으로 '딥러닝' 이라는 개념이 생겨났는데요, 딥러닝이란 컴퓨터가 사람처럼 생각하고 배울 수 있도록 하는 인공지능(AI) 기술이며, 인간 두뇌의 정보 처리 방식을 모방해 컴퓨터가 사물을 분별하도록 기계를 학습시키는 기술입니다. 딥러닝 기술을 적용하면 사람이 모든 판단 기준을 정해주지 않아도 컴퓨터가 스스로 인지·추론·판단할 수 있게 되며, 이는 음성·이미지 인식과 사진 분석 등에 광범위하게 활용된다고 하네요. ​ 그렇다면 카드뉴스를 통해 더 자세한 딥러닝 기술의 사례를 살펴볼까요? ​ "
" 딥 러닝 제대로 시작하기 작가 오카타니 타카유키 출판 제이펍 발매 2016.10.10. 평점 리뷰보기 책 서문의 베타리딩 평을 보니 수학이 어렵다는 얘기가 많았는데 반대로 나는 CNN(Convolutional Neural Network)의 역전파BP(back-propagation)이 유도되어있는 것을 보고 감동받았다. 나같이 바닥부터 직접 만들면서 공부하려는 사람은 자료가 없어서 참 힘들다. CNN의 BP도 내가 직접 유도하면서 조마조마하던 느낌이 떠올랐다. 이 책이 6개월 일찍 나와줬더라면 내 시간을 한 달은 아낄 수 있었을 것 같다. 앞으로 RNN이나 LSTM을 공부할 때 반드시 옆에 두고 볼 예정이다.공학적인 배경을 가지고 있고 NN이나 딥러닝에 대해 어느정도 개념을 알고 있다면 작동 구조를 가장 빠르고 정확하게 이해하는 방법은 수학이다. 많은 사람들이 이 책을 펴는 순간 수식들을 보면서 불편함을 느낄 것이다. 그러나 생각해보라. '현재의 내가 이해할 수 있는 자료'는 나를 발전시켜주지 않는다. 미래의 더 발전한 나를 꿈꾸며 이런 책에 도전하는 것을 권한다. 책의 앞부분은 내 OCW 강의 ""C++로 배우는 딥러닝""을 책으로 쓴다면 이렇게 써야겠다 싶은 모양새다. ""C++로 배우는 딥러닝""을 끝마치고 그 이상을 원하는 분들에게는 강력히 권장한다. 이번주 심화 프로그래밍 과목에서 back-propagation을 가르쳤는데 실습 시간 30분만에 반 이상의 학생들이 프로그래밍을 끝내고 가버려서 충격을 받았다. 당신도 할 수 있다. (참고로 내 학교 강의는 절대로 OCW 처럼 친절하지 않다.)각 기술들의 특징을 콱 찝어서 정확히 설명해주고 있어서 매우 편리했다. 단점은, 따로 공부해서 살을 붙여야 한다는 것인데 그런 자료들은 인터넷에 많이 있다.번역 말투는 다소 안타깝지만 한국의 현실을 생각해보면 이런 책이 나와준 것만 해도 고맙다.원판이 몇 년도에 나왔는지 찾아보려 했으나 일본어를 못해서 포기했다. 요즘같이 기술이 급변하는 시대에는 출판사에서 원어판이 몇 년도에 나왔는 지도 좀 기재해주셨으면 좋겠다.출판사에서 제공해주신 책을 읽었는데 서점 판매 시작하기 전에 보내주시겠다고 미리 얘기가 없었다면 자비로 바로 샀을 것이다. 사실, 나는 발간되는 거의 모든 관련 서적들을 자비로 구매하고 있지만 부정적인 얘기는 공개적으로 하지 않으려고 맘 먹은 터라 굳이 서평을 쓰지 않는 정도로 넘어가고 있다. 내 논조를 이해하는데 참고하시기 바란다. "
 안녕하세요! 종이비행기입니다.최근에 엄청 이슈가 되었던 알파고의 딥러닝에 대한 카드뉴스를 가져왔습니다.알파고가 이세돌을 이길 수 있었던 신의 한수로 딥러닝이 꼽히고 있는데요~​과연!!딥러닝이 무엇인지 산업일보 산소통과 함께 알아보도록 합니다!​​​ ​​알파고와 이세돌의 바둑대결이 4승 1패로 알파고의 승리로 끝났더랬죠...​​ ​저도 처음에는 이세돌이 이길 수 있을 거라고 생각했었는데 ㅠㅠ한 경기 두 경기 진행될수록 이세돌이 한 판만 이겼으면 좋겠다 했는데....​이세돌이 1승했을때 얼마나 감격스럽던지 ...​ ​알파고는 어떻게 바둑 최고수 이세돌을 이길 수 있었을까요??​​ ​​핵심은 ! 바로 딥러닝 분석 기법입니다.몬테카를로 트리탐색이라는 형태의 알고리즘을 바탕으로 하는 딥러닝 분석기법을 적용했다고 하는데요~!이 기법은 자신에게 승률이 높은 선택을 하도록 돕는 알고리즘이라고 합니다.​​ ​딥러닝은 기계학습의 한 종류입니다.인공 신경망을 기반으로 하여 컴퓨터가 보유한 많은 데이터를 활용하여 사람처럼 스스로 학습할 수 있게 하는 기술인데요~알파고는 이를위해 가치망과 정책망 신경을 결합했다고합니다.​알파고의 정책망이란 상대방의 다음 수를 예측하여 자신에게 가장 승률 높은 수를 계산하는 것을 말합니다.가치망은 바둑돌의 위치를 분석하여 승자를 예측하는 것을 말합니다.​​알파고는 딥러닝 기술을 활용해 승률 변화까지 계산해서 상대방에게 불리한 수를 추려내며 바둑을 두었습니다.​​​바둑의 경우 경우의 수가 많은 편이라 처음에는 이세돌 9단이 승리할 것이라는 예측이 우세했었습니다.​딥러닝은 빅데이터를 기반으로 하고 있습니다.딥마인드는 이번 대국전 알파고에게 바둑 기사의 3천만건의 기보를 입력했다고합니다.사람이 3천만건의 기보를 학습하려면 걸리는 시간은 무려 1천년.......이쯤되니 이세돌이 1승을 한게 엄청 대단해지네요.​이번 대결에서 승부를 가른건 시간이었다고 볼수 있겠네요. 물론 사람도 예측과 계산 분석이 가능합니다.하지만 사람과 기계가 상황을 분석하고 판단하는 시간이 다를 수 밖에 없으니까요...그래서 제한시간이 1시간인 경기를 했다면 이세돌이 이겼을 수도 있다는 분석이 있다고 합니다.​​이상 산업일보 산소통과 함께 알파고 딥러닝에 대해 알아보았습니다!! 
" 체스의 월드챔피언은 인공지능?! 인공지능 시대의 도래누구나 한번쯤은 화려한 온라인 게임 대신 컴퓨터에 내장된 기본 게임을 해봤으리라 생각합니다. 체스는 어떤 컴퓨터에서도 빠지지 않고 볼 수 있는 게임 중 하나죠! 체스 게임을 실행하면, 컴퓨터의 사용자는 자신의 수준에 따라 컴퓨터와 체스대결을 벌이게 됩니다.[컴퓨터 기본 게임 체스]위 사진은 기본 체스게임을 캡처한 사진입니다. 체스 실력이 많이 부족한 저는 가장 쉬운 단계에서도 컴퓨터에게 자주 지곤 합니다. 문득 ‘체스 고수와 이 컴퓨터가 체스대결을 벌인다면 누가 이길까?’하는 궁금증이 생겼습니다.그러던 중 우연히 체스와 인공지능의 대결 이야기를 접하게 되었습니다. 이야기에 따르면 정말 놀랍게도 체스의 세계챔피언은 사람이 아니라 ‘인공지능’이라고 합니다. IBM에서 개발한 체스전용 인공지능 수퍼컴퓨터 ‘딥블루’가 1997년 5월, 무려 15년 동안 체스의 세계 정상자리를 지켜온 가리 카스파로프를 이기는 사건이 벌어졌습니다.이 때 딥블루에는 2억 가지 경우를 계산할 수 있는 기능은 물론지난 100년 동안의 체스 주요대국 기록이 저장되어있었다고 합니다. 그 이후 아직까지도 체스의 세계 챔피언 자리는 ‘인공지능’이 지키고 있습니다. [인공지능 vs 포커선수 / 출처-http://article.joins.com/news/article/]하지만 모든 인공지능이 사람을 이길 수 있는 것도 아닙니다.올해 5월 초 미국 피츠버그의 한 카지노에서 인공지능 ‘클라우디코’가 4명의 포커선수와 맞붙었는데요! 시합의 결과는 4:0 인공지능의 완패였습니다. 이러한 사례를 보면, 인공지능은 그 발전 가능성과 성능이 무궁무진해 질 수 있지만 아직 보완할 부분이 분명 남아있구나 하는 것을 알 수 있습니다.자칫 이 인공지능이 우리와는 전혀 상관없는 고도의 기술이라고 느껴질 수도 있습니다. 하지만 지금은 ICT가세계 산업의 주역으로 떠오르고 있는 지금, 인공지능은 이미 우리 생활에 밀착되어 각종 편의를 돕고 있습니다.생활 속 인공지능, 딥러닝그렇다면 우리 생활 속 인공지능에는 무엇이 있을까요? 먼저 ‘딥러닝’기술을 살펴보겠습니다. ‘딥러닝’은 알고리즘을 이용해서 컴퓨터 스스로가 데이터를 분석하고 그 패턴을 예상하게 하는 인공지능 기술입니다. 이 때, 알고리즘의 처리방식은 사람의 뇌가 정보를 처리하는 방식과 유사하다고 합니다. ‘인공지능은 사람의 뇌를 시스템으로 옮겨놓은 것이구나’하는 것을 더 확실하게 체감했어요.솔직히 ‘딥러닝’이라는 이름이 많이 생소하시죠? 그렇지만 ‘딥러닝’은 실제로 우리들이 많이 사용하고 있는 기술입니다.네이버 검색창이나 카카오톡에 문자를 입력할 때 자주 볼 수 있는 ‘검색어 자동완성기능’은 딥러닝이 활용 된 가장 대표적인 기술 중 하나입니다. 또 최근 휴대폰을 얼굴인식으로 잠그고 해제하는게 가능해졌죠? 이때의 ‘얼굴인식’도 딥러닝이 활용된 기술입니다. [엑스마키나 / 출처-네이버]하지만 인공지능에 항상 긍정적인 시선만 있지는 않습니다. 인공지능의 발달에 따른 부정적 영향에 대한 우려도 많이 생겨나고 있습니다.쉽게 말해 ‘인공지능이 너무 뛰어나져서 사람의 통제를 벗어나게 된다면?’이라는 의문으로 설명할 수 있겠네요.가까운 예로 이에 대한 사람들의 우려가 종종 영화로 만들어 지기도 합니다.올해 큰 관심을 끌었던 어벤져스2 (에이지 오브 울트론)에서도 토니 스타크가 만들어낸 인공지능 로봇 ‘울트론’이 세상을 없애려고 하는 악당으로 나왔었죠. 어벤져스 뿐 아니라 사람과 인공지능(운영체제)의 사랑을 다룬 영화 'HER'나 사람을 빼 닮은 인공지능 로봇 이야기 엑스마키나 등의 영화들이 속속 등장하고 있습니다. 인공지능은 우리의 미래에서 빼놓을 수 없는 기술임이 분명해 보입니다.영화처럼 인공지능이 혹여 부정적인 결과를 가져올 수도 있지만, 기술이 사람을 만드는 것은 아니라 사람이 기술을 만드는 것이니 만큼, 기술에 대한 올바른 이해와 사용이 뒤따른 다면 선기능 또한 확실한 기술이 인공지능이라 생각합니다. 스마트폰의 등장이 그랬듯, 인공지능이 우리 삶 속에 더욱 밀착되면서 등장할 다양한 변화를 기대해 봅니다. "
" 2월 둘째주 빅데이터/딥러닝/인공지능 트렌드를 전달해 드리오니 업무에 참조하여 주시면 감사하겠습니다.이제 ""인공지능 플랫폼(AI 플랫폼)"" ""딥러닝 기반의 챗봇, 상담시스템"", ""머신러닝 기반의 IOT/제조 실시간 모니터링 솔루션"", ""머신러닝 기반의 보안패턴분석 솔루션""도 저희 락플레이스 빅데이터사업부에서 컨설팅, 가이드, 구축, 활용방안을 제시해드립니다...[빅데이터/인공지능 트렌드 및 소식]‘21세기 석유’ 데이터 다루실 분 모십니다http://news.joins.com/article/21212426타깃은 고객의 임신사실을 어떻게 알았을까http://www.edaily.co.kr/news/NewsRead.edy?SCD=JE41&newsid=01275926615827240&DCD=A00504&OutLnkChk=Y“고객을 알아야 살아남는다”…은행권도 빅데이터http://www.yonhapnewstv.co.kr/MYH20170204006400038/?did=1825m""의료 빅데이터 혁신 5~10년 안에 온다""http://www.monews.co.kr/news/articleView.html?idxno=97392홍순만 코레일 사장 “IT·빅데이터 접목한 경영효율화·안전체계 구축”http://www.dailian.co.kr/news/view/610330/?sc=naver“바이오 빅데이터 연구 집중”http://www.gnmaeil.com/news/articleView.html?idxno=333653빅데이터로 민생분야 꼼꼼하게 챙긴다..공공 빅데이터 표준분석모델 설명회 개최http://www.hkbs.co.kr/?m=bbs&bid=envnews5&uid=415740""고객 소비패턴부터 비금융정보까지""…금융권 빅데이터 활용 '확산일로'..금융권, 마케팅부터 위험관리 등 전방위적으로 활용http://www.ebn.co.kr/news/view/874421자동제어기업, IIoT·빅데이터·클라우드 통한 스마트 공정제어 실현http://www.kidd.co.kr/news/189745데이터 낙후·인재 장벽·투자기피…한국 인공지능의 3敵http://news.mk.co.kr/newsRead.php?&year=2017&no=77260딥러닝 통해 '맞춤형 상품' 검색·추천…고객 마음 읽는다http://www.newsis.com/view/?id=NISX20170202_0014679746&cID=10408&pID=13000FLI, 착한 인공지능 개발하자!…‘아실로마 AI 원칙’ 23개 도출http://www.itnews.or.kr/?p=20791인공지능 '구글 홈'과 '아마존 알렉사'http://www.irobotnews.com/news/articleView.html?idxno=9768“인공지능 10년만에 급성장…스타트업 황금기 계속 된다”http://news.mk.co.kr/newsRead.php?no=71142&year=2017이승훈 실장 드림추신 : 빅데이터/딥러닝/인공지능 솔루션 서비스 및 컨설팅 문의처 - 락플레이스 이승훈 실장, 010-9338-6400, hunlee@rockplace.co.kr "
" 정말 쉬운 머신러닝과 딥러닝의 강의알파고와 이세돌의 경기를 보면서 이제 머신 러닝이 인간이 잘 한다고 여겨진 직관과 의사 결정능력에서도 충분한 데이타가 있으면 어느정도 또는 우리보다 더 잘할수도 있다는 생각을 많이 하게 되었습니다. Andrew Ng 교수님이 말씀하신것 처럼 이런 시대에 머신 러닝을 잘 이해하고 잘 다룰수 있다면 그야말로 ""Super Power""를 가지게 되는 것이 아닌가 생각합니다.더 많은 분들이 머신 러닝과 딥러닝에 대해 더 이해하고 본인들의 문제를 이 멋진 도구를 이용해서 풀수 있게 하기위해 비디오 강의를 준비하였습니다. 더 나아가 이론에만 그치지 않고 최근 구글이 공개한 머신러닝을 위한 오픈소스인 TensorFlow를 이용해서 이론을 구현해 볼수 있도록 하였습니다.수학이나 컴퓨터 공학적인 지식이 없이도 쉽게 볼수 있도록 만들려고 노력하였습니다. 내용 (대략 1주일에 하나씩 업데이트 됩니다.)수업의 개요 비디오 머신러닝의 개념과 용어 비디오 (TensorFlow의 기본 Lab 비디오 )Linear Regression 의 개념 비디오 (TensorFlow 로 구현 Lab 비디오 )Linear Regression cost함수 최소화 비디오 (TensorFlow 로 구현 Lab 비디오 )여러개의 입력(feature)의 Linear Regression 비디오 (TensorFlow 로 구현 Lab 비디오 )Logistic (Regression) ClassificationSoftmax Regression (Multinomial Logistic Regression)Neural NetworksConvolutional Neural NetworksRecurrent Neural NetworkDeep Deep Network AWS 에서 돌려보기 (powered by AWS)Acknowledgement이 비디오는 저도 인터넷등을 통해 공부하면서 만든것이며 아래 자료를 많이 사용하였습니다.Andrew Ng’s and other ML tutorialshttps://class.coursera.org/ml-003/lecturehttp://www.holehouse.org/mlclass/ (note)Deep Learning TutorialConvolutional Neural Networks for Visual Recognition.http://cs231n.github.io/Tensorflowhttps://www.tensorflow.orghttps://github.com/aymericdamien/TensorFlow-ExamplesDeep learning @Udicity의견주기비디오나 강의에 대한 의견이 있으시면 아래로 이메일을 보내 주시면 됩니다. hunkim+ml@gmail.com 기본적인 머신러닝과 딥러닝 강의 is maintained by hunkim.This page was generated by GitHub Pages using the Cayman theme by Jason Long. "
" 저희는 빅데이터 분석 플랫폼(Data Analysis Platform), 비주얼 분석 도구(Visual Analysis Tool) 들을 개발 또는 공급, 소개하고 있으며 또한 빅데이터 분석 서비스와 빅데이터 구축 및 인공지능, 머신러닝/딥러닝 플랫폼 공급과 관련 컨설팅도 병행하고 있습니다. 1. 스카이트리(Skytree) : Skytree는 AI(머신러닝/인공지능) Platform(플랫폼)으로 자동화된 머신러닝 소프트웨어입니다. 엔터프라이즈급 기계학습의 선두주자인 Skytree는 기존 인프라에 설치하고 전체 데이터 세트를 사용하며 고성능 알고리즘과 자동화 된 모델 구축을 사용하여 더 짧은 시간에보다 정확한 예측 모델을 제공합니다. 머신러닝, 이제 쉽고 빠르게 구현하실수 있습니다.2. 호튼웍스(HortonWorks) : 100% 오픈 소스 하둡 공급사인 호튼웍스는 HDP의 YARN으로 하둡의 처리력을 두 배로 만들엇고 가장 빠른 버전 업그레이드를 제공합니다. 또한, 가장 많은 커미터를 고용 아파치® 하둡™ 프로젝트와 다른 중요한 프로젝트의 200+명이 있습니다. 호튼웍스는 하둡 로드맵에 영향력 보유 최신 데이터 아키텍처에 위한 정의, 혁신하며, 로드맵을 제공하며 고객들과 파트너들에게 로드맵에 직접 영향을 줄 수 있는 방법을 제공하고 있습니다. 3. Splunk: 보안관제/내부통제/FDS/제조 및 설비 데이터/[웹-WAS-모바일로그] 등의 로그성 데이터 분석은 Splunk가 좋습니다. 머신러닝 기반의 IT관제 및 보안 관제, IOT관제 및 제조 및 설비분야의 인지 장애 시스템을 제공해 드립니다.저희는 빅데이터 분석 전문업체로 파트너들과 고객 여러분의 관심과 기대에 부응하도록 노력 하겠습니다. 언제나 건강하고 활기찬 하루 되십시요.연락처) 연락처 : 이승훈 실장, 010-9338-6400 E-Mail : kosena21@naver.com, kosena2121@gmail.com Skype, Facebook, Twitter, Linkedin, Cacaotalk ID : kosena21 "
" 작년 알파고 등장으로인공지능이 엄청 화재가 됐는데요.모바일어플계의 알파고가 등장했습니다.이름하야 최강바둑 딥러닝한글판 크레이지스톤이죠알아보도록 할께요22,000원의 고가 어플이지만바둑팬이라면 구입할만한 어플이죠ㅋㅋ최강바둑 딥러닝 줄여서 DL의메인화면은 이렇습니다.15급부터 5단까지인데요모바일 인공지능인데도기력이 상당합니다.PC로 상용화된 젠6에 비하면약간 떨어지나 자유로운 기풍과인간다움도 느껴지는 대단한 어플바둑 어플로 강추!분석모드도 있어 혼자 복기도 가능아마 5단 급의 복기를 받을 수 있는 바둑어플이에요바둑 매니아분들께 강력추천합니다! "
" 구글을 능가하는 일본의 딥러닝 인공지능(AI) 벤처기업 딥러닝은 그물과 같은 뇌의 신경세포를 모방해서 정보처리 단계를 심화하는 기술이다. 기존의 인공지능보다 정확도가 높고, 데이터 내부에 숨어 있는 패턴을 인식할 수 있다. ​다양한 용도에 응용할 수 있으므로 산업계에서 기대가 크며, 지금도 영상을 해석해서 사람들의 흐름을 분석하고 대량의 문장을 장르별로 분류하는 등 일부 용도에서 사용하기 시작했다. ​ 구글도 관련 벤처기업을 인수하는 등 딥러닝의 개발을 강화하고 있다. IT업계의 맹주라고 할 수 있는 이런 강력한 라이벌들에 비해 독자성이 있는 기술과 타 기업과의 제휴를 통해 이들에게 대응하는 일본의 벤터기업이 바로 프리퍼드 네트웍스(PFN)이다. ​ 파낙, 도요타와 공동개발 ​ PFN은 자연언어 처리기술을 배경으로 해서 웹 검색엔진과 데이터 분석서비스를개발한 경험을 가지고 있다. 2014년 10월 NTT로부터 출자를 받았으며, 도요타와 자동운전차 공동개발을 시작했고 2015년 6월 파나소닉 및 산업용 로봇업체 파낙과 협업을 발표하기도 했다. ​ 일본을 대표하는 기업들이 PFN을 지원하는 이유는 두 가지가 있다. 하나는 딥러닝(심층학습)을 하드웨어와 조합할 수 있기 때문에 응용범위가 넓다는 점이다. 또 하나는 기술의 독자성이다. ​각각의 로봇이 학습한 경험을 실시간으로 공유할 수 있는 분산학습이 특징이다. 산업용 로봇의 경우, 공장에 배치한 복수의 로봇에 딥러닝을 처리하는 연산장치와 각종 센서를 부착하고 네트워크 회선으로 연결한다. 센서의 정보를 해석해서 로봇이 동작을 하면서 작업을 실행한다. 그 후 계속적으로 센싱을 하고, 이 루프를 돌려감으로써 각각의 로봇이 시스템 전체를 효율화하는 동작을 학습해 간다. ​ ​ ​미니코스에서 주행하고 있는 복수의 로봇카 ​ 이런 과정에서 분산학습이 효과를 발휘한다. 예를 들면, 로봇이나 자동운전자가 주변과의 충돌을 피하기 위해 스스로 처신방법을 습득한다고 한다. 그 지식은 네트워크를 통해 순식간에 다른 로봇이나 자동운전차에도 전송되며, 이 같은 각 로봇의 성공체험을 반복적으로 공유함으로써 학습을 효율화할 수 있다. ​ ​ ​<로봇의 모니터 화면>각 로봇이 벽이나 다른 로봇과의 거리, 주행속도 등의 파라미터를 심층학습으로 처리하여가속, 브레이크, 핸들을 조작한다. 로봇은 부딛히지 않고 빨리 이동하기 위한 방법을서서히 학습해 간다. 로봇이 자율적으로 학습하는 기능에 의해 1대의 로봇이 파손되어도 나머지 로봇이 작업을 커버하는 등 환경의 변화에 대응하여 고장에 내성이 강한 '쉬지 않는 공장'을 만들 수 있다고 한다. ​ 하드웨어 기술은 일본 대기업이 우위 ​ 딥러닝의 효과를 보여주기 위해 이 업체는 다수의 로봇카를 미니코스에서 달리게 하는 데모 동영상을 공개했다. 로봇카는 장해물을 피하면서 자신의 위치와 방향, 다른 차량과의 위치관계를 파악하여 자율적으로 주행한다. 처음에는 자주 서로 충돌하고 정지하곤 했다. 그렇지만 시간이 지나면서 딥러닝의 효과에 의해 서로 피하면서 원활하게 주행을 한다. ​ 파낙 등 일본 업체와의 협력관계도 구글 등 라이벌에 대한 우위점이라고 할 수 있다. 구글도 로봇 벤처기업을 인수하여 기술을 축적하고 있지만, 장기간 실적이 있는 파낙 쪽이 1보나 2보 앞서 나가고 있다. ​ 산업용 로봇 이외에도 자동운전차에서는 도요타, 차량의 자동브레이크 등을 제어하는 운전지원시스템 개발에서는 파나소닉과 제휴를 하고 있다. 시판 차량의 모든 기술을 축적하고 있는 도요타와 비교하면 구글이 개발하고 있는 것은 장난감 같은 것이라고 한다. ​ 약물의 개발이나 네트워크 최적화에도 응용 ​ 딥러닝 기술이 발전함에 따라 응용분야도 넓어지고 있다. 특히 주목할만한 분야는 약품의 개발이다. 지금까지 약물의 임상실험에는 엄청난 비용과 노력이 들었지만 앞으로 iPS세포에 의한 재생의료의 기술이 발전하면 난치병에 걸린 장기 등의 실험용 세포를 대량으로 만들 수 있다. ​약품의 개발에서 급속한 공업화가 이루어질 것이며, 그 때에 인공지능에 의한 자동화가 크게 기여할 것으로 보고 있다. ​ 약물의 개발에는 2단계의 딥러닝을 이용한다. 먼저 산업용 로봇과 마찬가지로 실험장치를 딥러닝으로 자동화하고 작업을 효율화한다. 이어서 실험에서 획득한 데이터의 해석에도 딥러닝을 사용한다. 방대한 데이터를 다각적이고 광범위하게 조사함으로써 기존의분석방법으로는 발견할 수 없었던 특이점을 찾아낼 수 있다. ​ 이 업체는 미국 캘리포니아에도 진출해 있다. 미국에서는 시스코시스템즈와 통신기기에 딥러닝을 탑재하는 기술을 공동으로 개발하고 있다. 라우터 등 네트워크 기기에 인공지능을 탑재함으로써 기존에는 시스템 관리자가 수작업으로 설정했던 네트워크 경로를 이제는자동으로 알아서 자동으로 할당할 수 있다. ​ 지금까지는 인터넷 경로에 주로 사람이 만든 데이터가 이동했지만 앞으로는 인공지능을 갖춘 대량의 기계가 접속함으로써 기계중심의 인테넷으로 변할 것이라고 한다. 모든 사물이 인터넷에 연결되어 능동적으로 정보를 주고받는 사물인터넷(IoT) 시대에 새로운 기반을 자신들이 만들고 지켜날 것이라고 한다. ​ ​ http://www.nikkei.com/article/DGXMZO89792620X20C15A7000000/ http://www.sisapress.com/news/articleView.html?idxno=64877 http://www.nikkei.com/article/DGXMZO93698150W5A101C1000000/ ​ "
" 컴맹들은 알파고의 기술 수준을 너무 물로 본다.프로 기사들의 수를 내다 본다는 개념 자체가 대략적으로 그렇다는 것이지, 정확히 그렇게 각본대로 진행된다는 의미가 전혀 아니다. 186수 불계승이란 의미는, 한 수 한 수에서 알파고의 선택이 지지 않는 방향으로, 안정적으로 운영했을 가능성이 크다.불과 하루 사이에 알파고는 1만 번 이상의 대국 트레이닝으로 더욱 강해질 것이다.아래는 ELO 기준 바둑 기력 세계 랭킹이다.RankName♂♀FlagElo1Ke Jie♂36232Park Jungwhan♂35713Iyama Yuta♂35464Lee Sedol♂35325Shi Yue♂35106Kim Jiseok♂35057Park Yeonghun♂35048Mi Yuting♂35029Zhou Ruiyang♂349910Kang Dongyun♂349811Tang Weixing♂348012Lian Xiao♂347613Chen Yaoye♂347314Gu Zihao♂346915Gu Li♂345516Huang Yunsong♂345317Tuo Jiaxi♂345218Jiang Weijie♂344819Wang Xi♂344520Li Qincheng♂343921Tan Xiao♂343922Lee Donghoon♂343523Choi Cheolhan♂342824Tao Xinran♂342825Hong Seongji♂342726Weon Seongjin♂342727Fan Tingyu♂342428Peng Liyao♂342329Yang Dingxin♂342230Gu Lingyi♂3415ELO 포인트는 WHR 알고리즘을 통해 바둑 기사의 기력을 수치화한 것으로, 바둑계에서도 상당히 객관적이고 과학적인 것으로 받아들여지고 있다. 이 수치에 따른 통계적인 승패 적중도는 80%에 근접한다.즉, 3,613점의 커제가 3,532점의 이세돌을 압도하는 것은 과학적으로 당연한 것이었다.이미 알파고의 기력은 3,500을 상회한다고 볼 수 있다.이는 제한된 구글의 정책(?)에 따른 기력이며, 알파고의 하드웨어를 확충하기만 한다면 기력은 지속적으로 상승 가능하다.일부러 비슷한 수준이나 약간 압도할 수 있는 수준에서 기력을 조절하는 것으로 보인다.커제가 와도 알파고와 호각이거나, 알파고가 약간 우위를 가져갈 수 있다고 본다.그리고 많은 컴맹들과 모 대학 컴퓨터 공학 교수 님도 딥러닝에 대한 이해가 부족한 헛소리들을 하는데...하나의 대국을 뛴다고 무슨 초사이어인처럼 알파고가 엄청나게 성장을 한다?무슨 터무니 없는 헛소리다.3,000만 대국 이상을 벌였고, 지금 이 순간도 수십 개의 대국을 동시에 펼칠 알파고에게 대국 하나가 지니는 의미는 그다지 대단하지 않다.그냥 알려진 프로 기사들의 기보 5만 여개 정도만으로도 알고리즘 개선은 충분할 것이다.구글은 절대 바둑이나 두려고 이런 프로젝트를 기획하지 않았다.인간을 상대하는 목적은, 인간에게 배우고자 하는 것이 아니다.딥러닝 머신 여러 대 간의 상호간의 경쟁 체제가 훨씬 더 발전하기 쉬운 구조이다.단순히 이런 하나의 이벤트는 홍보이자, 하나의 실험 데이터에 불과하다.사람 백 명, 천 명 달라 붙어 상대해봤자, 이제는 데이터를 쌓는데 큰 의미가 없는 수준이다.그냥 비슷한 수준의 베타고, 감마고 여러 대를 만들어 (단, 성향은 조금씩 다르게 설정하여)리그를 구성해서, 하루에 수 만 번 씩 논리 배틀을 벌이는 것이 낫다.궁극적으로 딥러닝 머신 기술은 앞으로 미래에많은 국가에서 판검사를 대체할 것이고, 많은 사회-정치적 문제들을 해결하는 용도로 사용될 것이라 본다.(사회 과학적 문제를 가장 최선의 판단으로 선택할 수 있는 기계가 바로 딥러닝 머신의 미래다.)또한, 기업에서의 사업 정책 결정, 주식 시장에서의 매매 등에도 충분히 활용될 수 있다.주식 및 파생 시장에서의 딥러닝 기법 매매가 활성화 될 경우에는 기존의 비교적 단순하고 미개한 프로그램 매매가 딥러닝 머신 기반 매매에 완존 탈탈 털리는 엄청난 사건이 벌어질 수 있다. (단 몇 시간 만에도 수십 억 달러를 털릴 수 있음)내가 과거에 썼던, 미래에 망할 직업 예상 글을 보면 잘 알 수 있따.http://blog.naver.com/chambungg/8020171513930년 후 망하는 직업. (참붕 저 - 미리 본 미래)본 저작물의 저작권은 네이버 chambungg에게 있습니다. 30년 후 망하는 직업 예측. 1. 의사 - 로봇이 다 수...blog.naver.com30년 후에 판사를 딥러닝 머신이 대체하지 못한다는 근거는 없다.알파고 승리 예측 관련 글http://blog.naver.com/chambungg/220636331024이세돌은 존 코너가 될 것인가, 코너에 설 것인가.이세돌과 알파고의 대결이 얼마 남지 않았다. 이 대결 이후로 인류의 미래는 엄청난 기로에 설 것이라는 견...blog.naver.com "
" Beyond Industry 4.0의 세계 로봇에 뉴럴네트워크 딥러닝 기술과 기계학습 도입 일본 최대 로봇업체, 파낙은 뉴럴네트워크 기술의 일종인 딥러닝(심층학습) 기술과 머신러닝(기계학습) 기술을 보유하고 있는 벤처기업, Preferred Networks(PFN)과 제휴계약을 체결했다. ​ ​ ​ 앞으로 딥러닝 기술을 자사의 산업용 로봇이나 공작기계 등에 응용하기 위해 PFN과 공동으로 기술을 개발한다. PFN은 딥러닝 기술에서 일본 최고의 기술력을 보유하고 있는 기업이며, 산업용 로봇 톱기업과 딥러닝 톱기업의 상호 협력은 의의가 크다고 할 수 있다. PFN은 자동운전 분야에서 이미 도요타자동차와 협업관계에 있다. ​ 적용대상은 산업용 로봇, 공작기계, 사출성형기 등이며, 현재는 기본적으로 프로그래밍에 의해 로봇의 동작을 제어하고 있지만, 앞으로 딥러닝 기술에 의한 학습을 통해 로봇을 제어한다. ​사람이 생각하지 못한 동작을 딥러닝 기술에 의해 발견하는 등 지금보다 더 고차원적인 생산의 최적화를 도모할 수 있다. ​ 구체적으로는 로봇이나 공작기계의 예방정비, 복수의 로봇의 협조동작 등에 적용할 예정이다. 기존의 예방정비는 이상징후를 검출하기 위한 룰을 사람이 설정하고 있지만, 이제 이런 룰을 기계학습을 기반으로 로봇이 설정한다. ​ 복수 로봇의 협조에 대해서는 예를 들어, 10대의 스폿 용접로봇을 협조 동작시켜서 사이클 타임을 단축하거나 1대가 고장 등으로 정지한 경우에도 나머지 9대로 라인을 정지하지 �方� 용접을 계속하는 방법 등을 찾아낼 수도 있다. ​ 인더스트리 4,0에서는 센서 데이터를 수집, 분석하는 수준에 머물러 있지만, 파낙은 이를 넘어선 Beyond Industry 4.0의 세계, 복수 로봇의 협조나 로봇 자체의 제어까지 내다보고 생산의 초인텔리전트화를 목표로 하고 있다고 한다. ​​ ​ 이들이 가지고 있는 딥러닝 기술은 교사가 없는 학습의 일종인 강화학습(Reinforcement Learning) 기법을 이용하고 있다. ​ PFN은 파나소닉과도 기술제휴를 통해 자동운전이나 디지털가전 등에 딥러닝 기술을 적용할 예정이다. ​ ​ 한편 미국의 차세대 로봇을 대표하는 Baxter는 보스톤에 위치한 Rethink Robotics가 개발한 로봇으로 생산 현장에서 사용하고 있다. ​ ​ ​Baxter Baxter는 시각이 있으며, 시범을 보고 그것을 학습할 수 있다. 유튜브에서 요리프로그램을 보고 조리법을 학습하는 인텔리전스를 가지고 있다. 특정한 테스크를 프로그램할 필요는 없으며 로봇이 자동으로 학습을 한다. ​ Baxter의 가격은 2만 달러이며, 전기요금을 감안해도 사람보다훨씬 돈이 적게 든다고 한다. ​ ​ http://www.fanuc.co.jp/ja/whatsnew/notice/osirase20150610.html​ http://www.nikkei.com/article/DGXMZO87962070R10C15A6000000/ http://techon.nikkeibp.co.jp/article/FEATURE/20150609/422346/ http://www.nikkei.com/article/DGXMZO87907510Q5A610C1000000/​ ​ "
" 이번주는 온통 알파고와 이세돌9단의 대결이 화제거리다.https://deepmind.com/alpha-go.htmlAlphaGo | Google DeepMinddeepmind.com구글에서도 이 역사적 한판의 관전을 위해 에릭슈미트 회장과 많은 엔지니어들이 입국했는데,그 유명한 구글브레인의 수장 Jeffrey Dean도 한국을 방문했다.(사실 작년 NIPS에서 이미 봤...)온김에 요사이 공학계/통계학계/뇌신경학계등 방대한 분야를 위아더월드로 만든 deep learning에 관한 세미나를 개최했다.이름하여 제프딘과 함께하는 딥러닝 이야기.http://googledevkr.blogspot.kr/2016/02/deep-learning.html제프 딘과 함께하는 딥러닝 (Deep Learning) 이야기googledevkr.blogspot.com사실 페이스북 인공지능 커뮤니티에서 구글 관련자분께서 초대한정으로 등록을 받으셨는데, 운좋게 나도 참석자로 선정이 되어 구글캠퍼스를 방문했다. 삼성역 근처의 오토웨이타워 지하2층.각종 행사를 위해 구글코리아에서 마련한 공간 같다.초대한정이니까 많아야 50명 되겠지 했는데 한 200-300명 가량 왔으려나?들어가자마자 생각보다 너무 사람이 많아서 당황;;;다양한 분야에서 정말 많은 사람이 참석했다.딥러닝에 대한 관심은 3년째 여전히 뜨겁나보다.(한국에서는 생각보다 저명한 딥러닝 관련 논문이 잘 안나오는게 함정...)이렇게 입구에서 등록확인 절차를 거친다.이런 이름표에 이름을 쓰게 하는데 어떤용도인지는 3일이 지난 현재까지 파악되지 않는다.구글 매니저님께서 간단히 약력소개를 하시고.요새는 텐서플로우(TensorFlow)라는 딥러닝 오픈소스 홍보에 바쁘신 제프딘 님이시다.일단 구글이 한다는 이유만으로 소위 굉장히 '뜨는' 오픈소스인데, 나도 현재 Theano를 쓰고있지만 언젠가는 텐서플로우로 넘어가지 않을까 싶다.https://scholar.google.co.kr/citations?user=NMS69lQAAAAJ&hl=koJeff Dean - Google 학술검색 서지정보scholar.google.co.kr이건 구글스콜라에서의 제프딘 학술정보.그 유명한 MapReduce 논문은 인용이 16000건이 넘어간다ㄷㄷㄷ내 논문을 봐주신 Bovik교수님의 그 유명한 SSIM도 이제 11000건을 겨우 넘었는데;;;테크니컬한 내용은 보통 국제학회에서 진행되는 딥러닝 튜토리얼과 크게 다르지 않았다.다만 이들을 구글에서는 어떠한 응용분야로 적용시키고 있는가에 대한,아카데믹보단 프로덕트 필드 차원에서의 접근에 대해 흥미롭게 프레젠테이션이 진행됐다.(통번역, 사진에서의 텍스트 검출 및 번역, 자동 이메일 회신, 이미지 리트리벌, 캡셔닝 등등)""한국인들 질문 잘 안하잖아요""이건 맞다. 해외 가보면 한국인들은 질문을 안해...덕분에 미리 질문을 받아놓고, 그중 몇개(라고 하기엔 꽤 많은)의 질문을 미리 추려두고 사회자가 진행했다.테크니컬한 질문, 그냥 질문(?)이 번갈아가면서 제시됐는데.인상깊었던 질문은 ""어떻게 하면 당신같은 쩌는 엔지니어가 될 수 있나요?""제프딘 왈 ""아침밥을 드세요""물론 농담이고, 공학자는 다른 분야 전문가와의 교류와 디스커션이 중요하다고 부연설명을 했지만 일단 어느정도 쩌는 엔지니어가 되어야 그런 프로젝트 팀에 들어갈 수 있지 않을까.본 세미나의 내용은 Youtube에 통째로 녹화본이 업로드 되어 언제든 시청할 수 있다.딥러닝에 대해 이미 아는 사람이라면 49분부터 진행되는 Q&A를 더 흥미롭게 볼 수 있을듯.유투브 녹화 후에는 오프라인에서 다시한번 Q&A가 이루어졌는데, 굉장히 유익했다.테크니컬한 질문이 많이 나왔는데 다들 연구 혹은 프로젝트에 비슷비슷한 문제점이 있구나 하는 생각을 하게됐다.(대용량 데이터의 부재, 컴퓨팅 파워, 프로그래밍 언어, 티아노 윈도우 지원에 대한 질문 등)물론 ""그 옷 (제프딘이 입고온 텐서플로우 옷) 어디서 구할 수 있어요?""""텐서플로우는 왜 GPU프로그래밍을 NVIDIA CUDA만 가능한가요? 우리집 그래픽카드는 AMD인데...""와 같이 유쾌한 질문들도 많았다.이래저래 즐거웠던 시간.이런 세미나에 다녀오면 열심히 공부하고 논문쓰자 라는 생각밖에 안든다.그 기술의 격차가 너무 크게 느껴져서.(특히 reinforcement learning. 아오...)얼마전 나온 기사에서는 우리나라가 기계학습 기술이 세계수준에 무려 2.6년 뒤쳐졌단다.행사가 끝나고 단체사진도 찍었는데 그건 어디에 올라와있는지 모르겠다...업로드 되면 이 포스트에도 첨부해야지.20160307 @구글캠퍼스 서울%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%알파고 vs. 이세돌9단잠시 이 불세출의 천재기사와 인공지능의 대결에 대해 소회하자면,3월 10일 현재 2번의 대국 모두 알파고의 승리이다.형국을 보니 이제는 알파고가 이세돌에게 도전하는게 아니라 이세돌이 알파고에게 1승 도전! 의 분위기이다.해설자조차도 알파고 수의 의미를 파악하지 못해 우왕좌왕하는 모양새다.알파고 기술에 대한 NATURE논문 (http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)을 분석한 분들은Mastering the game of Go with deep neural networks and tree search : Nature : ...www.nature.com첫수부터 기존 프로 기보에서는 절대 나오지 않는 수를 두어 알파고의 policy network을 혼란에 빠트려라. 즉 트리구조 관점에서 볼때 처음부터 제대로 학습되지 않은 이상한 가지쪽으로 빠진 상태에서 시작해야 한다고 한다.이 외에는 어차피 중후반에는 경우의 수가 작아지므로 알파고가 압도적으로 유리하다.한마디로 초장은 전략적으로 말아먹고 시작해라 이 뜻이다.막상 이렇게 딥러닝을 통한 기술들이 세간의 주목을 받다보니(조간신문 1면이 정치사회가 아닌게 얼마만인가...)이 최고난이도 공학 분야에 대한 호기심, 내 커리어에 딥러닝은 무조건 필요하다는 이해타산, 저 위대한 엔지니어들과의 실력적 격차에 대한 불안함,등 많은 생각들이 머리속을 지배한다.나는 고전적 의미에서의 영상처리가 전공이고 논문도 이제 창피하지 않을정도로는 쓰고있다고 생각한다.하지만 갈수록 영상처리가 computer vision의 한 분야로 흡수되어가는 느낌이다.교수님께서 이번에 졸업하라고 말씀을하시는데, 아무래도 딥러닝 관련 논문 하나는 써야 할 것 같아 한학기를 더 하겠다고 말씀드릴 참이다.엔지니어로써 이 세계의 빠른 발전이 너무나도 두렵다.빨리 따라가자!참고로 다음 구글의 목표는 스타크래프트랜다...http://www.fnnews.com/news/201603091421018140[이세돌 vs. 알파고 세기의 바둑 대결] 알파고, 다음 목표는 ‘스타크래프트’구글 인공지능(AI) 프로그램 '알파고(Alpha Go)'가 바둑에 이어 전략 시뮬레이션 게임 ‘스타크래프트’에 도전할 예정이다. 제프 딘 ...www.fnnews.com이영호 나오나? "
" 위이미지의 산업용 로봇은 간병로봇으로 간병인이 환자를 옮기는거을 대신하기위해 제작된 로봇입니다. 간병로봇 리바는 체중이 80키로 되는 무거운 환자도 휠체어나 화장실로 옮겨줍니다. 산업용 로봇 리바는 환자를 들고 좁은곳도 자유롭게 다닐수 있다고 합니다. 산업용 로봇이 처음 만들어진것은 1958년 미국의 gm이라는 업체에서 유니메이트를 만들면서 시작되었습니다. 산업용 로봇은 지구 뿐만아니라 우주에서도 활약하는데 1996년 무인탐사로봇 소저너를 보낸후로 2004년에 오퍼뉴니티 2012년 큐리오시티를 화성에 보냈습니다. 심지어 수술도 산업용 로봇이 하는데요. 2000년 인튜티브서지컬이라는 곳에소 개발한 수술로봇 다빈티는 4개의 팔ㄹ로 수술이 가능한데 손떨림 현상이 없기때문에 오히려 정확히 수술할수 있다고 합니다. sf영화를 보면 로봇이 인간의 시중을 들거나 인간과 유사한 외모와 지능을 통해 인간의 역할을 대신하게 되는데요. 산업용 로봇이건 가정용 로봇이건 핵심이 되는 기술이 바로 딥러닝입니다. 딥러닝은 인간이 살면서 수많은 패턴을 이해하여 지능이 발전하는것처럼 인간의 학습 패턴을 모방한 인공지능입니다. 딥러닝 기�D을 통해 산업용 로봇,개인용 로봇이 우리화 함께하여 1인 1로봇시대로 생각보다 빨리 올것이라고 많은 전문가들이 말하고 있습니다. "
" 원문제목: Deep learning for computational biology 한글키워드: 딥러닝; 계산생물학; 기계학습; 유전체학영문키워드: deep learning; computational biology; machine learning; genomics1. 분석자 서문 2000년대 후반 및 2010년대 초반, 음성 인식과 이미지 인식에서 획기적인 성능을 보인 이후, 이제 딥러닝은 데이터 학습 및 분석과 관련된 대부분의 분야에서 적용되어 괄목할 만한 성과를 보여주고 있다. 이러한 추세는 생물정보학 및 계산생물학 분야도 마찬가지이며, 최근 3~4년간 여러 형태의 딥러닝 모델을 이용하여 유전체 시퀀스 예측, 바이오헬스 이미지 분류, 질병 진단 등 다양한 문제에 적용되어 우수한 성능을 보이고 있다. 본 논문은 계산생물학에서의 기계학습 기법 활용을 위한 프레임워크과 딥러닝을 실제 계산생물학 태스크에 어떻게 적용할 수 있는지 그리고 여러 하이퍼파라미터와 최적화 기법들이 어떠한 의미를 갖는지에 대해 구체적이고 알기 쉽게 잘 정리되어 있다. 개인적으로 기계학습 기반, 특히 딥러닝 기반의 계산생물학 문제를 해결하고자 하는 연구자에게는 많은 도움이 될 수 있는 논문이라 여겨진다[1]. 2. 목차 1. 서론 2. 조절유전체학을 위한 딥러닝 2.1. 조절유전체학에서 초기 신경망 응용 2.2. convolution 설계 2.3. 복수 특징의 동시 예측 방법 및 확장 기법 3. 생물 이미지 분석을 위한 딥러닝 3.1. 픽셀 수준 이미지 분류 응용 3.2. 전체 세포, 세포 군집 및 조직 분석 3.3. 학습 모델 재활용 3.4. CNN의 해석 및 시각화 4. 딥러닝 도구 및 실제 고려 사항 4.1. 데이터 준비 4.2. 모델 설계 4.3. 모델학습 4.4. Overfitting 회피 5. 결론 References 3. 원문정보 Christof Angermueller, Tanel Parnamaa, Leopold Parts, Oliver Stegle/Deep learning for computational biology / Mol Syst Biol. 12(7):878/29 July 2016 ※ 이 자료의 분석은 서울대학교의 김수진님께서 수고해주셨습니다.분석자료 바로가기http://www.kosen21.org/info/kosenReport/reportView.do?articleSeq=REPORT_0000000000474 "
" 2월 첫째주 빅데이터/딥러닝/인공지능 트렌드를 전달해 드리오니 업무에 참조하여 주시면 감사하겠습니다.이제 ""딥러닝 기반의 챗봇, 상담시스템"", ""머신러닝 기반의 IOT/제조 실시간 모니터링 솔루션"", ""머신러닝 기반의 보안패턴분석 솔루션"" 도 저희 락플레이스 빅데이터사업부에서 컨설팅, 가이드, 구축, 활용방안을 제시해드립니다...[빅데이터/인공지능 트렌드 및 소식]국제적 수준 유전체 빅데이터 분석 방법론 개발..서울대 박태성 교수, 정밀 맞춤의학 구현 기여http://www.kidd.co.kr/news/189710빅데이터 시대의 새로운 마케팅: 4P 전략http://ppss.kr/archives/65974이광구 행장, 차기 우리은행장 낙점…""AI, 빅데이터 등 적극 활용"" 미래전략 제시http://www.ddaily.co.kr/news/article.html?no=152250WCS 2017, 인공지능시대에 맞는 교육시스템 변화 촉구..4차 산업 견인기술의 현황과 현안’ 주제로 좌담회 개최http://www.kidd.co.kr/news/189655원자로도 인공지능·빅데이터 기술 접목http://news.mk.co.kr/newsRead.php?no=60929&year=2017롯데그룹, 빅데이터-AI 활용 고객별 맞춤형 서비스http://news.donga.com/3/all/20170124/82565191/1'스타트렉 키드' 베조스, 아마존 '알렉사'로 인공지능 꿈 실현..영화 속 컴퓨터에 영감 얻어 알렉사 개발...인공지능 생태계 선두주자 부상http://www.businesspost.co.kr/news/articleView.html?idxno=41564""인공지능이 세상을 먹어치운다""http://techm.kr/bbs/board.php?bo_table=article&wr_id=3646인공지능 개발하는 법을 배우는 인공지능 SW..구글 브레인, 오픈AI 등 연구 착수http://www.irobotnews.com/news/articleView.html?idxno=9713에어컨·공기청정기·전기밥솥이 똑똑해졌다...인공지능의 힘http://www.sporbiz.co.kr/news/articleView.html?idxno=71897인공지능 대중화 시대 빨라진다http://weekly.khan.co.kr/khnm.html?mode=view&code=114&artid=201701241705061&pt=nv구글, 라즈베리파이에 인공지능 탑재한다http://www.hellot.net/new_hellot/magazine/magazine_read.html?code=202&sub=004&idx=32834인공지능 의사 IBM '왓슨', 부산대병원서 진료 돕는다http://www.ebn.co.kr/news/view/873296인공지능 사용 소프트웨어 심장병 환자 사망 시기 예측한다http://www.mdtoday.co.kr/mdtoday/index.html?no=277870비고 : 빅데이터/딥러닝 솔루션 서비스 및 컨설팅 문의처 - 락플레이스 이승훈 실장, 010-9338-6400, hunlee@rockplace.co.kr "
" 인공신경망과 딥러닝이 겉보기에 비슷해보였다.그래서 어떤 점이 다른 건지 좀 더 알아보기로 하였다.인공신경망의 문제점에서 착안을 해서 딥러닝과 비교해 보려고한다.나의 생각은 인공신경망의 단점을 보안한 것이 딥러닝이라고 생각한다.[인공신경망의 문제점]1. 깊어지는 레이어 구조에서 파라미터들이 최적의 값을 찾기 어려워지는​지역최소값에 머무르게 되는 문제점 2. 불연속 시뮬레이션에서 초기 상태를 어떻게 선택하느냐에 따라 수렴이 안되고 진동 또는 발산하는 문제 3.트레이닝셋에 너무 가깝게 맞추어 학습되는 Overfitting 문제 (가중치 문제) 4. 느린 학습시간5. 계층 수가 늘어날수록 변화 방향을 상실하는 문제6.오류 역전파 알고리즘을 통해 발생하는 오차 신호가 사라지는 현상 [인공신경망의 발전 - 딥러닝]위 문제 중 과적합(overfitting) 문제를 살펴보자.이는 Weight decay(=regularization) 으로 해결한다.여기서 특히 2가지를 논한다.기존 신경망의 Overfitting 문제를 해결하기 위해 이들은 unsupervised RBM(restricted Boltzmann machine)을 통해 학습시킬 feedforward neural network의 각 층을 효과적으로 사전훈련(pre-trainning)하여 overfitting을 방지할 수 있는 수준의 initialize point를 잡았고, 이를 다시 supervised backpropagation를 사용하는 형태로 학습을 진행한다.또한 RBM을 대체하여 overfitting을 방지할 수 있는 Drop-out이라는 개념이 소개되면서 사전훈련 보다 훨씬 더 간단하고 강력한 형태로 overfitting을 방지가 가능하다.대부분이 Drop-out방식을 선택한다고 한다.매 학습시 은닉층에서 모든 neuron을 사용하는게 아니라 50%정도의 neuron을 사용한다.하나의 딥러닝에서 여러개의 작은 neural net이 앙상블되어진 효과가 있고, 앙상블은 과적합이 크게 줄어든다고 알려져 있다.또한, 비슷한 weight를 갖는 뉴런들이 줄어들게 되어서 중복된 판단을 하는 뉴런들이 줄어들게 되어 뉴런을 효율적으로 사용가능하다고 한다.​​또한 ReLU(Rectified Linear Unit) 라는 활성함수로 느린 학습시간과 가중치 문제 등을 해결 할 수 있다. 1.기존의 sigmoid함수는 기울기 하강(Gradient Descent)를 여러 층으로 해나갈 때 마다 error가 소멸되는 문제가 발생한다.(극한으로 갈 수록 sigmoid함수는 Gradient(기울기) 가 작아져서 weight가 업데이트 안되는 문제)그런데,ReLU 함수를 사용시, 기울기가 0 또는 1로 학습되는 경우에는 100%로 error가 전파되어 문제가 없다.2.sigmoid 처럼 [0,1]로 제한되는 것이 아니고 무제한이기 때문에 좀 더 확실한 표현력을 가진다고 볼 수 있다.3. 각 노드의 출력값 중 필요 없는 값들이 많다. 이럴 때, sigmoid함수 사용시 모든 값에 대한 계산을 해야하는데,ReLU함수는 상당 부분의 연산량을 줄일 수 있어 속도적인 면과, 필요없는 값을 줄일 수 있어서 좋다.그러하여서, 정규화(Regularization)이 강력하다.이 사이트에서 많은 도움을 받았다.http://slownews.kr/41461http://blog.naver.com/dusrb2003/220353638775딥러닝을 위한 기본 개념 및 단어정리(LeNet, Weight Decay, Regularization, Ove...1. LeNet a layered model composed of convolution and subsampling operations followed by a holistic ...blog.naver.com아직 부족한 점이 훨씬 많다.알고리즘을 더욱 깊이 공부하려하니 이건 무슨 ㅋㅋㅋㅋㅋ....하나 하나 정리하고 쌓아갈 예정이다. "
" 밑바닥부터 시작하는 딥러닝 작가 사이토 고키 출판 한빛미디어 발매 2017.01.03. 평점 리뷰보기 밑바닥부터 시작하는 딥러닝자율주행 자동차에 있어서 이미지 인식은 아주 중요합니다. 따라서 저자가 이것만 강조하여 빠르게 배울 수 있는 포인트를 선정하는 것은 정말 좋은 선택과 집중의 묘미가 있습니다.얇은 책을 먼저 반복해서 공부하는 것은, 효율적인 방법이 될 만하다고 하죠. 딱 딥러닝 분야에서 이 책은 그런 역할읗 잘 보여 줍니다. 정말 인공지능 뉴스가 하루라도 빠지지 않습니다. 마치 처음 인터넷이 등장하고 윈도우95가 등장하던 그런 때가 생각납니다. 그보다는 더욱 더 파괴적인 영향력을 끼칠 것 같습니다. 그래서 미루고 미룬 딥러닝 공부라면 딱 이 책부터 해보면 시간도 절약하고 전체적인 흐름을 좀 더 깊이있게 알게 됩니다. 다른 사람에게 듣는 딥러닝은 한계가 있습니다. 그래서 직접 열공 성공하는 길은 당연히 스스로 해보는 것이죠. 파이썬 기초부터 다루고 있습니다. 넘파이, matplotlib도 다루면서 파이썬 데이터분석을 빠르게 경험합니다. 파이썬을 처음 접하는 분들도 배려하고 있습니다. 퍼셉트론 / 신경망 / 신경망 학습 / 오차역전파법 / 합성곱 신경망 / 딥러닝 이렇게 알짜로만 배우기 위해 조금만 노력하면 되는 것이죠. 그렇게 흥미롭고 보람을 얻을 만한 시간을 이 작은 책, 얇은 책에서 경험할 수 있습니다. 물론 이미 잘 알려진 것처럼 이 분야는 수학을 새롭게 다시 공부하는 각오가 있어야 한다고 그렇죠. 당연히 인공지능적이라면 수학이 필요하겠죠. 물론 딥러닝 학습이라는 목적성을 위해 일단 빠르게 경험하는 것조차 행운입니다. 물론 저자는 특별히 ""누구를 위한 책이 아닌가"" 언급하면서 시작합니다. 즉, 딥러닝 분야 최신 연구, 상세한 이론, 튜닝, GPU 기술을 다루지 않고 자연어 처리, 음성 인식 등의 사례도 커버하지 않는다고 합니다. 이미지 인식은 그래도 굉장한 분야이죠. 그래서 일단 시작해보자. 그렇게 마음을 먹을 수 있습니다. 딥러닝 그 넘사벽이 완만한 동산 같이 느껴질 것입니다. 언제라도 마음 먹고 딱 주말 짧은 시간이라도 노력하면 어렵지 않게 완독을 할 것입니다. 그래서 저자에게 경의를 표하게 됩니다. 우리에게 정말 필요한 기술을 아주 쉽게 알려 주니 말이죠!!!// 한빛미디어 서평 리뷰단으로 책을 받은 후, 바쁜 일정 속에서도 충분히 읽고 열공할 수 있게 되었습니다. 한빛미디어 그리고 저자에게 감사드립니다. "
" 스탠포드 대학에서 9월 24~25일 딥러닝 스쿨을 개최합니다. 이를 위해서 bayareadlschool.org 란 도메인까지 등록을 하고 공개한 것으로 보아 상당한 규모의 프로젝트임을 알수 있습니다.아직 상세한 스케줄은 공개되어 있지 않지만 머신러닝 분야에서 일하고 있는 사람이라면 누구나 등록해서 참여가 가능할 것 같습니다. Yoshua Bengio, Andrej Karpathy, Hugo Larochelle, Richard Socher 등 발표자들의 라인업도 대단합니다. 이에 앞서 스탠포드 비전랩의 Fei-Fei 교수가 앞장서 진행했던 스탠포드 세일러즈(Stanford Sailors)도 있었습니다. 이 프로그램은 스탠포드 대학에서 통학이 가능한 범위내의 여고생(10th grade)들을 위한 무려 10일짜리 인공지능 서머 캠프입니다. 이 캠프에 참여한 교수와 PhD 학생들의 리스트와 블로그는 살펴볼 수록 더 놀랍습니다. 이 서머 캠프는 올해로 2번째이며 인공지능 분야의 인기에 걸맞게 올해는 구글, 드롭박스, 바이두 등 많은 스폰서가 생겨서 전액 무료로 진행되었습니다. 국내에서도 8월 8~12일까지 ‘인공지능 및 로보틱스 여름학교‘가 처음 열립니다. 세계의 추세에 맞추어 한국 또한 이와 같은 프로그램들이 민.관을 가리지 않고 좀더 발빠르고 폭넓게 추진 되길 기대 합니다.참고http://www.bayareadlschool.org/https://aifuture2016.stanford.edu/agendahttp://www.deeplearningbook.org/http://ai.stanford.edu/sailors/https://stanfordsailors.wordpress.com/http://ai.stanford.edu/sailors/people.htmlhttp://kros.org/summerschool2016/02web01.php "
" 2012년 6월 시작 천권 읽기 555권)알고리즘으로 배우는 인공지능, 머신러닝, 딥러닝 입문 김의중 저. *인상적인 구절: 인공지능은 여러 학문이 연계된 전형적인 융합 학문이다. 컴퓨터과학, 수학, 통계학을 중심으로 철학, 심리학, 의학, 언어학 등 실존하는 모든 학문이 광범위하게 연계돼있다. 인류 역사상 가장 오래된 학문 중 하나인 철학은 2,000년 이상 사람은 어떻게 인지하고, 배우고, 기억하고, 추론하는지에 대해 고민해 왔다. 철학에서는 기원전 400년경 이미 인공지능의 개념을 상상했다. 그것은 다름아닌 마인드mind라는 것이다. 철학에서는 마인드를 사람 안에 어떤 언어로 인코딩encoding된 지식을 조작하는 일종의 기계 같은 개념이라고 생각했다. 수학은 단연코 인공지능의 기반이 되는 학문이다. 수학에서 대수,논리학,확률론의 3개 핵심 분야는 철학에서 제안한 추상적인 아이디어를 증명하고, 알고리즘이라는 형태로 구현 방법을 제시한다. 인지 심리학은 인간과 동물들이 어떻게 정보를 인지하고, 저장하고, 분석 처리하느냐에 대한 동작 메커니즘을 밝히는데 중요한 역활을 한다. "
 텐서플로우 딥러닝 스터디...예전에 분명 선배들이 개발자는 수학 몰라도 된다 했었는데... 거짓말 쟁이들...ㅠ.ㅠ나는 사실 완전 수포자였지만... 다행히... 통계학과 유능한 대학생 선생님들 때문에 겨우겨우 어찌어찌 이어가고 있다... 그런데.... 담주엔 내가 정리해서 발표해야 하는데... 흠... 크리스마스니까 가족과 보내야 한다고 빵꾸내야 하나 ㅎㅎㅎ 아니면... 아프다고 해야 하나?? ㅋㅋㅋㅋㅋㅋㅠ.ㅠ ㅋ 
" ​ 딥러닝 실전수필 1. 딥러닝 실전수필은? - 전통적 수필 작법은 물론 문화, 영화, 음악, 철학, 역사를 접목한 글쓰기 능력을 배양하는 퓨전, 크로스오버 실전강좌. 개인 작품에 대한 첨삭 지도도 병행하며, 체계적이고 실용적인 강의를 진행함. - 처음 글을 쓰려거나 마냥 글이 좋은 분은 물론, 수필가로 활동하려거나 고품격 서정수필을 쓰려는 분. 시대의 화두인 인문학적인 배경 지식을 습득하여 차별화된 에세이를 쓰고 싶은 분 대상으로 함. * 보다 자세한 사항은, 한국산문 (02. 707-3071) 또는, 김창식(010. 3753 5354)에게 문의 2. 강의 기본 포맷 문화‧인문학 강의 - 문학 이론과 수필 작법 - 회원수필 합평 - 근‧현대 명수필 평설 3. 강의 제목(예: 학기 당) 1. 듀마의 소설과 제목 짓기/2.<벤허>는 왜 최고의 영화인가? /3. 팝송으로 읽는 비유와 상징 4. 개그콘 서트의 기호학/5. 미네르바의 부엉이와 소재포착/6. 십자군 전쟁의 함의와 전개 과정7. ‘시뮬라시옹’ ‘시뮬라크르’/8. 아프로디테의 황금사과/9. 무적함대 ‘아르마다’는 왜 패했나?/10. 수필 작성 사례-창(窓), 알(卵), 점(點/)11. 현대 명수필 감상/12. 소격효과와 낯설게 하기 4. 강사 김창식 수필가‧문화평론가‧칼럼니스트 흑구문학상, 조경희수필문학상, 한국수필작가회문학상 수상 수필집『안경점의 그레트헨』『문영음(文映音)을 사랑했네』 5. 기타 안내 - 장소: 한국산문 강의실(서울 종로구 율곡로 6길 36 월드오피스텔 207호) - 기간: 3개월 단위 계속 - 수강료: 210,000원(학기 당) - 수강료 납부: 개강일 및 수시 접수 5. 강의 내용(사례: 2016, 10. 6, 목) ‘글을 잘 쓰는 방법’《미네르바 성냥갑》-움베르토 에코 ​ a. 과장하지 마라! 감탄부호를 적게 써라! b. 접속사를 피하라. 꼭 필요할 때 써야만 c. 기성품 문장을 피하라. ‘다시 데운 스프’와 같다 d. 자신의 생각을 표현하라. 자신을 실 찌우게 하니까 e. 쉼표, 상업적 기호, 약자(&, etc. 등)는 사용치 않는다 f. 괄호는 문장의 흐름을 방해한다는 것을 (언제나) 기억하라 g. 따옴표(‘ ’)와 말없음표(......) 소화불량에 걸리지 않도록 h. 단어 하나로 만들어진 문장을 만들지 말라 i. 인용을 줄여라. 과잉설명을 하지마라. 일반화하지 마라 j. 과감한 은유를 조심하라. 뱀의 비늘 위에 돋은 깃털? k. 긴 문장 피하고 간략하게. 생각 압축. 정보 오염 주의 l. 우리는 등 ‘위엄 있는' 1인칭 복수를 쓰지 말라 m. 이례적이거나 ‘리좀’ 같은 어휘는 인지 역량을 넘어선다 n. 완성된 문장으로, 장황하지 않도록. 덜 말하지도 않도록 ​ * 움베르토 에코(Umberto Eco, 1932~2016) 이탈리아의 기호학자이며 역사학자·미학자·소설가. 아리스토텔레스, 토마스 아퀴나스의 철학 에서 퍼스널 컴퓨터에 이르기까지 다방면에 걸쳐 전문적 지식을 갖추었고 8개 국어에 통달해 레오나르도 다빈치 이래 최고의 르네상스적 인물이라는 칭호를 얻음. 1980년 첫 번째 발표한 베스트셀러 장편소설 『장미의 이름(Il nome della rosa)』으로 세 계적인 명상을 얻었으며, 연이어 『푸코의 진자(Il pendolo di Foucauilt)』 『전날의 섬 (L'isola del giornoprima)』을 발표함. 그 밖의 저서로 『기호학이론』이 있음. "
" 구글(Google)이 온라인 무료 강좌(MOOC, Massive Open Online Course) 서비스 중 하나인 유다시티(Udacity)에 기계학습(machine learning) 관련 강좌를 새로 개설했다. 강좌는 딥러닝(deep learning)에 대한 것이며 구글 내 수석과학자(principal scientist) 빈센트 반호크(Vincenet Vanhoucke)가 주 강의자로 나선다. 구글의 기계학습 플랫폼인 텐서플로우(TensorFlow)를 활용하는 과제가 많을 것으로 예상된다. 참고로 텐서플로우는 작년 11월에 공개되어 무료로 사용 가능한 기계학습 관련 플랫폼이다. 개인적으로는 크게 두 가지 생각이 든다. 첫째, 기계학습, 딥러닝, 또는 – 결이 다르지만 – 빅데이터와 관련된 강좌, 플랫폼 등이 최근 들어서 여기저기서 우후죽순으로 나타나고 있다. 무료로 무엇이 제공되는 것들이 상당히 많다. 기계학습의 가장 중요한 기능은 데이터화할 수 있는 모든 것들을 추상화, 정형화하여 예측하는데 있기 때문에 활용성이 상당히 높은 편이다. 데이터를 다루고 조작하는 플랫폼을 사람들이 많이 사용하면 할수록 이로부터 높은 부가가치를 창출할 수 있기 때문에 저마다 성공한 플랫폼이 되기 위해 수단과 방법을 가리지 않고 있다. 이번 무료 강좌도 그런 측면이 분명히 있다.둘��, 사실 이 부분은 내가 애써 외면하고 있는 부분이기도 한데, 온라인 무료 강좌의 양과 질이 날로 좋아지고 있다. 칸아카데미(Kahn academy)에서 추구하는 수준을 넘어서, 여기에 참여하는 해외 유수의 대학과, 각계 교수들도 폭발적으로 증가하고 있는 추세이다. 10~20년 후에는 – 그 시기는 더 빨리 올 수도 있다 – 대학을 포함한 정규 교육에 심각한 타격을 입힐 것이다. 학위라고 하는 것이 어떠한 의미를 가지고 있는가에 대해 사회적으로도 많이 논의가 될 것이다.질문. 기계학습/딥러닝에 대한 진입장벽이 낮아지면 어떤 일들이 벌어질까?주요 출처[1] The Verge, Google just published a free, three-month course on deep learning "
" 입시계의 절대강자 청솔학원과 프리미엄 인강으로 많은 학생들의 선택을 받은 이투스가 만난 강북독학재수학원 이투스24/7에서 N수생을 위한재수선행반과 예비 고1,2,3을 위한 윈터스쿨을 모집하고 있습니다. 다른 곳과는 차원이 다른 프로그램을 준비해놓고 있다는데요.어떤 것인지 구체적으로 알아보도록 하겠습니다 :)기존 강북독학재수학원 은 스스로 공부할 수 있는 환경을 마련하고,공부시간을 점검하는 정도에서 그쳤습니다.그러다보니 개인에게 모든 것을 맡기는 방식이었죠.하지만 그렇게 해서는 발전을 기대하기 어렵습니다. 그렇기에 이곳은 이투스의인강 관리 시스템인 24/7을 오프라인관리와 접목하여 독학의 효율을 최대로 높인 딥러닝 프로세스를적용하고 있습니다. ​ 딥러닝 프로세스는 '학습이해도와 취약 단원 점검 -> 일일 및 주간 인강 스케줄 작성 -> 인강 학습 및 오프라인 점검 반복 학습 -> 학습이해도와 취약 단원 점검' 의 프로세스를 반복하는 것인데요.이 과정을 진행하다보면 학습이해도가 높아지고 습득하는 학습내용이 증가하는 것은 물론인강을 어떻게 이용하는 것이 효율적인지, 인강의 효율을 높이는 나만의 공부방법이 무엇인지를 확실하게알 수 있습니다. ​ 중요한 것은 이투스와청솔학원이 맞닿았다는 점에도 있습니다. 이투스는인강으로 모든것을 보여주기 위해 노력하지만 인강 속에 교육철학과 교육전략이 모두 담길 수는 없습니다. 인강을 활용하는 방식 등은 오프라인에서 직접 학습매니저를통해 배우는 수 밖에 없죠, 또한 청솔학원의 오랜 노하우를 가진 강사가 직접 제공하는 특강 등은다른 어떤 강북독학재수학원 에서도 제공할 수 없는 최고의 특전입니다. 현재 재수생,삼수생 등을 위한 재수선행반과 예비고1, 고2,고3을 위한 윈터스쿨이 모집중에 있습니다. 4주의 기간 동안 한해를 준비할 수 있는 기반을 다지고 자기주도학습법을 배울 수 있는 기간이죠. ​ 또한윈터스쿨과재수선행반을 듣는 학생들을 위한 다양한 특전도 준비돼있습니다.내신 족보, 입시자료 등을 제공하는 것은 물론 다니는 4주동안 이투스인강 올-프리패스가 무/상으로 지원되고,차후 유/료구매 시 10/만/원 할인 혜택도 주어집니다. 또한 학습관리 프로그램인 이투스24/7 연간 멤버십도 제공됩니다.이 외에도 다양한 혜택이 있어 기간은 단 4주이지만 혜택은 1년동안 이어진다는것참고하시기 바랍니다. ^^ 대세는 자기주도학습입니다. 강북독학재수학원을 찾는 학생들은 대다수가 혼자서 공부하는 것이 편하고, 혼자서 공부해야 학습능률이 오른다고 생각할 것입니다. 하지만 명확한 자기주도학습방법이 없다면 확실한 효과를 볼 수 없습니다.일반 학생이라면 더 나은 공부방법을 고민하는데에 많은 시간이 걸릴수도 있습니다. 그 시간을 대폭 줄여줄 수 있는 곳이 바로 이곳입니다. 이제 함께 자기주도학습을 완성하세요 :) "
" 딥러닝을 공부하다 보면 많은 오픈소스로 공개되있는 프레임 워크들을 만날 수 있다.즉, 프로젝트 코드를 받아 직접 분석하고 테스트 해 볼 수 있다는 말이다. 물론 논문이나 과제를 할 땐 출처를 분명히 밝혀야 하지만 이런 기술들이 오픈되어있다는 것은 이 분야를 처음 접하는 사람들에게 정말 단비같은 일이다.본인도 그 동안 Caffe 라는 프레임 워크 위주로 공부했었지만 이번엔 Torch 에 관해 간략히 소개한다. Torch 는 Lua라는 생소한 언어를 사용해서 구현되어 있지만 조금만 살펴보면 Lua(루아)라는 언어도 파이썬과 유사하면서 가독성이 꽤 높은 언어임을 알 수 있다. 따라서 오히려 C/C++로 만들어진 Caffe보다 오히려 이해하고 접근하는데 더 쉬울 수도 있을 것 같다. 컴퓨터 비젼학회 중에서 가장 권위가 높은 컨퍼런스 중 하나인 CVPR에서 작년에 열린 세션들을 보면 3개의 큰 프레임 워크가 소개되는데 Caffe와 함께 Torch 가 맨 먼저 자리잡고 있다. Theano 도 언젠가 시간이 되면 맛볼까한다. 나는 하드코딩 유저는 절대 아니라고 생각하기 때문에(사실 딥러닝의 모든 구조들을 지금 와서 처음 부터 코딩하는건 애초부터 바보짓일듯..ㅎㅎ) 이런 프레임 워크들을 분석하고 공부해서 내 입맛대로 구현해 보는게 좋을 것이라 생각된다.Torch’s main site and resources: www.torch.chOn Github: https://github.com/torch➡ Tutorials for Torch: http://torch.madbits.comOn Github: https://github.com/clementfarabet/torch-tutorials➡ Lua: http://www.lua.orgLuaJIT: http://luajit.org/luajit.html 그럼 Torch + Lua 를 설치해 볼텐데, 나는 우분투 14.04 에서 진행했다.우분투에서 사용해보지 않은 명령어 curl 이나 pip 등을 사용하기 위해 업그레이드를 해준다.1. apt-get upgrade2. curl 설치 apt-get install curl apt-get install git3. Torch 및 LUAJIT 설치 curl -sk https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash curl -sk https://raw.githubusercontent.com/torch/ezinstall/master/install-luajit+torch | bash luarocks install env4. IPython 설치 pip install ""ipython[all]"" 에러나면, sudo apt-get install python-dev libxml2-dev libxslt-dev5. 디펜던시 설치 sudo apt-get install libzmq3-dev6. ITorch 설치 git clone https://github.com/facebook/iTorch.git cd iTorch luarocks make위의 1~6번이 본인이 Torch 를 돌려보기 위해 실제로 설치한 과정이다. 사실 Torch 의 Github 이나 홈페이지에 튜터리얼이 모두 있지만 다른 부분이 많았다. iPython을 설치할 때 [all]을 해주지 않으면 디펜던시 부분에서 에러가 나는 등 살짝 삽질을 했었던 것 같다.이까지 문제가 없이 진행되었다면 설치가 완료된 것이다.http://torch.madbits.com/wiki/doku.php?id=tutorial_basicstutorial_basics – Machine Learning with Torch7torch.madbits.com여기서 튜터리얼을 보고 따라하면서 직접 실습하면 된 상황이 된 것이다.~!터미널에 iTorch notebook 을 입력하면 이미지 파일들을 다룰 수있는 브라우저가 켜지면서 시작된다. "
" (출처 : 밑바닥부터 시작하는 딥러닝)0.신경망(딥러닝)의 기원이 되는 알고리즘인""퍼셉트론""에 대해 알아보겠습니다1. 퍼셉트론- 퍼셉트론은 다수의 신호를 입력으로 받아 하나의 신호를 출력한다- 퍼셉트론 신호는 흐름을 만들고 정보를 앞으로 전달한다- 퍼셉트론 신호는 '흐른다/안 흐른다(1이나 0)'의 두 가지 값을 가진다( 여기서는, '1 = 흐른다' '0 = 안 흐른다' )- '인공뉴런' 혹은 '단순 퍼셉트론'으로 불린다[그림1, 입력이 2개인 퍼셉트론] - [그림1]은 입력으로 2개의 신호를 받은 퍼셉트론의 예(x1, x2 = 입력신호 / y = 출력 신호 / w1, w2 = 가중치)- [그림1]의 원 = 뉴런 혹은 노드- 입력 신호(x)가 뉴런에 보내질 때는 각각의 고유한 가중치(w)가 곱해진다(w1*x1, w2*x2)- 뉴런에서 보내온 신호의 총합이 정해진 한계를 넘어설 때만 1을 출력( = 뉴런이 활성화한다)(*그 한계 값은 = 임계값 = 세타)[그림2, 퍼셉트론 공식]- 퍼셉트론은 복수의 입력 신호 각각에 고유한 가중치를 부여한다- 가중치는 각 신호가 결과에 주는 영향력을 조절하는 요소로 작용한다- 즉, 가중치가 클수록 해당 신호가 그 만큼 더 중요함2. 논리회로2.1. AND 게이트- AND게이트는 입력이 둘이고 출력은 하나이다[그림3, and게이트] - 위와 같은 입력 신호와 출력 신호의 대응표를 '진리표'라고 한다- 위의 그림에서, 두 입력이 모두 1일 때만 1을 출력하고, 그 외에는 0을 출력한다2.1.1. AND게이트 by 퍼셉트론- AND게이트를 퍼셉트론으로 표현하기 위해서는 진리표에 작동하는 가중치와 임계값을 설정해야 한다- 위의 그림을 충족하는 가중치와 임계값을 설정하기 위한 매개 변수 조합은 정말 많다- 가령 (w1, w2, 임계점)일 경우=> (0.5, 0.5, 0.7)=> (0.5, 0.5, 0.8)=> (1.0, 1.0, 1.0)- 위의 매개변수를 적용하면 x1과 x2가 모두 1일 때만 신호의 총합이 주어진 임계값을 넘게된다 ( = 신호가 활성화 된다)2.2. NAND 게이트- Not AND를 뜻한다- 즉, AND 게이트의 출력을 뒤집은 것이다( = x1과 x2가 모두 1일 때만 0을 출력하고, 그 외에는 1을 출력한다)[그림4, NAND게이트 진리표] - 위를 만족하는 매개변수 조합=> (-0.5, -0.5, -0.7)- 사실 AND 게이트를 구현하는 매개변수의 부호를 모두 반전하면 NAND게이트가 됨2.3. OR 게이트- OR 게이트는 입력 신호 중 하나 이상이 1이면 출력이 1이 되는 논리회로[그림5, OR 게이트 진리표] 3. 퍼셉트론 by 컴퓨터- 여기서 퍼셉트론의 매개변수 값을 정하는 것은 컴퓨터가 아닌 우리 인간- 기계학습은 이 매개변수의 값을 정하는 작업을 컴퓨터가 자동으로 하도록 함- 학습 = 적절한 매개변수 값을 정하는 작업- 사람은 퍼셉트론의 구조를 고민하고 컴퓨터에 학습할 데이터를 주는 일을 함 "
" Deep learning 을 위한 TensorFlow 텐서플로우는 원래 구글의 인공지능 관련 연구팀인 Google brain팀에서 소속 연구원 및 엔지니어들이 머신러닝, 딥러닝 연구를 목적으로 만들어진 라이브러리이다. 텐서플로우는 노드(Node)와 엣지(Edge)로 구성된 Data flow graph 형태의 구조로 수치 계산을 위해 사용된다. 그래프의 노드는 수학적 연산 역할을 하고, 노드 사이에 연결된 엣지는 연결된 노드들 사이에서 전달되는 텐서(다차원 데이터 배열)의 역할을 한다. 텐서플로우는 별도의 라이브러리 없이 하나 이상의 CPU와 GPU를 적절히 분산시켜 사용할 수 있다는 것이 큰 장점이다.(https://www.tensorflow.org) 텐서플로우를 이용하는 세계적인 기업들 텐서플로우의 아키텍쳐를 살펴보자 (출처:https://www.tensorflow.org/extend/architecture)텐서플로우 런타임은 cross-platform 라이브러리로 C++, Python, Java, GO 등 여러 언어에서 사용할 수 있다.구조는 역할에 따라 크게 Client, Distributed master, Worker Service, Kernel implementation 으로 나눠진다.Client는 수행해야할 계산을 그래프의 흐름으로써 정의한다. 그리고 세션을 이용해 그래프 계산을 시작한다. Distributed master는 부분 그래프 계산 작업을 서로 다른 장치 및 프로세서에서 실행될 수 있도록 분할 해준다.즉, 그래프의 부분을 다시 여러 태스크로 나눠 일을 분배해주는 것이다. 일을 쪼개고 나면 각 Worker service에게 일을 나눠서 배포한다.그리고 Worker service의 일을 시작하게 명령하는 역할도 담당한다.Worker service는 일이 할당되면 사용가능한 하드웨어(CPU,GPU 등)에 적절한 Kernel implementation을 사용하여 할당 받은 그래프 작업을 실행할 수 있도록 스케줄링한다.Kernel implementation이 실질적으로 각 그래프 작업에 대한 계산을 수행하게 된다. 그리고 결과는 상위단계로 전달된다.마치 하나의 회사에서 하는 업무와 같은 구조이다. Client는 하나의 프로젝트를 기획 및 설계를 하고, 이 프로젝트를 진행하는 팀의 팀장인 Distributed master에게 업무를 전달한다. 팀장은 업무를 나누어 사원 Worker service들에게 업무의 일부분을 지시한다. 사원은 각자의 기기 Kernel implementation을 이용하여 일을 처리하고, 결과를 확인하여 팀장에게 보고한다. 팀장은 모든 사원들의 결과를 모아 최종 보고서를 Client에게 전달하게된다. 알고리즘에서는 Divide&conquer 와 유사하다. 특히 Merge sort와 처리하는 구조가 흡사하며, 구글에서 빠른 검색을 위해 고안한 Map&Reduce도 같은 맥락이라고 볼 수 있을 것 같다. 각 컴포넌트별 자세한 동작 방식은 텐서플로우 공식 홈페이지에서 확인할 수 있다.https://www.tensorflow.org/extend/architecture현재 텐서플로우 외에도 딥러닝을 위한 다양한 라이브러리가 존재한다. caffe, keras, Java용 라이브러리 ND4J 등 많은 라이브러리가 제공되고 있다. 이 중 무엇을 사용해야할 지 고민이 될 수도 있다. (출처:https://twitter.com/fchollet/status/830499993450450944)고맙게도 누군가 github에 등록된 프로젝트들의 정보를 이용해 각 딥러닝 라이브러리의 사용정도를 비교하기 좋게 분석해주었다.딥러닝을 시작하는 입장에서 라이브러리 선택은 자유지만 이왕이면 앞으로도 많은 사람들에 의해 사용되고, 발전 가능성이 있는 라이브러리를 선택하는게 좋을 것이라고 판단된다. "
" [ref. http://hunkim.github.io/ml/]모두를 위한 머신러닝과 딥러닝의 강의알파고와 이세돌의 경기를 보면서 이제 머신 러닝이 인간이 잘 한다고 여겨진 직관과 의사 결정능력에서도 충분한 데이타가 있으면 어느정도 또는 우리보다 더 잘할수도 있다는 생각을 많이 하게 되었습니다. Andrew Ng 교수님이 말씀하신것 처럼 이런 시대에 머신 러닝을 잘 이해하고 잘 다룰수 있다면 그야말로 ""Super Power""를 가지게 되는 것이 아닌가 생각합니다.더 많은 분들이 머신 러닝과 딥러닝에 대해 더 이해하고 본인들의 문제를 이 멋진 도구를 이용해서 풀수 있게 하기위해 비디오 강의를 준비하였습니다. 더 나아가 이론에만 그치지 않고 최근 구글이 공개한 머신러닝을 위한 오픈소스인 TensorFlow를 이용해서 이론을 구현해 볼수 있도록 하였습니다.수학이나 컴퓨터 공학적인 지식이 없이도 쉽게 볼수 있도록 만들려고 노력하였습니다. 시즌 RL - Deep Reinforcement Learning비디오 리스트 (일주일에 한강좌씩 천천이 업데이트 예정입니다.) Lecture 1: 수업의 개요 비디오 강의 슬라이드 Lecture 2: OpenAI GYM 게임해보기 비디오 강의 슬라이드 Lab 2: OpenAI GYM 게임해보기 실습 비디오 실습슬라이드 Lecture 3: Dummy Q-learning (table) 비디오 강의 슬라이드 Lab 3: Dummy Q-learning (table) 비디오 실습슬라이드 Lecture 4: Q-learning exploit&exploration and discounted reward 비디오 강의 슬라이드 Lab 4: Q-learning exploit&exploration and discounted reward 비디오 실습슬라이드 Lecture 5: Q-learning in non-deterministic world 비디오 강의 슬라이드 Lab 5: Q-learning in non-deterministic world 비디오 실습슬라이드 Lab 5-1: Q-learning web Demo 비디오 Lecture 6: Q-Network 비디오 강의 슬라이드 Lab 6-1: Q Network for Frozen Lake 비디오 실습슬라이드 Lab 6-2: Q Network for Cart Pole 비디오 실습슬라이드 Lecture 7: DQN 비디오 강의 슬라이드 Lab 7-1: DQN 1 (NIPS 2013) 비디오 실습슬라이드 Lab 7-2: DQN 2 (Nature 2015) 비디오 실습슬라이드 Lab 7-3: DQN Cart Pole Demo 비디오 Lab 7-4: DQN Simple Pacman Demo (여러분은 최고 몇점까지 갈수 있나요?) 비디오 시즌 NLP - Deep NLP(시즌 RL이 끝나는 2017년 4~5월경에 업데이트 예정입니다.) Lec 0: 수업의 개요 비디오 슬라이드 Bot lab1-1: API.ai의 개념 비디오 Bot lab1-2: API.ai 사용해보기 비디오 시즌 1 - 딥러닝의 기본 (종강) 비디오 리스트 전승현님이 만들어주신 코드 https://github.com/FuZer/Study_TensorFlow수업에 사용한 Lab 슬라이드 전체 (이전 버전의 API사용과 오타가 있으니 주의)수업의 개요 비디오 슬라이드 머신러닝의 개념과 용어 비디오 (TensorFlow의 기본 Lab 비디오 ) 슬라이드 Linear Regression 의 개념 비디오 (TensorFlow 로 구현 Lab 비디오 ) 슬라이드 Linear Regression cost함수 최소화 비디오 (TensorFlow 로 구현 Lab 비디오 ) 슬라이드 여러개의 입력(feature)의 Linear Regression 비디오 (TensorFlow 로 구현 Lab 비디오 ) 슬라이드 Logistic (Regression) Classification 슬라이드 Hypothesis 함수 소개 비디오 Cost 함수 소개 비디오 TensorFlow에서의 구현 비디오 Softmax Regression (Multinomial Logistic Regression) 슬라이드 Multinomial 개념 소개 비디오 Cost 함수 소개 비디오 TensorFlow에서의 구현 비디오 ML의 실용과 몇가지 팁 슬라이드 학습 rate, Overfitting, 그리고 일반화 (Regularization) 비디오 Training/Testing 데이타 셋 비디오 TensorFlow에서의 구현 (학습 rate, training/test 셋으로 성능평가) 비디오 딥러닝의 기본 개념과, 문제, 그리고 해결 슬라이드 딥러닝의 기본 개념: 시작과 XOR 문제 비디오 딥러닝의 기본 개념2: Back-propagation 과 2006/2007 '딥'의 출현 비디오 실습비디오 없음Neural Network 1: XOR 문제와 학습방법, Backpropagation (1986 breakthrough) 강의 슬라이드 실습 슬라이드 XOR 문제 딥러닝으로 풀기 비디오 특별편: 10분안에 미분 정리하기 비디오 딥넷트웍 학습 시키기 (backpropagation) 비디오 실습1: XOR을 위한 텐스플로우 딥넷트웍 비디오 실습2: Tensor Board로 딥네트웍 들여다보기 비디오 Neural Network 2: ReLU and 초기값 정하기 (2006/2007 breakthrough) 강의 슬라이드 실습 슬라이드 XSigmoid 보다 ReLU가 더 좋아 비디오 Weight 초기화 잘해보자 비디오 Dropout 과 앙상블 비디오 레고처럼 넷트웍 모듈을 마음껏 쌓아 보자 비디오 실습: 딥러닝으로 MNIST 98%이상 해보기 비디오 Convolutional Neural Networks 강의 슬라이드 실습 슬라이드 ConvNet의 Conv 레이어 만들기 비디오 ConvNet Max pooling 과 Full Network 비디오 ConvNet의 활용예 비디오 실습: ConvNet을 TensorFlow로 구현하자 (MNIST 99%) 비디오 Recurrent Neural Network 강의 슬라이드 실습 슬라이드 NN의 꽃 RNN 이야기 비디오 실습: TensorFlow에서 RNN 구현하기 비디오 [보너스] Deep Deep Network AWS 에서 GPU와 돌려보기 (powered by AWS) 실습 슬라이드 비디오 [보너스2] AWS에서 저렴하게 Spot Instance를 터미네이션 걱정없이 사용하기 (powered by AWS) 실습 슬라이드 비디오 [보너스3] Google Cloud ML을 이용해 TensorFlow 실행하기 실습 슬라이드 비디오 (한글) 비디오 (영어) Acknowledgement이 비디오는 저도 인터넷등을 통해 공부하면서 만든것이며 아래 자료를 많이 사용하였습니다.Andrew Ng’s and other ML tutorialshttps://class.coursera.org/ml-003/lecturehttp://www.holehouse.org/mlclass/ (note)Deep Learning TutorialAndrej Karpathy's Youtube channel 동국대 홍정모 교수님의 C++로 배우는 딥러닝 Lecture VideosCS231n: Convolutional Neural Networks for Visual RecognitionCS224d: Deep Learning for Natural Language ProcessingTensorflowhttps://www.tensorflow.orgTensorFlow Tutorials (Simple Examples)Another TensorFlow TutorialsTensorFlow ExamplesDeep learning @Udacity "
" 딥러닝(rnn)을 이용한 주가 예측 결과인데, HKUST 김성훈 교수님 깃헙에서 약간 코드를 수정하여 실험해 보았다.(왼쪽이 train data 및 예측 결과, 오른쪽이 test data 및 예측 결과.)직전 7일간의 시가/종가/저가/고가/거래량을 데이터로 학습시킨 결과이다. 400~2000번 사이의 학습 결과가 오버피팅이 적고, 2000번 이상 진행하게 되면 RMSE가 0.30 이상에서 밑으로 내려오질 못한다.1) 생각보다 시계열 학습이 잘되고,2) 일단 아무 종목이나 코스피 실제 데이터 넣어서 해보고 싶고,3) 적절한 학습 횟수, seq_length와 hidden_dim의 최적점도 고찰이 필요하다. 특히 주식 항목에 의존하는지 궁금.4) input_dim을 해당 주식의 데이터 뿐만 아니라, 환율, 각종 인덱스, 계열사, 협력사 주가 정보도 넣어보면 어떻게 될지 궁금.[step: 0] loss: 69.09278106689453 RMSE(test): 0.5288500189781189 [step: 100] loss: 0.8329199552536011 RMSE(test): 0.03500033915042877 [step: 200] loss: 0.6910057067871094 RMSE(test): 0.029860801994800568 [step: 300] loss: 0.5967426300048828 RMSE(test): 0.027198301628232002 [step: 400] loss: 0.5402294397354126 RMSE(test): 0.025497671216726303 [step: 500] loss: 0.49758052825927734 RMSE(test): 0.024294156581163406 [step: 600] loss: 0.4670945703983307 RMSE(test): 0.023671239614486694 [step: 700] loss: 0.44653746485710144 RMSE(test): 0.023540738970041275 [step: 800] loss: 0.431912899017334 RMSE(test): 0.02377583459019661 [step: 900] loss: 0.42075011134147644 RMSE(test): 0.024199118837714195 [step: 1000] loss: 0.41144683957099915 RMSE(test): 0.02460731752216816 [step: 1100] loss: 0.4026947617530823 RMSE(test): 0.02493477612733841 [step: 1200] loss: 0.3940300941467285 RMSE(test): 0.025208519771695137 [step: 1300] loss: 0.38583093881607056 RMSE(test): 0.025441301986575127 [step: 1400] loss: 0.3782137930393219 RMSE(test): 0.025617677718400955 [step: 1500] loss: 0.37085089087486267 RMSE(test): 0.025800911709666252 [step: 1600] loss: 0.3666529357433319 RMSE(test): 0.025909852236509323 [step: 1700] loss: 0.359618604183197 RMSE(test): 0.026508860290050507 [step: 1800] loss: 0.3537199795246124 RMSE(test): 0.02693178504705429 [step: 1900] loss: 0.3692275881767273 RMSE(test): 0.028618328273296356 [step: 2000] loss: 0.342058002948761 RMSE(test): 0.027876226231455803 [step: 2100] loss: 0.33600300550460815 RMSE(test): 0.02896985225379467 [step: 2200] loss: 0.3594988286495209 RMSE(test): 0.028440367430448532 [step: 2300] loss: 0.32883429527282715 RMSE(test): 0.030284656211733818 [step: 2400] loss: 0.3255539536476135 RMSE(test): 0.030970897525548935 [step: 2500] loss: 0.3226870000362396 RMSE(test): 0.031199298799037933 [step: 2600] loss: 0.32302242517471313 RMSE(test): 0.029996180906891823 [step: 2700] loss: 0.3183594048023224 RMSE(test): 0.0313357338309288 [step: 2800] loss: 0.3157694339752197 RMSE(test): 0.03139820694923401 [step: 2900] loss: 0.49994733929634094 RMSE(test): 0.03589856997132301 [step: 3000] loss: 0.31135791540145874 RMSE(test): 0.03133353963494301 [step: 3100] loss: 0.308290034532547 RMSE(test): 0.03150351345539093 [step: 3200] loss: 0.3049423396587372 RMSE(test): 0.031307220458984375 [step: 3300] loss: 0.3041365146636963 RMSE(test): 0.03438039496541023 [step: 3400] loss: 0.29827338457107544 RMSE(test): 0.031409263610839844 [step: 3500] loss: 0.29366999864578247 RMSE(test): 0.031056653708219528 [step: 3600] loss: 0.2885873317718506 RMSE(test): 0.03045172616839409 [step: 3700] loss: 0.29769521951675415 RMSE(test): 0.02953011728823185 [step: 3800] loss: 0.27865472435951233 RMSE(test): 0.03052441217005253 [step: 3900] loss: 0.2732591927051544 RMSE(test): 0.03013918548822403 [step: 4000] loss: 0.26821428537368774 RMSE(test): 0.029958728700876236 [step: 4100] loss: 0.26641571521759033 RMSE(test): 0.030275214463472366 [step: 4200] loss: 0.2607392370700836 RMSE(test): 0.03057299368083477 [step: 4300] loss: 0.25734254717826843 RMSE(test): 0.03050682693719864 [step: 4400] loss: 0.2541470229625702 RMSE(test): 0.030560441315174103 [step: 4500] loss: 0.2525787353515625 RMSE(test): 0.03188183158636093 [step: 4600] loss: 0.24940435588359833 RMSE(test): 0.031299836933612823 [step: 4700] loss: 0.24634677171707153 RMSE(test): 0.031296465545892715 [step: 4800] loss: 0.45580750703811646 RMSE(test): 0.037602778524160385 [step: 4900] loss: 0.24118417501449585 RMSE(test): 0.031591758131980896 training end <class 'numpy.ndarray'> "
" [GTC 2015] 타이탄 X로 만나는 딥러닝의 세계: 소프트웨어부터 데브박스까지 ﻿안녕하세요, 엔비입니다. 한국 시각으로 바로 오늘 새벽, 엔비디아는 그래픽 기술의 세계적인 컨퍼런스인 GTC 2015를 엔비디아 본사가 있는 산호세에서 개최했는데요. 올해도 역시 엔비디아가 발전시키고, 또 앞으로 주목하고자 하는 다양한 기술들이 소개되었습니다. 그에 대한 내용을 앞으로 차례대로 소개해 드리겠습니다. 이번에는 그 첫번째, 딥 러닝에 대한 이야기 입니다. ​오늘날 언급되는 가장 복잡한 기술적 도전 중 하나가 바로 딥 러닝 (Deep Learning)인데요. 엔비디아는 딥러닝 연구에 있어 전례없는 속도와 유용함, 그리고 새로운 동력을 지닌 새로운 하드웨어와 소프트웨어를 이번 GTC 2015에서 소개하게 되었습니다. ​딥러닝은 빠르게 성장하고 있는 가상지능의 한 부분으로써 선진화된 의학/ 약학 연구부터 자동주행 차량까지, 그야말로 활용 범주가 다양한 컴퓨팅 혁신의 엔진이라고 할 수 있겠습니다. 엔비디아 CEO인 젠슨황 (Jen-Hsun Huang)은 4,000명의 참석자들에게 답러닝을 가속화 시킬 새로운 기술 3가지를 소개했는데요. 살펴볼까요? 딥 뉴럴 네트워크 훈련을 위한 가장 강력한 프로세서, 엔비디아 지포스 GTX 타이탄 X엔비디아 코리아 페이스북에서 사진으로 살짝 겉모습을 공개했던, 엔비디아 지포스 GTX 타이탄 X (NVIDIA GeForce TITAN X)가 이날 젠슨황 엔비디아 CEO의 키노트에서 자세히 소개되었습니다. ​ ​​타이탄 X는 엔비디아의 새로운 주력 모델인 지포스 게이밍 GPU이지만, 딥 러닝에도 안성 맞춤이라고 할 수 있습니다. 영화 '호빗'에 나온 용, 스마우그에 기초한 '그림자 속의 도둑 (Thief in the shadow)""을 기억하시나요? 2주전 샌프란시스코에서 열린 게임 개발자 컨퍼런스 (GDC 2015)에서 타이탄 X를 활용한 이 맛보기 영상이 소개되었는데요. 이와 같이 가장 최근 출시된 AAA급 게임의 4K급 그래픽 구현은 타이탄 X에게 간단한 일입니다. 예를 들어, <반지의 제왕_중간계: 모르도르의 그림자> 는 지포스 GTX 980의 구동력이 30fp인 것과 비교했을때, 이용 가능한 FXAA를 탑재하고 최고 옵션을 설정하면 1초당 40프레임을 구현하는 것이 가능합니다. ​​엔비디아의 맥스웰 GPU 아키텍쳐 (Maxwell GPU architecture) 를 기반으로 한 타이탄 X는 12GB의 온보드 메모리로 3,072개의 프로세싱 코어를 결합한 점이 특징입니다. 이전 모델보다 퍼포먼스와 동력 효율성이 두배로, 최고의 퍼포먼스를 보여주죠. 최고의 프로세싱 동력과 336.5GB/s 의 메모리 대역폭으로 딥 뉴럴 네트워크를 훈련시키는데 사용된 수많은 데이터들을 세분화 할 수 있는 능력을 가지고 있답니다. 예를 들어, 알렉스넷(AlexNet)의 산업별 표준비율 모델에서는 16-코어 CPU에서 데이터 분할에 40일이 넘게 걸린 반면, 1,200만 개의 이미지넷의 데이터 세트를 분석하고 훈련시키는데 타이탄 X로는 3일도 채 걸리지 않은 것이 그 증거가 될 것입니다. 타이탄 X는 미국 달러 기준 999불에 판매될 계획입니다. 디짓 딥러닝 훈련 시스템: 최고의 딥 뉴럴 넷 (Deep Neural Net)으로 향하는 빠르고 유용한 소프트웨어​컴퓨터가 물건을 분류하고 스스로 인식할 수 있도록 훈련시키는 딥 뉴럴 네트워크 (Deep Neural Network, DNN, 심층 신경망)가 최근 화두입니다. 그렇지만 이와 같이 컴퓨터에 딥 러닝을 적용하는 것은 과중하고, 시간이 소비되는 업무일 겁니다. 이번에 엔비디아는 GTC 2015에서 소개한 디짓 딥러닝 GPU 훈련 시스템 소프트웨어 (DIGITS Deep Learning GPU Traning Software) 를 통해서, 가능한 최상의 딥 뉴럴 네트우크를 구축하기 위해 유저둘에게 그들이 처음부터 끝까지 필요한 모든것을 제공하여 이 분야를 변화시켜 나갈 계획입니다. ​​실제로 소프트웨어는 개발자 사이트에서 다운로드 가능합니다. (http://developer.nvidia.com/digits) 이것은 이미지 분류를 위한 딥 뉴럴 네트워크를 디자인하고, 훈련하며, 검증하는 최초의 올인원 그래픽 시스템이죠. 디짓은 사용자들에게 딥 뉴럴 네트워크의 세팅, 환경 설정, 훈련 과정을 인도합니다. 사용자들이 실제 연구와 결과에 집중할 수 있도록 까다로운 과정을 다뤄주는 건데요. 직관적 사용자 인터페이스와 워크 플로우 관리 능력 덕분에 지역 시스템이나 웹 상 어디든지 디짓에 데이터 세트를 준비하고 로드 해 오는 것이 단순해졌습니다. ​ 사용자들이 그들의 작업을 세부 조정할 수 있도록 실시간 모니터링과 시각화를 제공하는 것은 이러한 소프트웨어 중 최초 입니다. 오늘날 뉴럴 네트워크를 구축하기 위해 많은 과학자와 연구자들이 데이터에 사용하는 대중적 프레임 워크인 카페 (Caffe) 의 가속화된 GPU버전을 지원할 계획입니다. 디짓 데브박스 (DIGITS DevBox): 세상에서 가장 빠른, 내 책상 옆 딥러닝의 구현 또 다른 놀랄만한 결과물은 바로 엔비디아 딥러닝 엔지니어링 팀이 자신들의 R&D 과업을 위해 구축한 디짓 데브박스 (DIGIT Dev Box) 입니다. 디짓 데브박스는 딥러닝 연구를 가속화 시키기 위해 일원화 된 플랫폼을 말합니다. 4개의 타이탄 X 로 시작한 개발자 박스는 메모리에 I/O, 동력까지 - 모든 구성 요서들이 가장 어려운 딥러닝 연구의 효율적인 퍼포먼스를 수행하기 위해 최적화 되어 있습니다. 이것은 데이터 과학자와 연구자들이 자신들의 딥 뉴럴 네트워크를 발전시키는 데 필요한 모든 소프트웨어가 미리 설치되어 나오게 해 줍니다. 이러한 소프트웨어는 가장 대중적인 딥러닝 프레임 워크인 카페 (Caffe), 테아노 (Theano) 그리고 토치 (Torch)-인 디짓 소프트웨어 패키지와 엔비디아의 강력한 GPU로 가속화 되는 딥러닝 라이브러리인 cuDNN 2.0을 포함하고 있습니다. 이것은 책상 아래에 놓을 수도 있고, 기본적으로 벽에 설비된 콘센트에 꽃아 효율적으로, 조용하게, 멋지게 구동될 수 있게끔 패키지로 포장되어 있습니다. 초기 멀티 -GPU 훈련의 결과는 디짓 데브박스가 중요한 딥러닝 벤치마크에서 한개의 타이탄 X 보다 무려 4배나 높은 퍼포먼스를 수행 할 수 있다는 것을 보여주었습니다. 최고 사양의 GPU를 탑재한 PC 한대가 이틀이상 소요된 것 혹은 CPU만 사용하는 시스템에서 한달 이상 소요된 것과 비교했을때, 알렉스 넷 (Alex Net)을 적용해 훈련하는 것은 13시간에 가능한 것이 바로 디짓 데브박스의 위력을 입증합니다. 엔비디아의 기술력은 게임과 영화 등 우리 삶에 밀접한 그래픽을 뛰어넘어, 보다 많은 분야를 발전시킬 과학과 연구분야로 그 영역을 넓혀나가고 있는데요. 이번에 발표된 타이탄 X, 딥러닝 훈련 시스템과 데브박스가 그 본격적인 시작이 되지 않을까 합니다. 다음 이야기에서도 GTC 2015에서 소개된 놀라운 기술의 발전을 들고 찾아뵙겠습니다. ​ ​​ "
 최근 들어서 알파고와 이세돌 9단과의 대국으로 딥러닝이 각광받고 있다. 그러다보니 요즘은 본디 딥러닝의 근원이였던 AI를 넘어서 이것저것에다가 알파고와 딥러닝을 같다 붙이는 유행이 일고 있다.근데 솔직히 말하면 꼴사납다.특히 그 꼴사나운 짓거리의 최고 1순위는 대치동에서 아이들을 위한 딥러닝 학습법이니 뭐니 하면서 한다는데 정말 웃기는 짓거리다. 과연 이거 가르치는 사람들은 딥러닝 알고리즘이 정확하게 뭔지 알고 있을지 모르겠다.딥러닝 알고리즘은 그냥 쉽게 풀어쓰면 엄청나게 많은 경험자료들을 때려박는 것이다. 사람이 공부하는 방법중에서 가장 무식하지만 가장 원초적이고 기억에 오래남는 것이 실제로 경험해보는 것이다. 백문이불여일견. 이게 바로 딥러닝이다. 수많은 경험자료들을 묶고 분류해서 이 경험들을 토대로 현재 해내야하는 선택에서 가장 합리적이라 생각하는 선택을 내리는게 바로 딥러닝이란 것이다.그럼 그 딥러닝으로 애들을 제대로 가르치려면? 당장 애들을 학원에 집어넣는 짓 부터 그만둬라 라고 하고싶다. 딥러닝 학습법이니 뭐니하면서 애들을 잡아둘게 아니라.아무리 고성능의 컴퓨터를 가진 알파고라 하더라도 딥러닝 학습법이랍시고 가져오는 비슷비슷한 내용의 데이터들로만 가득 채우면 이세돌 9단은 커녕 바둑 좀 배웠다 하는 학생도 이기지 못한다. 요컨데 다양한 경험이 필요한 것이다. 결국 학원에서 틀에박힌 경험만 쌓으면서 세상을 바라보길 바란다면 그건 과욕이고 자기모순이다. 당장 아이들을 뭐든간에 새로운걸 보여주면서 다양한 경험을 시키고 스스로 생각하게끔 만들어야 제대로 된 딥러닝 학습법이라 할 수 있다. 딥러닝 학습법으로 영어를 잘하게 하고싶다? 수학을 잘하게 하고싶다? 웃기지 말라. 그래봐야 기존에 있던 학습법들과 다를게 없다. 다를 수가 없다. 수많은 경험을 때려박는 짓은 옛날부터 인간이 해오던 짓이니까. 그런식으로 딥러닝이란 알고리즘을 변질시키지 마라. 더러운 상술에 지나지 않는다. 
 앞의 미분 강의에 이어지는 수치 미분 numerical differentiaion 강의 입니다.딥러닝을 제대로 하기 위해서 반드시 이해해야 하는 gradient descent method로 이어집니다.'C++로 배우는 딥러닝' 메인 페이지http://blog.naver.com/atelierjpro/220697890605 
" 2014년 가트너가 주목해야 할 IT 기술 중 하나로 딥러닝(Deep Learning)을 선정한 후, 이에 대한 관심도 급속도로 증가했습니다. 오늘은 딥러닝에 대한 최근 트렌드를 살펴보고자 하는데요. 사실 저도 기계학습(Machine Learning)에 대해서 깊이 있게 알지는 못합니다. (깊이 있게 알려고 해도 너무 어려운 분야이기도 하고요^^;) 하지만 최근 시장 동향이 예사롭지 않아 그간 관심 있게 모아둔 자료들을 요약. 정리하는 차원에서 포스팅 주제로 선정해 보았습니다. 인공지능, 머신러닝, 빅데이터, 데이터마이닝… 등의 핫 키워드가 회자되는 순간, 이러한 기술 동향에 대해 아는 척이라도 하려면 반드시 알아두어야 할 기술이 바로 ‘딥러닝’이기도 합니다.참조 1. Top Predictions for IT Organizations and Users for 2014 and Beyond 딥러닝이란?딥러닝은 쉽게 말해 컴퓨터가 마치 인간처럼 생각하고 학습할 수 있도록 하는 기계학습의 한 분야로, 사물이나 데이터를 군집화하거나 분류하는 데 사용하는 기술적 방법론을 이야기합니다. 예를 들어 사람은 이미지를 보고 고양이와 개를 쉽게 구분할 수 있는데 컴퓨터는 할 수 없었죠. 컴퓨터는 주어진 질문이나 정보에 대해서는 정확한 답변을 내놓지만, 그것들이 내재하고 있는 추상적인 부분에 대해서는 판단하지 못하는 약점을 가지고 있습니다. 이처럼 대상에 내재되어 있는 2차원적인 의미들을 파악하고 위와 같은 구분을 학습시키기 위해 기계학습이라는 방법이 고안되었습니다. 수많은 데이터를 컴퓨터에 입력하고 유사한 것들끼리 분류하여 대상을 인식하도록 학습시키는 것인데요. 저장된 개 이미지와 비슷한 이미지가 입력되면 컴퓨터가 스스로 이를 개 이미지로 분류할 수 있게 한 것입니다. 구글은 스탠포드대학의 앤드류 응(Andrew NG) 박사와 구성한 딥러닝 프로젝트의 연구를 통해, 2012년 컴퓨터가 1천만개의 유투브 동영상 중 고양이 영상을 스스로 인식하도록 하는 데 성공하였습니다. 이 연구가 의미 있는 것은, 컴퓨터에게 고양이의 이미지가 어떤 것인지 가르쳐 주지 않은 상태에서 스스로의 학습을 통해 이미지를 인지하고 분류해 낸 비지도학습(Unsupervised Machine Learning)이라는 사실입니다. 기존의 검색엔진이 제목이나 태그 등의 텍스트 정보를 기반으로 고양이 영상을 찾아냈다고 한다면, 위 연구는 컴퓨터가 영상에 등장한 고양이의 형태와 생김새 자체를 인식하고 판단하게 만든 것이 그 차이점인 것이죠. 이 프로젝트를 맡았던 앤드류 응 박사는 인공지능 연구 분야의 최고 권위자 중 한 명으로, 얼마 전 중국 기업인 바이두의 딥러닝 연구소로 스카우트 되었습니다. 딥러닝 분야에서의 바이두의 활약은 이어서 소개해 드리겠습니다.그림 1. 딥러닝이 문제를 해결하는 방식<출처: Google>딥러닝, 어디까지 왔니? (업계동향과 활용사례) 표 1. 글로벌 기업 딥러닝 기술 경쟁 (출처: MK 뉴스)최근 딥러닝은 음성인식과 번역, 인공지능 로봇 분야에서 괄목할 만한 성장을 이루고 있는데요. 특히 음성인식 분야에서 큰 발전을 보여주고 있습니다. 이전 포스팅에서도 잠시 소개드렸던 구글 ‘나우’, 애플 '시리', MS '코타나' 등이 딥러닝 기술이 적용된 음성비서 서비스의 대표적 사례라 할 수 있습니다. 이외에도 다양한 글로벌 기업들이 딥러닝 기술 경쟁에 참여하고 있는데요. 각 기업들의 동향에 대해 좀 더 자세히 살펴볼까요?1) 바이두, 검색 기술의 핵심은 딥러닝중국의 구글이라 불리는 바이두가 2014년 5월 실리콘밸리에 약 3억 달러를 투자하여 딥러닝 연구소를 설립하고 구글 출신의 앤드류 응 박사까지 영입하였습니다. 바이두의 CEO인 리옌홍이 직접 연구소의 원장을 맡아 기술 연구에 박차를 가하고 있다고 합니다. 현재 그들이 보유한 음성인식 기술은 정확도가 92% 이상이라고 하며, 음성인식 외에도 이미지 인식, 이미지 검색 기능을 강화하여 사용자 경험(UX)과 고객 ROI 영역에서 이미 성과를 내고 있다고 발표했습니다. 2013년에는 딥러닝 기술을 이용한 이미지 검색 엔진을 오픈하였는데요. 아래 그림에서처럼 마음에 드는 옷을 사진으로 찍어 검색하면 이미지의 특징을 판별하고 구분하여 유사 상품을 찾아 가격정보와 상품정보를 보여주고, 바로 온라인 샵 구매로 연결해 주는 서비스입니다. 그림 2. 바이두 이미지 검색 <출처: http://shitu.baidu.com>앤드류 응 박사는 “인공지능 분야에서 이기는 자가 중국 인터넷 시장 승자가 되고 동시에 세계 시장의 최강자가 될 것”이라고 전망하였으며 “현재 바이두의 최대 목표는 딥러닝 분야에서 구글을 제압하는 것”이라고 강조하였습니다. 급기야 지난주, 바이두는 세계에서 가장 정확한 컴퓨터 비전 시스템을 구축했다고 발표하였는데요. 딥러닝 알고리즘에 최적화되어 있는 바이두의 슈퍼컴퓨터가 ‘이미지넷’ 오브젝트 분류 벤치마크에서 5.98%이라는 역대 최저 에러율을 기록했다고 합니다. 이는 구글이 작년에 기록한 6.66%의 에러율을 뛰어넘는 기록이며, 사람의 기록인 5.1%과 비교해 보아도 놀라지 않을 수 없습니다. 이 밖에도 바이두는 휴대폰을 딥러닝과 연계해 지능형 개인 비서로 활용하거나, 기계가 사람의 요구를 인지하고 해석하는 단계까지 진입하는 것을 목표로 기술 개발을 추진하고 있다고 합니다. 또 구글처럼 딥러닝과 연계할 수 있는 차세대 로보틱스 사업 분야에도 관심을 가지고 있으며 기타 비공개의 대규모 프로젝트들을 진행 중에 있습니다. 2) 알리바바 타오바오, 딥러닝 기반의 이미지 검색 기술요즘 가장 핫한 기업이죠? 알리바바를 대표하는 서비스 타오바오도 작년 여름 이미지 검색 기능을 탑재한 타오바오 모바일 앱을 출시했습니다. 바이두와 마찬가지로, 딥러닝 기술을 활용하여 의류 제품 사진을 검색하고 구매할 수 있습니다. 타오바오에 의하면, “딥러닝은 오리지널 픽셀에서 피처(Feature)를 배워가고, 하이어라키(Hierarchy)로 이루어진 피처를 배운다는 특징이 있으며 이 과정에서 픽셀에서 엣지를 판별하고, 다음으로 파트를 판별하며 최종적으로 오브젝트를 판별하게 된다.”고 합니다. 타오바오가 밝힌 구체적인 딥러닝 기술은 ‘복잡한 배경 속에서 의류를 감지하는 디텍션(Detection)’, ‘방대한 데이터를 처리하는 딥러닝 플랫폼’, ‘유사한 옷을 찾기 쉽도록 하는 로컬 시밀러리티 매칭 기술(Local Similarity Matching Technology)’, ‘고차원 데이터에 대한 인덱싱과 복구(Retrieval)’ 등 입니다. 그림 3. 타오바오 이미지 검색 <출처: Google> 그림 4. 타오바오 이미지 검색 결과 <출처: Google>3) 구글, ‘구글브레인’을 현실로앞서 말씀 드렸다시피 구글은 2012년 앤드류 응 교수와 함께 1만 6천개의 컴퓨터와 10억개 이상의 신경 네트워크(Neural Networks)를 구성해 심층신경네트워크(Deep Neural Networks)를 구현하였습니다. 이후 미래학자이자 발명가인 레이 커즈와일(Ray Kurzweil)을 구글 브레인 팀 이사로 영입하여 인공지능과 뇌공학 비전을 현실화하고 있습니다. 작년 초에는 머신러닝 스타트업인 딥마인드(Deep Mind)를 5억 달러에 인수해 화제가 되기도 했었죠. 구글 검색의 기본인 ‘페이지 랭크(Page Rank)’도 텍스트 마이닝(Text Mining)이라는 딥러닝 기술의 일종입니다. 더 나아가 현재 구글의 딥러닝 기술은, 개인 비서 서비스인 구글 나우에서 음성인식의 정확도를 높이고, 소셜 서비스인 구글 플러스에서 사진 태깅과 음성인식을 가능케 하며, 유투브에서 추천 영상을 제공하고, 구글 맵의 스트리트 뷰에서 건물 주소를 인식하기 위한 알고리즘 등에 널리 활용되고 있습니다. 올 초 해외 IT 뉴스에 따르면 구글이 머잖아 모바일 실시간 음성 통역 서비스도 선보일 예정이라고 하는데요. 구글이 모바일 통역 앱을 출시할 경우 글로벌 e 커머스 시장이 급성장할 것으로 예측됩니다. 이 밖에도 구글은, 구글 최고의 브레인 집합체라 불리는 비밀 연구 조직 ‘구글X’를 통해 세상을 변화시킬 다양한 프로젝트들을 진행하고 있는데요. 이 중 딥러닝 기술 바탕의 프로젝트가 다수 포함되어 있는 것으로 알려져 시장의 기대치가 높습니다.4) 페이스북의 얼굴인식 알고리즘 ‘딥페이스’페이스북은 딥러닝을 뉴스피드와 이미지 인식 분야에 적용하고 있습니다. 페이스북은 이 분야 최고 권위자로 꼽히는 미국 뉴욕대 얀 리쿤(Yann LeCunn)교수를 인공지능연구소(AI 랩) 수장으로 영입한 후, 작년 3월 ‘딥페이스’라는 얼굴 인식 알고리즘을 발표하여 화제가 되었습니다. 페이스북은 딥페이스 알고리즘을 통해 사진에서 인물의 성별과 헤어스타일, 패션스타일, 얼굴의 표정을 식별하는 방법을 지속적으로 연구 중이며, 현재 인식의 정확도는 인간의 눈과 거의 차이가 없는 수준까지 올라왔다고 합니다. 이러한 기술은 페이스북이 사진을 태깅하는 성능을 높이고 더욱 더 개인화 된 맞춤형 광고를 제공하는 데에 활용되고 있습니다. 그림 5. 페이스북 딥페이스 동작 원리 <출처: Facebook>5) MS의 AI 프로젝트 ‘아담’작년 초, MS는 미국에서 열린 한 컨퍼런스를 통해 자사의 인공지능 프로젝트인 ‘아담(Adam)’을 발표했습니다. 이날 MS는 ‘아담’을 MS 윈도우폰의 지능형 음성비서 ‘코타나’, 검색엔진인 ‘빙(Bing)과 연동하여 사물을 촬영하고 분석하는 데모 행사를 가졌습니다. 현장에서 애완견을 스마트폰으로 촬영한 후 ‘코타나’를 통해 어떤 견종인지 음성으로 질문하자, 바로 견종을 분석하여 스마트폰 문자로 알려주었습니다.‘아담’의 목표는 시각 데이터를 활용하여 모든 사물을 인식할 수 있게 하는 것이라고 하는데요. ‘아담’ 프로젝트를 위해 그 동안 MS는 웹과 플리커(Flicker) 등의 소셜 서비스로부터 약 1400만 장의 개 사진을 수집한 후 2만 2천개에 달하는 카테고리의 DB를 구축하여, ‘아담’의 사물 인식률에 대한 정확도를 높였다고 합니다. 동영상 1. MS 리서치 프로젝트 ‘아담’ 데모 영상 뿐만 아니라 MS는 화상 통화 서비스인 스카이프에 동시 통역 기능을 추가하기도 했습니다. 현재는 일부 사용자들을 대상으로 프리뷰 버전을 테스트 중이며 영어와 스페인어에 대한 동시 통역 기능만을 지원하고 있지만, 향후 한국어와 중국어, 불어, 독일어, 이탈리아어, 일본어, 포르투갈어, 러시아어, 스페인어, 아랍어까지 지원을 확대할 예정이라고 합니다. 이러한 MS의 행보에 경쟁 의식을 느낀 듯 보이는 구글 역시 자체 번역 앱에 자동 음성 탐지 기능을 추가하여 좀 더 자연스러운 실시간 번역을 지원하기 위해 힘을 쏟고 있다고 하고요. 페이스북 역시 전세계 사용자들의 소통의 장인 만큼, 자체 음성 번역 기술 확보에 큰 관심을 기울이고 있다는 소식입니다. 아직은 이러한 실시간 번역 서비스들의 정확도가 사용자들의 기대를 100% 충족시키지 못하고 있는 것도 사실입니다. 하지만 이들 서비스의 사용자가 늘어 날수록 컴퓨터는 더 많은 데이터를 학습하게 되고 좀 더 정교한 번역 결과를 제공할 수 있게 되겠죠. 머잖아 국제적인 언어의 장벽이 허물어지고 외국어에 대한 압박을 훌훌 털어버릴 수 있는 날이 오리라는 희망을 가져봅니다!!6) 기타그 외에도 IBM은 슈퍼컴퓨터 ‘왓슨’을 통해 딥러닝 분야를 연구하고 있고, 트위터는 딥러닝 기술을 보유하고 있는 스타트업 매드비츠를 인수하였습니다. 전세계적으로 트위터 사용자는 매년 증가하고 있으며 이들이 올리는 사진의 양도 엄청나겠죠. 트위터는 딥러닝 기술에 기반한 사진 분석 기술을 통해, 사용자들이 어떤 사진을 올리고 무엇에 관해 이야기하는지에 대한 분석 결과를 얻기를 기대하고 있습니다.딥러닝은 큐레이션 서비스에서도 그 빛을 발합니다. 세계 최대 비디오 스트리밍 업체인 넷플릭스는 사용자의 구매 이력을 바탕으로 맞춤형 콘텐츠를 추천해 주는 서비스에 딥러닝을 적용하고 있습니다.국내 상황은 어떨까요? 국내 딥러닝 연구의 중심에는 네이버가 있습니다. 네이버는 음성인식을 비롯하여 뉴스 요약, 이미지 분석에 딥러닝을 적용하고 있습니다. 네이버에 따르면, 이미 딥러닝 알고리즘을 통해 음성인식의 오류를 25%나 개선하였다고 하고요. 뉴스 요약 서비스에도 딥러닝을 적용해, 기사에 제목이 있을 경우와 없을 경우를 분리해 기사를 정확하게 요약해낼 수 있는 알고리즘을 개발 중이라고 합니다.마치며…이렇듯 머신러닝 기술이 점점 더 발전하면, 눈 앞에 보이는 모든 것들을 컴퓨터가 실시간으로 분석하여 알려주는 세상이 오게 될 것입니다. 길을 걷다가 흥미로운 물건을 발견하면 어느 브랜드의 제품이고 가격은 얼마이고 어디에서 구매하면 되는지 바로 알 수 있고, 소셜 서비스에 올린 사진을 바탕으로 내가 어떤 스타일의 옷을 좋아하는지 컴퓨터가 분석하여 내가 좋아할 만한 옷을 추천해주는 시나리오 정도는 이제 쉽게 예측이 가능한 것이죠. 분야를 막론하고, 다량의 데이터가 발생하는 상황이라면 이 DB를 통한 활용 방안은 무궁무진합니다. 다만, 이러한 방대한 데이터를 보유하고 있는 기업이라야 딥러닝 기술 연구가 가능한 것이겠죠? 해외에는 구글, 페이스북, 아마존, 트위터, 바이두 같은 기업들이 해당되지만, 국내에서는 이처럼 데이터를 충실히 오랫동안 쌓아온 기업이 없습니다. 따라서 국내 머신러닝 연구는 초기 단계일 수 밖에 없는 것이죠. 우리 기업들도 좀 더 적극적인 투자와 연구가 필요한 시점입니다. 더불어 딥러닝에 대한 기술 연구가 아닌, 기술의 원리만 제대로 파악한다면, 누구나 이를 활용한 다양한 서비스/제품 아이디어를 생각해낼 수 있습니다. ^^어렸을 적 미래 기술로 상상만 해오던 수많은 장면들이 점점 현실이 되어가고, 그 현실 속에 내가 있다는 생각을 하면 기분이 묘해집니다. 미래 기술이 우리의 생활에 밀접하게 다가선 만큼, 정부의 지원과 규제도 신속 유연하게 대응해야 할 때입니다. "
" 얻는 것- 딥러닝(deep learning)의 원리 이해- 강화학습(reinforcement learning)의 원리 이해- 논문과 기술문서 작성법- 관련 논문에 저자로 참여연구 주제- 강화학습을 이용한 게임 캐릭터 애니메이션 기술 (동국대 재학생만 가능)- 인공지능 작곡 기술 개발 (Python version : https://github.com/jmhong-simulation/nn_midi_trainer , C++ : http://blog.naver.com/atelierjpro/220851418829 , 학교 무관)해야하는 일- 주 15시간 이상의 코딩과 실험, 세미나 준비, 공부, 논문 작성 등지도 방식- 미국 명문대 대학원 방식 + 소규모 코딩 지도가 혼합된 진행 방식- https://www.youtube.com/channel/UCg6IlhycdYiK_nWB3spjIqA 참고참여 자격- 아래 강의 중 하나 이상을 수강한 (수강중인) 학생자이번학기 심화 프로그래밍C++로 배우는 딥러닝 강의 http://blog.naver.com/atelierjpro/220697890605지난 학기 컴퓨터 그래픽스- 관련 분야에 관심이 많으며 단기간에 많은 체험을 하고 높은 성취를 얻길 원하는 학생- 성실하고 끈기가 있는 학생지원 방법- jmhong @ dongguk.edu 로 A4 1페이지 이내의 자유양식 지원서 (프로젝트에 참여할 능력이 있다는 것을 증명하세요, 글쓰기 능력도 평가합니다)- 2016년 12월 27일 밤 10시까지- 탈락자에게는 별도 공지하지 않음- 자잘한 문의는 이 글의 댓글로 적어주세요.중요비인부전 (非人不傳)http://blog.naver.com/atelierjpro/220859763901http://blog.naver.com/atelierjpro/220858965131 "
" 1월 넷째주 빅데이터/딥러닝/인공지능 트렌드 및 빅데이터 플랫폼 자료를 전달해 드리오니 내용을 검토하여 주시면 감사하겠습니다.이제 ""딥러닝 기반의 챗봇, 상담시스템"", ""머신러닝 기반의 IOT/제조 실시간 모니터링 솔루션"", ""머신러닝 기반의 보안패턴분석 솔루션"" 도 저희 락플레이스 빅데이터사업부에서 컨설팅, 가이드, 구축, 활용방안을 제시해드립니다...[빅데이터/인공지능 트렌드 및 소식]빅데이터 활용한 맞춤형 마케팅 대세http://www.koreatimes.com/article/10357554차혁명 시대…은행, 빅데이터에 빠지다..데이터분석 조직 신설하고 리스크 대응 프로젝트 추진http://www.zdnet.co.kr/news/news_view.asp?artice_id=20170117132024&type=det&re=""자동화 늘면서 데이터 과학자 업무 부담 준다"" 가트너http://www.ciokorea.com/news/32794獨 머크, 팰런티어와 빅데이터 활용 제휴 체결데이터 수집 및 분석 소프트웨어 이용키로http://www.bosa.co.kr/news/articleView.html?idxno=2052882AI·빅데이터 활용 ‘스마트공장’…제조업 생산방식 혁명 이끈다http://www.hani.co.kr/arti/economy/economy_general/778984.html""빅데이터, 4차 산업혁명의 원동력""··· 한국IDG, 제7회 빅데이터 컨퍼런스 개최http://www.ciokorea.com/news/32734'가전+스마트폰' AI 대통합 노리는 삼성전자의 빅픽처 5가지는?...""이르면 2월 말 눈으로 볼 수 있어""http://biz.chosun.com/site/data/html_dir/2017/01/17/2017011702117.html빅데이터가 정책을 바꾼다…교통 관제·질병 예방에 빅데이터 활용 급증http://www.fnnews.com/news/201701121645458232AI·빅데이터 활용한 맞춤형 학습으로 개인 격차 줄이자http://sunday.joins.com/archives/1430492017년 어디서든 인공지능…글로벌 IT업체 선점 경쟁http://view.asiae.co.kr/news/view.htm?idxno=2017012110541436692인공지능의 블랙박스를 열어라http://techm.kr/bbs/board.php?bo_table=article&wr_id=3574""5년 안에 인공지능이 미래를 처방한다""http://www.hankyung.com/news/app/newsview.php?aid=2017011971641""블록체인·인공지능, 한은 통화 정책에도 영향 미칠 것""http://www.etnews.com/20170117000263인공지능(AI), 이젠 바이러스도 잡는다http://www.edaily.co.kr/news/NewsRead.edy?SCD=JE41&newsid=03106166615798704&DCD=A00504&OutLnkChk=Y인공지능, 사물인터넷 생태계 놓고 대전(大戰) 벌인다http://www.viva100.com/main/view.php?key=20170117010005888법률상담에 인공지능 시스템 도입http://www.dailysecu.com/news/articleView.html?idxno=18012법률상담에 인공지능 시스템 도입정부가 보유한 각종 법령과 판례정보를 검색해 법률상담을 제공하는 인공지능 시스템이 도입된다.또 국내에 거주하는 외국인들이 생활에 필요한 법...www.dailysecu.com "
" 2월 셋째주 빅데이터/딥러닝/인공지능 트렌드를 전달해 드리오니 업무에 참조하여 주시면 감사하겠습니다.이제 ""인공지능(AI) 플랫폼"" ""딥러닝 기반의 챗봇, 상담시스템"", ""머신러닝 기반의 IOT/제조 실시간 모니터링 솔루션"", ""머신러닝 기반의 보안패턴분석 솔루션""도 저희 락플레이스 빅데이터사업부에서 컨설팅, 가이드, 구축, 활용방안을 제시해드립니다...[빅데이터/인공지능 트렌드 및 소식]에너지 빅데이터 활용 ‘따로 또 같이’..정부, 전력·가스·열 에너지 빅데이터 취합·제공 플랫폼 구축 시작http://www.electimes.com/article.php?aid=1486607795141723002'로보 애널리스트' 올 하반기 선보여…코스콤, 빅데이터 전략 구체화http://www.ddaily.co.kr/news/article.html?no=152602빅데이터 날개 달고… 제조업, 서비스업 되다http://biz.chosun.com/site/data/html_dir/2017/02/09/2017020900080.html""재난 대응 위해 빅데이터 이용해야""..재난안전 기획 심포지엄http://news20.busan.com/controller/newsController.jsp?newsId=20170208000366“빅데이터 기반 도정 홍보 전략 짜야”..道의회 기획경제위원회http://www.ksmnews.co.kr/default/index_view_page.php?idx=166316&part_idx=269전문가들이 말하는 2017년 빅데이터·분석 전망 15선http://www.ciokorea.com/news/33014SK하이닉스 부사장 “미세공정 극복 빅데이터도 활용해야""...10나노 이하 초미세공정 위해 EUV 상용화 꼭 필요"" 강조http://www.zdnet.co.kr/news/news_view.asp?artice_id=20170208165125&type=det&re=생명보험업계, 보험사기 유형조사 시스템 구축http://www.yonhapnews.co.kr/bulletin/2017/02/08/0200000000AKR20170208055200002.HTML?input=1195m가톨릭정밀의학연구센터 개소…빅데이터로 맞춤형 치료http://www.cpbc.co.kr/CMS/news/view_body.php?cid=670973&path=201702일본 운송회사 안전 ‘빅데이터’ 활용 어디까지 왔나..사전 위험성 차단 사고 피해 최소화http://www.econovill.com/news/articleView.html?idxno=308634인공지능끼리는 협력할까 경쟁할까?..주어진 규칙과 상황에 따라 달라http://www.econovill.com/news/articleView.html?idxno=308946신용카드와 인공지능이 만나면http://www.moneys.news/news/mwView.php?type=1&no=2017020915328039592&outlink=1""AI와 MI 함께 봐야 인공지능 제대로 이해""..2019년 MI 시장규모 313억달러…생활전반으로 확산http://news.inews24.com/php/news_view.php?g_serial=1005900&g_menu=020600&rrf=nv인공지능이 가져올 리걸테크의 미래https://www.lawtimes.co.kr/Legal-Opinion/Legal-Opinion-View?serial=107919인공지능이 열어가는 금융 신세계http://www.cnews.co.kr/uhtml/read.jsp?idxno=201702070948163840274인공지능 시대 신개념 소자될까?…'4진법 소자' 발견http://www.yonhapnews.co.kr/bulletin/2017/02/06/0200000000AKR20170206173100063.HTML?input=1195m""콜센터에서 비서까지""..올해는 카드사 인공지능(AI) 시대http://www.mt.co.kr/view/mtview.php?type=1&no=2017020315484026031&outlink=1인공지능 스마트카의 미래http://slownews.kr/61535인공지능을 갖춘 '콘센트'특허청, 센서·통신 기능 구비한 사물 인터넷 콘센트 특허출원 활발http://www.enewstoday.co.kr/news/articleView.html?idxno=1000087사람 감정 파악하는 인공지능 기술 진화...상용화 잰걸음http://www.hellot.net/new_hellot/magazine/magazine_read.html?code=201&sub=004&idx=33010이승훈 실장 드림추신 : 빅데이터/딥러닝/인공지능 솔루션 서비스 및 컨설팅 문의처 - 락플레이스 이승훈 실장, 010-9338-6400, hunlee@rockplace.co.kr "
" 1월 셋째주 빅데이터/딥러닝/인공지능 트렌드 및 빅데이터 플랫폼 자료[빅데이터 플랫폼 참조자료]1. 100%오픈소스 하둡플랫폼, 호튼웍스 자료https://www.dropbox.com/s/p0tfda4pay0w18b/Hortonworks.pdf?dl=02. IBM AI기반의 왓슨 익스플로러 자료https://www.dropbox.com/s/tlk2fm54zjukyel/IBM%20Watson%20Explorer_AI.pptx?dl=03.IBM DW어플라이언스, PDA 자료https://www.dropbox.com/s/z7n0qkzhjj7rdrw/IBM_PDA%20.pdf?dl=04. 머신빅데이터, 스플렁크 자료https://www.dropbox.com/s/vw5ma1aqunzqz07/%EC%8A%A4%ED%94%8C%EB%A0%81%ED%81%AC2016.pptx?dl=0[빅데이터/인공지능 트렌드 및 소식]항암치료 거부 환자 맘도 돌린 AI 왓슨의 ‘족집게 처방’http://www.dt.co.kr/contents.html?article_no=2017011102101460041001물류수송업, 4차산업 바람 분다…빅데이터ㆍIoTㆍ 로봇 연구 가속화http://www.ekn.kr/news/article.html?no=260632태블로, 2017년 빅데이터 10대 트렌드 발표http://www.itworld.co.kr/news/102919“데이터 마이닝 기술 발달하면 비식별 개인정보 활용 제한”http://www.datanet.co.kr/news/articleView.html?idxno=1071024차혁명 시대, 빅데이터 활용 본격 나서는 병원들http://biz.chosun.com/site/data/html_dir/2017/01/08/2017010800284.html인공지능, 아마존이 구글 앞질러'.. 경쟁력은 무엇http://www.edaily.co.kr/news/NewsRead.edy?SCD=JE41&newsid=03352166615797392&DCD=A00504&OutLnkChk=Y인공지능의 올해 소소한 5개 관전 포인트..검증이 필요해http://www.econovill.com/news/articleView.html?idxno=306958전자정부에 인공지능·가상현실 등 혁신 기술 도입한다http://view.asiae.co.kr/news/view.htm?idxno=20170112112953185744차 산업혁명 대비 IoT·인공지능 직무표준 개발http://www.hkbs.co.kr/?m=bbs&bid=envnews13&uid=414361인공지능으로 법률상담, 교통사고부터 시범적용http://www.tbs.seoul.kr/news/bunya.do?method=daum_html2&typ_800=9&seq_800=10195670인공지능으로 우리 삶을 변화시킬 톱5 혁신기술http://www.koreaittimes.com/story/63908/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9C%BC%EB%A1%9C-%EC%9A%B0%EB%A6%AC-%EC%82%B6%EC%9D%84-%EB%B3%80%ED%99%94%EC%8B%9C%ED%82%AC-%ED%86%B15-%ED%98%81%EC%8B%A0%EA%B8%B0%EC%88%A0""인공지능(AI) 주도권을 잡아라""…업체간 경쟁 갈수록 치열http://www.viva100.com/main/view.php?key=201701090100030144차 산업혁명 게임체인저는 '인공지능'…일상을 파고들다http://www.mt.co.kr/view/mtview.php?type=1&no=2016122920470817600&outlink=1스플렁크 클라우드, 런던 개트윅 공항 실시간 데이터 분석으로 업무개선http://www.nextdaily.co.kr/news/article.html?id=20161208800071'환자 데이터, 안전하게' IBM 왓슨과 FDA의 블록체인 공동 연구http://www.ciokorea.com/news/32729호튼웍스, 최우선 커넥티드 데이터 플랫폼 클라우드 솔루션 선정http://www.yonhapnews.co.kr/bulletin/2016/06/29/0200000000AKR20160629057900009.HTML?input=1195m "
" Sketch Simplification by Deep Learning CNN CNN (Convolutional Neural Network)는 각 pixel 의 상화좌우 영역의 패턴을 인식하는데 가장 효과적인데요. 여러개의 선이 겹쳐진 스케치 그림에서 주요한 외곽선만 남기고 정리하는 deep learning model 입니다. 그런데, 학습을 시킬 때 필요한 스케치 원본과 사람이 노동으로 그린 결과물의 data set를 구할 수 있는 환경이 되었기에 시도를 해볼 수 있는 분야입니다. deep learning 분야는 이렇 듯, 어떠한 산업계에 적용될 수 있는 연결 고리가 있어야만 적용할 수 있음을 알아야 합니다. 딥러닝 코딩 기술만으로는 살아 남을 수 없을 것입니다. 그 산업 분야에서 전산을 툴로써 사용하여 확장하는 것처럼, 딥러닝 분야 또한 기존 산업 분야의 인프라와 데이터를 가진 그룹이 산업화 관점에서는 더 유리할 수 있습니다. http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch/Edgar Simo-Serra - Sketch Simplificationhi.cs.waseda.ac.jp "
" 상명대 납품 :: GPGPU를 이용한 Deep Learning 개발용 워크스테이션""사람처럼 생각하는 인공지능(AI) 딥러닝 개발용!""""GPGPU로 개발되는 딥러닝 컴퓨터는 어떻게 구성해야할까?""안녕하세요. 웰컴입니다.몇일 전 이세돌 9단과의 바둑대결, 다시말해 인간 VS 인공지능으로 전 세계적 큰 이슈를 일으켰던 '알파고'. 구글 딥마인드에서 개발 된 알파고는 인공지능의 전성기를 알리려는 듯 지지않을것만 같았던 이세돌 9단을 5국 중 무려 4번이나 이겼습니다. 엄청난 이슈를 일으킨 이번 바둑대결에 딥러닝이 전세계적으로 주목을 받고 있습니다. 오늘 소개 해 드리는 딥러닝 개발용 워크스테이션은 우분투에서 NVIDIA의 CUDA를 활용, GPGPU로 개발하는 컴퓨터입니다. GPGPU (General Purpose Graphics Processing Unit) 는 CPU보다 더 뛰어난 GPU의 연산 방식으로 CPU가 아닌 GPU를 활용하여 개발하는 방식을 말합니다. 따라서 단일 GPU 보다는 멀티 GPU(병렬방식)을 구성해야 훨씬 더 뛰어난 성능을 내줄 수 있습니다.물론 멀티 GPU 구성이라면 CPU의 PCI-Express 레인 개수 역시 중요하겠죠. 금일 소개 해 드리는 컴퓨터는 PCI-e 40레인을 지원하는 i7-5930K와 GTX Titan X 단일 GPU로 제작되었지만 향후 4Way SLi로 멀티 GPU 구성까지 고려한 컴퓨터입니다. CPU 인텔 i7 Extreme 5930K 하스웰-E CPU쿨러 CORSAIR HYDRO Series H60 수랭식 쿨러 메인보드 ASUS X99-E WS 메모리 삼성전자 DDR4 PC4-17000 16GB*4EA 총 64GB SSD 삼성전자 950 PRO Series 256GB 하드디스크 Seagate 3TB Barracuda ST3000DM001 그래픽카드 inno3D 지포스 GTX Titan X D5 12GB 케이스 CORSAIR CARBIDE SERIES AIR 540 블랙 파워서플라이 ENERMAX PLATIMAX EPM1350EWT 사양 및 견적문의는 전화, 카톡(wellmpc), 댓글, 메일 등으로 연락주세요! :) CPU* 인텔 하이엔드 데스크탑 i7-5930K 하스웰-E인텔 i7-5930K 하스웰-ELGA2011v3, 3.5GHz, 헥사코어오늘 소개 해 드리는 GPGPU 를 활용한 딥러닝 워크스테이션에 구성 된 프로세서는 인텔의 익스트림 프로세서인 i7-5930K 입니다. i7-5930K는 5820K와 마찬가지로 헥사코어에 조금 더 높은 클럭 스피드를 가지고 있습니다. 오버클럭을 하면 되지 왜 똑같은 헥사코어를 비싸게 구매하나요? 라고 할 수 있지만 두 CPU의 가장 큰 차이점은 바로 PCI-E 레인 갯수의 차이라는 것! 28레인인 5820K에 비해 무려 40레인으로 구성 된 5930K는 GPGPU 연산을 위해 4Way GPU 구성을 하더라도 제대로 된 성능을 내줄 수 있습니다. 따라서 오늘의 딥러닝 워크스테이션은 인텔의 하이엔드 데스크탑 i7-5930K를 기반으로 제작하였습니다.CPU쿨러* CORSAIR HYDRO Series H60 수랭식 쿨러CORSAIR HYDRO H60120mm 일체형, 수랭식 쿨러인텔 하이엔드 데스크탑 프로세서에는 기본적으로 번들 쿨러가 제공되지 않습니다. 따라서 인텔의 정품 쿨러 혹은 사제 쿨러를 따로 장착해야합니다. 오늘 소개 해 드리는 딥러닝 워크스테이션의 경우 장시간 풀로드 작업이 되는 경우가 많아 그만큼 열이 많이 발생되게 되므로 프리미엄 브랜드인 커세어의 1열 라디에이터 일체형 수랭식 쿨러인 CORSAIR HYDRO SERIES H60 으로 구성하여 빠르고 효율적인 쿨링능력을 가질 수 있도록 제작하였습니다.메인보드* ASUS X99-E WS ASUS X99-E WSExtended-ATX, 8+4Phase 전원부, USB3.0 오늘 소개 해 드리는 딥러닝 GPGPU 개발을 위한 워크스테이션의 메인보드는 제대로 된 워크스테이션 보드를 제작하는 에이수스의 X99-E WS 입니다. 7개의 PCI-Express3.0 x16 슬롯을 제공하여 4Way의 SLI 및 CrossFire X 를 지원합니다. 따라서 병렬구조 연결 시 더욱 뛰어난 연산 능력을 보여주는 GPU 연산 작업에서 매우 강한 면모를 보여줄 수 있습니다. 또한 8Phase의 서버 CPU 전원부 구성으로 오버클럭 작업을 진행하시는 분들에게도 매우 안정적인 성능을 보여줄 수 있습니다.메모리* 삼성전자 DDR4 PC4-17000 16GB*4EA 총 64GB 삼성전자 DDR4 PC4-17000 16GB*4EA DDR4, 16GB, 2133MHzCPU가 됐든, GPU가 됐든 컴퓨터에서 연산작업이 이루어질때에는 페이지 리소스가 발생하게 됩니다. 이러한 리소스는 휘발성을 가지고 있는 컴퓨터의 메모리에 저장되는데, 고사양을 요구하는 작업일수록 더욱 많은 리소스가 쌓이게 됩니다. 따라서 작업하는 환경에 맞춰 메모리의 용량을 구성하는것이 매우 중요합니다. 오늘 소개 해 드리는 딥러닝 개발을 위한 워크스테이션에는 삼성전자의 DDR4 PC4-17000 16GB 4개를 구성하여 총 64GB의 메모리로 제작하였습니다.SSD* 삼성전자 950 PRO Series 256GB M.2 삼성전자 950 PRO 256GBM.2(NVMe), 최대 쓰기 900MB/s, 최대 읽기 2,200MB/s 삼성의 최신 기술이 모두 담긴 SSD! 오늘 소개 해 드리는 딥러닝 개발용 워크스테이션에 구성 된 SSD는 삼성전자의 950 PRO 시리즈 256GB M.2 SSD 입니다. NVMe 인터페이스로 기존 SATA 방식의 SSD 대비 매우 빠른 최대 읽기 및 쓰기 속도를 가지고 있으며, 삼성의 뛰어난 기술력으로 제작 된 V-NAND 메모리 구성으로 내구성이 매우 뛰어나며 수명 역시 매우 긴 편입니다. 따라서 오늘 소개 해 드리는 딥러닝 워크스테이션의 SSD는 삼성 950 PRO 256GB 입니다.HDD* Seagate 3TB Barracuda ST3000DM001Seagate 3TB Barracuda ST3000DM001SATA3, 7200RPM, 64MB 캐시 메모리256GB의 SSD를 장착했음에도 사실 많은 영상 혹은 데이터 등을 여유있게 저장하기에는 부족한 용량입니다. 따라서 여유있는 저장공간을 통한 작업환경 개선을 위해 오늘 소개 해 드리는 딥러닝 워크스테이션에는 시게이트의 3TB 하드디스크를 세컨 스토리지로 추가 장착하였습니다. 3TB의 넉넉한 하드디스크를 장착함으로써 각종 데이터는 물론 많은 영상 및 용량이 큰 자료들을 여유있게 저장 및 백업할 수 있습니다.그래픽카드* inno3D 지포스 GTX Titan X D5 12GB inno3D 지포스 GTX Titan X3072 쿠다 프로세서, 384bit, GDDR5 12GB GPGPU를 활용하여 뛰어난 연산능력을 보여주기 위해서는 어떻게 보면 오늘 소개 해 드리는 부품 중 가장 중요한 부품이라고 할 수 있는 그래픽카드의 성능이 매우 중요합니다. 이번 딥러닝 워크스테이션에서는 지포스 라인업 중 최상위 스트림에 위치한 이노3D의 지포스 GTX Titan X D5 12GB (레퍼런스) 를 단일로 구성하여 뛰어난 성능의 연산 능력을 가질 수 있도록 구성하였습니다. 차후 4Way SLI 구성까지 염두에 둔만큼 Titan X 그래픽카드는 매우 뛰어난 선택이 될 것입니다.P.S.U* Enermax PLATIMAX EPM1350EWT 에너맥스 PLATIMAX EPM1350EWT정격 1350W, Modular, 80PLUS PLATINUM 파워 서플라이 제작사 중 최고의 권위를 자랑하는 에너맥스. 에너맥스 라인업 중에서도 최상위 스트림에 위치한 오늘의 딥러닝 워크스테이션에 구성 된 파워 서플라이는 Enermax PLATIMAX EPM1350EWT 입니다. 250W의 TDP를 가지고 있는 GTX TitanX를 차후 4Way까지 구성하기 위해서는 그만큼 높은 용량으로 구성해야 함은 물론 장시간 작업시에도 안정적인 성능을 낼 수 있다는 국제인증마크인 80PLUS, 그 중에서도 PLATINUM 등급으로 매우 높은 효율을 보여줄 수 있는 에너맥스 EPM1350EWT 입니다.CASE* CORSAIR CARBIDE SERIES AIR 540 블랙 커세어 CARBIDE AIR 540 블랙미들타워, 그래픽카드 최대 320mm, CPU쿨러 최대 170mm워크스테이션이라 한다면 부품들의 크기가 일반적인 데스크탑에 비해 많이 클 수 밖에 없습니다. 이에 내부 공간이 충분히 여유있는 케이스로 구성해야 제대로 된 쿨링 효과는 물론 부품간의 간섭이 생기지 않습니다. 오늘 소개 해 드리는 딥러닝 작업용 워크스테이션의 케이스는 고 퀄리티의 프리미엄 브랜드인 커세어의 CARBIDE SERIES AIR 540 으로 구성하였습니다. 미들타워급의 케이스지만 큐브 타입으로 케이스의 상하단부에 파워가 장착되는게 아닌 후면부에 장착되는 구조로 낮은 높이로도 빅타워급의 내부 공간을 활용할 수 있습니다. 따라서 오늘의 딥러닝 워크스테이션의 케이스는 CARBIDE AIR 540으로 제작하였습니다.제작과정* Assemble Process▲ CPU 장착을 위해 메인보드의 CPU 소켓을 열어줍니다.▲ CPU를 장착한 후 소켓을 닫고 고정걸쇠로 고정합니다.▲ 커세어 H60의 워터블록을 CPU에 장착합니다.▲ 메모리를 슬롯에 맞춰 장착합니다.▲ 메인보드 세트 완성!!!!▲ M.2 SSD를 위치에 맞춰 장착합니다.▲ 케이스에 장착 전 누드로 테스트를 진행합니다.▲ 파워 서플라이를 케이스 후면부에 장착합니다.▲ HDD를 가이드에 장착한 후 하단부에 장착합니다.▲ 그래픽카드 장착 후 보조전원을 연결합니다.▲ 웰컴피씨 딥러닝 워크스테이션 완성!! 총 평* 조립완료사진 및 총평 @20160319 GPGPU 딥러닝 작업용 조립식 워크스테이션 총평오늘 소개 해 드린 딥러닝 작업용 조립식 워크스테이션의 구성에 대해 다시한번 살펴보면,먼저 CPU는 PCI-E 40레인을 지원하여 4Way GPU 구성에서도 완벽한 성능을 보여줄 수 있는 인텔의 익스트림 프로세서인 i7-5930K로 구성하였으며, 삼성전자의 DDR4 PC4-17000 16GB 4개, 총 64GB 구성으로 장시간 작업시에도 메모리 부족없는 작업이 가능토록 구성하였습니다. 메인보드는 ASUS의 X99-E WorkStation 으로 구성하여 매우 튼튼한 전원부로 뛰어난 내구성 및 안정성을 가지고 있으며 950 PRO 256GB의 M.2 SSD 와 3TB의 하드디스크 구성으로 전반적으로 빠른 시스템 환경은 물론 넉넉한 스토리지까지 구성하였습니다. 그래픽카드는 지포스 계열의 최상위 스트림에 위치한 TITAN X로 구성하여 GPGPU 연산에서 매우 뛰어난 성능을 보여줄 수 있도록 제작하였습니다.PCI-E 40레인의 i7-5930K와 GTX TITAN X로 구성된 오늘의 워크스테이션!높은 성능의 컴퓨터를 완벽하게 제작하기 위해서는 그만큼 다양한 경험이 필요합니다.웰컴피씨는 수년간에 걸쳐 다양한 워크스테이션을 제작 및 납품하여 완벽한 제작을약속 드릴 수 있습니다! 딥러닝 워크스테이션이 궁금하시다면!? 주저마시고 웰컴으로연락주세요! 완벽한 가이드라인을 제시 해 드리겠습니다. 긴 글 읽어주셔서 감사합니다. ""덧글"" 및 ""공감""은 아주아주 큰 힘이 됩니다요 :D "
" 인공지능과 딥러닝 작가 마쓰오 유타카 출판 동아엠앤비 발매 2015.12.10. 리뷰보기 # 인공지능과 관련없는 연구소 다니시는 분과 대화할 기회가 있어서 인공지능에 대한 이야기를 했더니 매우 부정적이었다. 의아했다. 본인도 수십년전 인공지능 전공이었고 그거 옛날부터 있었는데 잘 안되었다고 했다. 이 책을 보니 인공지능분야에서 봄과 겨울이 계속되어와서 실망이 켜져 왔겠구나고 생각되었다. 인공지능이 지금까지 지지부진했던 이유는 기호를 단순한 기호표기로 다루고 있었기 때문이었단다. 기호를 개념과 기호표기가 세트로 된 것으로 다루어오지 않았다. 최근 돌파구가 된 것은 딥러닝이라는 기술로, 딥러닝은 다층의 뉴럴네트워크를 실현했다. 한층씩 계층마다 학습하는 것과 오토인코더 autoencoder라는 정보압축기 사용했다고 하는데 사실 완전히 이해되지는 않는다. # 딥러닝에서 멋진 점은 특징을 강건하게 할 수 있는 프로세스를 가한 점이다. 딥러니의 아버지 제프리 힌톤은 역설적이지만 입력신호에 노이즈를 첨가한다. 노이즈를 더할수록 나오는 개념은 여간해서 흔들리지 않는다. 우연히 일치하고 있었던 부분이 없어진다. 강건하게 만드는 다른 방법은 드롭아웃으로 일부 뉴런을 제외한다. 은닉층의 50%를 랜덤하게 누락하니, 어떤 특징에 과도하게 의존했던 특징표현이 없어진다. 일부분의 특징을 사용할 수 없게 하는 것이 적절한 특징표현을 찾게 한다. 가혹한 환경을 주어야 본질적인 특징을 획득하는 것이다. # 알파고와 이세돌의 대결로 인해 인공지능에 대해 허공에 뜬 담론이 아닌 조금 구체적인 것이 알고 싶어 읽은 책이다. 일본분이 지은 책으로 다른 책들이 미래에 어떤 일이 벌어질 지에 초점이 맞추어진 반면, 이 책은 좀 더 기술적인 부분이 구체적으로 써져 있다. 그래도 일반인에게는 어렵긴 하고 기술적인 부분이외 미래예상파트는 좀 약하다. "
" 컨텍아카데미, 3차 인공지능과 딥러닝 교육 개최 분류 전체 작성자관리자 작성일2017-03-16 16:03:41 http://aict.snu.ac.kr/?p=24&viewMode=view&idx=5510차세대융합기술연구원 알림소식 - 공지사항aict.snu.ac.kr ■ 과정명 : 인공지능과 딥러닝(3차)■ 교육일시 / 장소 : 2017.4.13(목)~4.14(금), 09:00~18:00 / 경기창조경제혁신센터 3층■ 세부주제 : 4차 산업혁명의 핵심기술로 주목받는 인공지능, 딥러닝 기술의 실제와 산업화 전략■ 교육대상 : ICT관련 개발자 및 R&D담당자, 기술에 관심이 있는 대학원생도 가능■ 교육내용 : 기계학습을 통한 딥러닝 기술, CNN알고리즘과 RNN알고리즘의 이해, Tool활용한 실습■ 비용 : 1인 40만원(경기도 기업 50% 감면, 20만원) * 직업능력개발훈련환급 미적용시 5만원 추가등록비 발생■ 문의 : 컨텍아카데미 박요명, 031-776-4877, myeong1590@snu.ac.kr인공지능, 딥러닝은 미래의 기술이 아닌 현재 산업과 R&D전반에서 즉시 활용, 적용가능한 기술입니다.인공지능 분야 최고 전문가를 모시고, 이론 강의는 물론 머신러닝, 딥러닝 아키텍쳐를 실습, 경험해봄으로써 일반기업에서 실제 인공지능/딥러닝 관련기술을 도입/검토할 수 있는 전문지식을 제공하는 교육입니다.관심있는분들의 많은 참여바랍니다. "
" 인공지능과 딥러닝 작가 마쓰오 유타카 출판 동아엠앤비 발매 2015.12.10. 평점 리뷰보기 지인분이 감수를 맡은 이 책을 읽었다. 사실 내가 공대 출신이기 때문에 이 책에 나오는 뉴럴네트워크 모델 같은 것은 학부 시절 간략하게 배운 적도 있었다. 제일 관심 가는 부분은 딥러닝이었다. 다행이 이 책을 통해 딥러닝이 무엇인지 감을 잡을 수 있었다.결론부터 얘기하면 'deep learning' 정말 대박이다. 뉴럴네트워크 구조에 계층구조를 도입해서 무작위로 주어지는 data에서 인공지능 스스로 특징을 잡아내 추상화하는 것이 가능해졌다니.... 왜 딥러닝 딥러닝 하는지 충분히 알 수 있었다. 이 계층구조 역시 인간 두뇌의 세포 구조를 모방한 것인데... 예전에도 계층구조를 시도했지만 생각보다 결과가 좋지 않았는데... 이 책에 의하면 오토인코더로 각 계층을 하나씩 단계적으로 충분히 학습시키는 방식으로 차근차근 접근해서 탁월한 효과를 거두게 된 것 같다. 이렇게 접근한 것이 우연인지... 아니면 인간 두뇌의 기능에서 힌트를 얻은 것이지 좀 궁금하다...인간과 같은 추상적 사고가 가능하다는 것은 인공지능에서 어마어마한 성과다. 이를 통해 이전에는 생각지도 못한 일들이 분명 가능해 질 것이다.하지만, 내가 생각하기에는........ 인공지능이 인간과 같은 감각기관과 운동기관을 갖고 있지 못해 인간이 이해하는 방식으로 세상을 이해할 수 있을지에 대한 회의가 있었는데... 역시 이 책에서 그런 한계에 대한 얘기도 나와서 반가웠다.아무튼 이 책을 통해 딥러닝의 의미를 확실히 이해했으니 큰 도움을 받은 책이라 하겠다. 다만 이공계 쪽의 배경지식이 적다면 내용을 제대로 이해하는 것이 조금은 어려울 수도 있겠다는 생각은 들었다. "
