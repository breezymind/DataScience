{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naver Webtoon \n",
    " - 해당 코드는 학습용도로 사용하는 코드로 상업적 이용이 없음을 알려드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 열렙전사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naver_url = \"http://comic.naver.com\"\n",
    "url = \"http://comic.naver.com/webtoon/list.nhn?titleId=670152&weekday=sun&page={page}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Beautifulsoup find가 img태그에 되지 않아 수작업(정규식으로 한 버젼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    real_url = url.format(page=i)    \n",
    "    req = requests.get(real_url)\n",
    "    if req.status_code == 200:\n",
    "        bs = BeautifulSoup(req.text, 'html.parser')\n",
    "        table_list = bs.find_all(\"table\",class_=\"viewList\")\n",
    "        tr_list = table_list[0].find_all(\"tr\")\n",
    "        for i in range(2,len(tr_list)):\n",
    "            title = tr_list[i].find_all(\"td\")[0].find(\"img\").attrs[\"alt\"]\n",
    "            date = tr_list[i].find_all(\"td\")[3].text \n",
    "            date = date.replace(\".\",\"\")\n",
    "            directory = \"d:\\webtoon\\\\\"+date\n",
    "            if os.path.isdir(directory) == False:\n",
    "                os.makedirs(directory) \n",
    "                in_url = tr_list[i].find_all(\"td\")[0].find('a').attrs['href']\n",
    "                full_url = naver_url + in_url\n",
    "                folder_name = date + \"_\" + title\n",
    "                sub_req = requests.get(full_url)\n",
    "                headers = {'Referer': full_url} # headers 쪽에 해당 url을 넣지 않으면 접근 할 수 없어 header를 적용.\n",
    "                if sub_req.status_code == 200:\n",
    "                    sub_bs = BeautifulSoup(sub_req.text, 'html.parser')\n",
    "                    container_list = sub_bs.find_all(\"div\",class_=\"wt_viewer\") \n",
    "                    ## 아무리 해도 img태그를 가지고 올려고 해도 되지 않아  정규식을 이용하여 주소를 가지고 왔습니다. \n",
    "                    # http://imgcomic.naver.net/webtoon/숫자/숫자/파일명.jgp\n",
    "                    img_list = re.findall(r\"src=\\\"http\\:\\/\\/imgcomic\\.naver\\.net\\/webtoon\\/([\\d]+)\\/([\\d]+)\\/([\\d_\\w]+.jpg)\",str(container_list[0]))                    \n",
    "                    for j in range(len(img_list)):\n",
    "                        first = img_list[j][0]\n",
    "                        second = img_list[j][1]\n",
    "                        file_name = img_list[j][2]\n",
    "                        file_name_url_base = \"http://imgcomic.naver.net/webtoon/{first_digit}/{second_digit}/{file}\"\n",
    "                        file_name_url = file_name_url_base.format(first_digit=first,second_digit=second,file=file_name)\n",
    "                        img_res = requests.get(file_name_url)\n",
    "                        tmp_file = img_list[j][2].split(\"_\")\n",
    "                        save_file_name = tmp_file[2] + \"_\" + tmp_file[3]\n",
    "                        directory_full = directory + \"\\\\\"+ save_file_name\n",
    "                        image_file_data = requests.get(file_name_url, headers=headers).content\n",
    "                        with open(directory_full, 'wb') as f:\n",
    "                            f.write(image_file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find_all이 아닌 select를 통해서 (class 태그 접근)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기기괴괴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naver_url = \"http://comic.naver.com\"\n",
    "url = \"http://comic.naver.com/webtoon/list.nhn?titleId=557672&weekday=thu&page={page}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,2):\n",
    "    real_url = url.format(page=i)    \n",
    "    req = requests.get(real_url)\n",
    "    if req.status_code == 200:\n",
    "        bs = BeautifulSoup(req.text, 'html.parser')\n",
    "        table_list = bs.find_all(\"table\",class_=\"viewList\")\n",
    "        tr_list = table_list[0].find_all(\"tr\")\n",
    "        for i in range(2,len(tr_list)):\n",
    "            title = tr_list[i].find_all(\"td\")[0].find(\"img\").attrs[\"alt\"]\n",
    "            date = tr_list[i].find_all(\"td\")[3].text \n",
    "            date = date.replace(\".\",\"\")\n",
    "            directory = \"d:\\webtoon\\기기괴괴\\\\\"+date\n",
    "            if os.path.isdir(directory) == False:\n",
    "                os.makedirs(directory) \n",
    "                in_url = tr_list[i].find_all(\"td\")[0].find('a').attrs['href']\n",
    "                full_url = naver_url + in_url\n",
    "                folder_name = date + \"_\" + title\n",
    "                sub_req = requests.get(full_url)\n",
    "                headers = {'Referer': full_url}\n",
    "                if sub_req.status_code == 200:\n",
    "                    sub_bs = BeautifulSoup(sub_req.text, 'html.parser')\n",
    "                    for img_list in sub_bs.select('.wt_viewer img'):\n",
    "                        file_name_url = img_list['src']\n",
    "                        save_file_name = file_name_url.split(\"/\")[6].split(\"_\")[2] + \"_\" + file_name_url.split(\"/\")[6].split(\"_\")[3]\n",
    "                        directory_full = directory + \"\\\\\"+ save_file_name\n",
    "                        image_file_data = requests.get(file_name_url, headers=headers).content\n",
    "                        with open(directory_full, 'wb') as f:\n",
    "                            f.write(image_file_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
