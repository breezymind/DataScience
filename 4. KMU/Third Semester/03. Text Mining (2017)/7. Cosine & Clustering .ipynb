{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 코사인 유사도 & Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.parse import quote_plus\n",
    "\n",
    "import requests\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_url = ('http://section.blog.naver.com/sub/SearchBlog.nhn?type=post&option.keyword={query}'\n",
    "              '&option.page.currentPage={page}&option.orderBy=sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%EB%94%A5%EB%9F%AC%EB%8B%9D'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = quote_plus('딥러닝')\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://section.blog.naver.com/sub/SearchBlog.nhn?type=post&option.keyword=%EB%94%A5%EB%9F%AC%EB%8B%9D&option.page.currentPage=2&option.orderBy=sim'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = search_url.format(query=query, page=2)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = lxml.html.fromstring(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element a at 0x15991ee4f48>,\n",
       " <Element a at 0x15991ee4f98>,\n",
       " <Element a at 0x15991eee048>,\n",
       " <Element a at 0x15991eee098>,\n",
       " <Element a at 0x15991eee0e8>,\n",
       " <Element a at 0x15991eee138>,\n",
       " <Element a at 0x15991eee188>,\n",
       " <Element a at 0x15991eee1d8>,\n",
       " <Element a at 0x15991eee228>,\n",
       " <Element a at 0x15991eee278>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.cssselect('h5 a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - a Class가 존재하지 않는다. 그럴때는 위에 태그를 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝(Deep Learning) 실습과정 강좌 오픈! http://blog.officen.kr/220953268153\n",
      "AlphaGo(알파고)와 딥러닝 http://blog.naver.com/ysw1130?Redirect=Log&logNo=220653505939&from=section\n",
      "딥러닝 / 머신러닝 워크스테이션 커스텀수냉은 필수! http://blog.naver.com/digiji1?Redirect=Log&logNo=220822461696&from=section\n",
      "딥러닝 전망과 응용사례는? http://blog.naver.com/bosungabi?Redirect=Log&logNo=220689269927&from=section\n",
      "딥러닝 기술로 색깔을 칠해주는, PaintsChainer http://blog.naver.com/jdiycdi?Redirect=Log&logNo=220927019170&from=section\n",
      "YJ MOD 딥러닝 워크스테이션 http://blog.naver.com/digiji1?Redirect=Log&logNo=220950111651&from=section\n",
      "6850K 파스칼  타이탄 X 4way 딥러닝 연산용 900D 풀 커스텀 동관 워크스테이션 http://blog.naver.com/polaris_810?Redirect=Log&logNo=220902614790&from=section\n",
      "알파고 AI 근간이 되는 딥러닝 이야기 http://gamsungit.com/220308660011\n",
      "GTX1080 4Way 우분투 활용 딥러닝 워크스테이션 http://blog.naver.com/wellmpc?Redirect=Log&logNo=220977799611&from=section\n",
      "2017 IT트렌드 딥러닝(Deep Lerning) http://blog.naver.com/youhyun4534?Redirect=Log&logNo=220948527326&from=section\n"
     ]
    }
   ],
   "source": [
    "for link in root.cssselect('h5 a'):\n",
    "    print(link.text_content(), link.attrib['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL 분해\n",
    " - 크롤링에서 필요했던 내용들을 분해해서 데이터를 format으로 하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.parse import parse_qs, urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = urlparse('http://blog.naver.com/civilize?Redirect=Log&logNo=220976431562&from=section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='http', netloc='blog.naver.com', path='/civilize', params='', query='Redirect=Log&logNo=220976431562&from=section', fragment='')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blog.naver.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/civilize'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Redirect=Log&logNo=220976431562&from=section'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Redirect': ['Log'], 'from': ['section'], 'logNo': ['220976431562']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = parse_qs(result.query)\n",
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'220976431562'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs['logNo'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_url = 'http://blog.naver.com/PostView.nhn?blogId={}&logNo={}'.format(result.path[1:], qs['logNo'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://blog.naver.com/PostView.nhn?blogId=civilize&logNo=220976431562'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 게시물 내용 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_res = requests.get(post_url)\n",
    "post_root = lxml.html.fromstring(post_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\t\\r\\n \\r\\n \\r\\n  밑바닥부터 시작하는 딥러닝 \\r\\n  \\r\\n  작가\\r\\n  사이토 고키\\r\\n  출판\\r\\n  한빛미디어\\r\\n  발매\\r\\n  2017.01.03.\\r\\n  평점\\r\\n  \\r\\n   \\r\\n    \\r\\n   \\r\\n  \\r\\n  \\r\\n  리뷰보기\\r\\n \\r\\n 이런 책이 진작 나왔다면 내가 머신러닝 공부하는데 장벽을 좀 덜 느꼈을텐데 말이다.왜 2017년에서야 나온거냐.일단 책 내용은 요즘 굉장히 핫한 뉴럴넷, 딥러닝을 파이썬으로 구현해 보면서 익히는 것이고,책 제목대로 초짜들도 따라하면서 뉴럴넷의 원리와 필요한 지식들을 배울 수 있게 구성되어 있다.뭐 그래도 calculus, linear algebra 정도는 머릿속에 배경지식을 깔고 들어가야 하고,애초에 머신러닝 분야가 통계나 수학적인 백그라운드 없으면 쉽게 할 수 없으니까그정도는 공부하고 읽는것을 추천한다.근데 난 이 내용 석사때 분명 배우긴 배웠고, matlab으로 구현까지 했던 기억이 있는데하도 손을 놔서 그런지 다 까묵어서 리마인드하는 용도로 보고 있기는 하다.그런 용도로도 괜찮은 책인것도 같고.\\r\\n\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_root.cssselect('div#postViewArea')[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 블로그 스크래핑 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keyword = '딥러닝'\n",
    "query = quote_plus(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_url = ('http://section.blog.naver.com/sub/SearchBlog.nhn?type=post&option.keyword={query}'\n",
    "              '&option.page.currentPage={page}&option.orderBy=sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "for page in tqdm.tqdm_notebook(range(1, 20)):\n",
    "    url = search_url.format(query=query, page=page)\n",
    "    res = requests.get(url)\n",
    "    root = lxml.html.fromstring(res.text)\n",
    "    \n",
    "    for link in root.cssselect('h5 a'):\n",
    "        link_url = link.attrib['href']\n",
    "\n",
    "        # 다른 형식의 주소는 무시\n",
    "        if not link_url.startswith('http://blog.naver.com'):\n",
    "            continue\n",
    "\n",
    "        # 진짜 주소\n",
    "        result = urlparse(link_url)\n",
    "        blog_id = result.path[1:]\n",
    "        qs = parse_qs(result.query)\n",
    "        post_id = qs['logNo'][0]\n",
    "        post_url = 'http://blog.naver.com/PostView.nhn?blogId={}&logNo={}'.format(blog_id, post_id)\n",
    "        \n",
    "        # 본문 가져오기\n",
    "        post_res = requests.get(post_url)\n",
    "        post_root = lxml.html.fromstring(post_res.text)\n",
    "        \n",
    "        try:\n",
    "            body = post_root.cssselect('div#postViewArea')[0]\n",
    "            posts.append(body.text_content())\n",
    "        except IndexError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV로 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/posts.csv', 'w', encoding='utf8', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    for post in posts:\n",
    "        post_short = re.sub(r'\\s+', ' ', post)  # 모든 종류의 공백을 빈 칸 하나로 바꿈 (엑셀에서 보기 좋게)\n",
    "        w.writerow([post_short])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV에서 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts = []\n",
    "with open(\"data/posts.csv\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        post = row[0]\n",
    "        if len(post) > 100:\n",
    "            posts.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 머신러닝의 딥러닝, 미래사회를 이끌다 산업 현장의 지각 변동을 이룰 미래 기술 미국의 IT 리서치 기업 가트너 그룹은 지난 2016년, ITxpo 2016에서 향후 5년간 혁신 잠재력을 지닌 10대 전략기술 트렌드를 발표했다. 가트너가 선정한 2017년 10대 전략 기술은 인텔리전트(Intellegent)와 디지털(Digital), 그리고 메시(Mesh)라는 3가지 영역으로 구분된다. 그중 인공지능과 고급 기계 학습, 즉 머신러닝은 10대 기술의 서두로서 로봇, 자율주행자동차, 가전 기기 등 물리적 디바이스를 비롯해 미래 IT 산업을 선도할 핵심기술로 평가 받고 있다.세상을 바꿀 최고의 전략 기술지난 2016년 ‘ITxpo 2016’에서 미국의 가트너 그룹이 발표한 ‘2017년 10대 전략기술 트렌드’는 향후 5년간 IT 산업 발전을 이끌 10가지 핵심 기술에 대해 이야기한다. 그중 인텔리전트(Intellegent), 즉 지능의 영역으로 분류되는 ‘인공지능과 고급 기계 학습(AI & Advanced Machine Learning)’은 기존의 알고리즘을 넘어 학습 예측, 적응을 비롯해 잠재적으로 스스로 가동하는 자율시스템을 만들어 지능형 스마트 기기를 만든다.인공지능의 한 분야인 머신러닝(Machine Learning)은 데이터의 생성량과 주기, 형식 등 방대한 빅데이터들을 분석해 미래를 예측하는 기술을 말한다. 이 기술은 기존의 빅데이터 분석과 유사점을 지녔지만, 데이터를 수집·분석해 미래를 예측한다는 점에서 차이점을 지녔다. 딥러닝, 신경망, 자연어처리, 첨단기법 등 기술의 결합으로 완성된 머신러닝 기술은 최근 각광받고 있는 물리적 디바이스(로봇, 자율주행자동차 등)을 비롯해 지능형 앱, 메시 디바이스 등 다양한 분야에 적용·융합될 혁신 기술로 평가받는다. 대표적 사례로 글로벌 소셜 네트워크 서비스를 제공하는 페이스북은 ‘Project PANDA’를 통한 딥페이스 기술을 연구한다. 또한, 세계 최대 비디오 스트리밍 기업 넷플릭스는 사용자의 구매 이력을 토대로 영화를 추천해 주는 서비스에 머신러닝을 적용했다. 이러한 기업들의 머신러닝 적용 배경에선 AI 기술의 정점으로 평가받는 딥러닝(Deep Learning)이 있었다. 머신러닝의 한 분야인 딥 러닝은 인공지능의 핵심 기술로서 인간의 두뇌 신경망 구조를 모방한 인공 신경망을 바탕으로 두각을 나타내고 있다. 그중 이미지 인식 분야에서 두드러지는 딥러닝 기술은 2014년부터 페이스북의 딥페이스 서비스에 적용되며 그 가능성을 인정받은 바 있다. 인공 신경망 기반 기계 학습 기술인 딥러닝은 컴퓨터가 스스로 학습한다는 점에서 머신러닝과 동일성을 지녔다. 하지만 데이터의 특징에 대한 정보를 사람이 직접 제공해야 하는 머신러닝과 달리 딥러닝은 특징을 스스로 파악해 분류한다는 점에서 차이점을 지녔다. 현대 지능 기술의 정점이 될 것으로 예견되는 두 기술은 다양한 산업현장에 적용 및 활용된다. 실현화 단계로 돌입한 딥러닝, 그리고 머신러닝의 미래딥러닝을 이용한 이미지 인식 기술의 인식률(97.35%)은 사람의 평균 인식률(97.5%)과 동일한 수준으로 발전했다. 또한, 다양한 서비스 추천 기능에도 적용되고 있는 딥러닝 기술은 인터넷 쇼핑몰 사이트의 상품 추천 서비스는 물론, 개인화된 음악 추천 서비스, 라디오 서비스 등에서도 엿볼 수 있다. 또한, 금융 분야에서 주목받는 딥러닝 기술은 미국의 온라인 결제 서비스 페이팔의 이상 금융거래 탐지시스템(FDS)에 적용되며 온라인 결제 패턴을 지능적으로 수집·분석해 기존 형태와 다른 패턴에서 범죄의 여부를 분류해 낸다. 금융 기업들에게 필요한 데이터 분석으로 주가와 기업 부도 예측이 가능하다는 점은 또 하나의 시사점이다. 머신러닝의 역사는 1950년부터 이어진다. 70년에 가까운 역사 속에서 정체되어 있던 기술은 2000년대 중반에 이르러서야 발전이 이루어지고 있다. 실제 머신러닝의 발전을 이끈 딥러닝의 인공신경망 기술은 IT 분야에서 새로운 것으로 보기는 힘들다. 전문가들은 ‘지난 20년간 인터넷 기술의 발전으로 축적된 방대한 정보와 이를 처리하기 위한 컴퓨터의 연산 능력 향상이라는 두 가지 요소가 만들어 낸 성과’라고 입을 모았다. 최근 딥러닝을 통한 머신러닝의 성공이 만들어낸 변화는 인류의 편의성을 혁신적으로 증대시킬 수 있다는 점에서 각광받고 있다. 또한, 구글, 페이스북 등 글로벌 IT 기업들은 딥러닝 기술 개발에 주력하며 끝없는 경쟁을 이어가고 있다. 구글은 학계에서 딥러닝 분야의 최고 석학으로 평가 받는 토론토 대학의 제프리 힌튼 교수를 영입해 자율주행차와 번역 서비스에 기술을 적용하고 있다. 검색 엔진 분야에서 세계 최고의 점유율을 지닌 만큼 구글이 지닌 방대한 데이터와 이미지들은 딥러닝 기술의 연구·개발을 위한 최고의 경쟁력으로 평가받고 있다. 한편, 페이스북은 힌튼 교수의 제자인 뉴욕주립대학교의 얀 레쿤 교수를 영입해 딥러닝을 광고에 반영하는 기술을 개발하고 있다. 이처럼 기업들의 경쟁을 바탕으로 성장 중인 딥러닝을 통해 추후 이미지 인식 분야를 토대로 커뮤니케이션이 가능한 로봇의 출현이 예고되고 있으며, 각종 언어에 대한 상황판단과 문화적 맥락의 수집을 통해 언어장벽을 무너뜨릴 통번역 서비스를 만들어 낼 것으로 예상되고 있다. 하지만 IT 강국으로 평가 받는 국내 사회에서는 머신러닝 기술과 딥러닝에 대한 관심이 부족한 점이 사실이다. 미래의 전략 트렌드로서 주목받는 머신 러닝과 이를 보조하는 딥러닝 기술이 만들어낼 새로운 사회에 국내 기업들과 관련 정부 부처의 관심이 필요한 시점이다.\\u200b 이슈메이커 이민성 기자 jadelee@issuemaker.kr ',\n",
       " \" 안녕하세요 ICT멘토링 서포터즈 7기 손영주입니다제가 알려드리는 2번째 ICT트렌드는 바로 '딥러닝'입니다'딥러닝'이 무엇이냐고요? '딥러닝'(Deep Learning) 쉽게 말씀드리자면 학습을 통한 생각하는 컴퓨터가까운 예시는 이세돌 9단과 바둑을 두었던 알파고인데요.역사적인 사건 혹은 대결이었던 이 대전은 ICT에 관심이 없었던 많은 사람들에게도 인공지능(AI)에 대한 관심을 불러일으켰습니다.많은 사람들과 이세돌은 경기 전, 낙승을 예상했지만 경기가 지날수록 이길 수 없는 상대와의 대전인 것처럼 되었습니다. 구글의 알파고는 딥러닝 기술에 기반한 프로그램인데요딥러닝에 대해 알아보겠습니다딥러닝이란 많은 데이터를 컴퓨터에 입력하고 비슷한 것끼리 분류하도록하는 기술입니다. 우리는 자각할 수 없지만 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정보처리 방식을 모방한 것입니다. 데이터를 기반으로 기계가 스스로 인지·추론·판단할 수 있게 됩니다. 위 2개의 사진은 생활 속의 딥러닝입니다.딥러닝이라면 '나'와는 아주 먼 이야기 같겠지만,얼굴 인식 기술을 페이스북 및 음성 인식 기술을 탑재한 아이폰 등일상 속에서 딥러닝을 마주하고 있습니다.현재 딥러닝은 사진 분류뿐만 아니라 문학, 그림, 게임 등다양한 산업에서 결합하고 있습니다. 이러한 딥러닝에도 한계가 있기 마련인데요!우선 '정확성'의 문제입니다.무적으로 보였던 알파고가 4번째 대국에서 패배, 페이스북이나 구글포토도 가끔 엉뚱한 사람을 태그하거나 엉뚱한 사물로 분류하기도 합니다.무조건 데이터가 많다고 해결되는 문제는 아닙니다.기계의 학습이 완벽해지는 시점이 있으며 이를 넘으면 오히려 정확성이 떨어집니다.다음은 '악용의 가능성'인데요. 예를 들면 영화 <아이로봇>처럼 틀린 정보를 기계에 학습시켜 옳지 않은 정보를 기계가 옳다고 생각하게 만든다면 영화처럼 비극이 일어나지 말라는 법은 없습니다.기하급수적인 데이터와 알고리즘의 발전으로 이러한 한계를넘어서다 보면 딥러닝이 적용될 수 있는 분야는 무궁무진하다 생각합니다 ICT 트렌드 '딥러닝'에 대해 알아보았는데요,딥러닝의 한계를 넘어서 인류에 좋은 방향으로 사용되길 바라는 4조 AdvanCT의 손영주였습니다 \"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDM 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_noun(text):\n",
    "    nouns = tagger.nouns(text)\n",
    "    return [n for n in nouns if len(n) > 1]  # 2글자 이상인 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=get_noun, max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdm = cv.fit_transform(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<83x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm # 83개문서를 500개 단어로 생성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDM 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('data/blog_tdm.npz',tdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 목록 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/blog_tdm.json', \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(cv.get_feature_names(),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDM 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load('data/blog_tdm.npz', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdm = data['arr_0'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<83x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 목록 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/blog_tdm.json', encoding='utf8') as f:\n",
    "    words = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['가능', '가속', '가이드', '가중치', '가지', '각각', '각종', '감사', '강의', '강좌']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 차원 축소 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=10) # 10개의 차원으로 변경."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = svd.fit_transform(tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<83x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm # 534파일을 500개 단어로 표현 했었다. 그걸 위에서 10개 차원으로 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41.01439085,  -4.42283017, -11.03644355, -12.43750706,\n",
       "         3.34100663, -14.78295421,   8.48035465,  -5.37070525,\n",
       "        16.13714105,  -5.93463435])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화 \n",
    " - 길이도 정보를 가지고 있는데 왜 줄이느냐 라는 비판도 있다.\n",
    "  - 보통 많이 사용한다. \n",
    "  - 다른걸 한다고 해서 크게 좋아지는건 없다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer) \n",
    "# 연속으로 적용할 수 있도록 svd -> normalizer가 될 수 있도록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = lsa.fit_transform(tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80363434, -0.08666076, -0.21624615, -0.24369955,  0.06546113,\n",
       "       -0.28970674,  0.16617507, -0.10525595,  0.31657606, -0.11567786])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pos[0, :] ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클러스터링 \n",
    " - 1차로 임의의 점으로 cluster 갯수로 해서 가까운 놈들로 나눈다.\n",
    " - cluster 에 나누어진 놈들끼리 평균을 구하면 다시 중심을 구할 수 있다.\n",
    " - 또 다시 평균을 내서 중심을 잡는다. \n",
    " - 그리고 점들을 중심에서의 거리를 구하고 가까운 놈들에게 포함시키게 한다.\n",
    " - 변화가 없을때 까지 돌린다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 0, 3, 0, 0, 1, 1, 2, 3, 3, 1, 3, 1, 2, 1, 0, 2, 3, 2, 1,\n",
       "       0, 2, 0, 3, 2, 3, 1, 1, 3, 0, 3, 0, 0, 3, 4, 1, 1, 4, 0, 2, 0, 0, 4,\n",
       "       4, 3, 4, 0, 2, 0, 2, 0, 2, 0, 4, 1, 0, 4, 4, 0, 0, 0, 1, 0, 1, 0, 3,\n",
       "       1, 0, 0, 0, 2, 2, 4, 4, 4, 2, 3, 4, 2, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 안녕하세요 ICT멘토링 서포터즈 7기 손영주입니다제가 알려드리는 2번째 ICT트렌드는 바로 '딥러닝'입니다'딥러닝'이 무엇이냐고요? '딥러닝'(Deep Learning) 쉽게 말씀드리자면 학습을 통한 생각하는 컴퓨터가까운 예시는 이세돌 9단과 바둑을 두었던 알파고인데요.역사적인 사건 혹은 대결이었던 이 대전은 ICT에 관심이 없었던 많은 사람들에게도 인공지능(AI)에 대한 관심을 불러일으켰습니다.많은 사람들과 이세돌은 경기 전, 낙승을 예상했지만 경기가 지날수록 이길 수 없는 상대와의 대전인 것처럼 되었습니다. 구글의 알파고는 딥러닝 기술에 기반한 프로그램인데요딥러닝에 대해 알아보겠습니다딥러닝이란 많은 데이터를 컴퓨터에 입력하고 비슷한 것끼리 분류하도록하는 기술입니다. 우리는 자각할 수 없지만 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정보처리 방식을 모방한 것입니다. 데이터를 기반으로 기계가 스스로 인지·추론·판단할 수 있게 됩니다. 위 2개의 사진은 생활 속의 딥러닝입니다.딥러닝이라면 '나'와는 아주 먼 이야기 같겠지만,얼굴 인식 기술을 페이스북 및 음성 인식 기술을 탑재한 아이폰 등일상 속에서 딥러닝을 마주하고 있습니다.현재 딥러닝은 사진 분류뿐만 아니라 문학, 그림, 게임 등다양한 산업에서 결합하고 있습니다. 이러한 딥러닝에도 한계가 있기 마련인데요!우선 '정확성'의 문제입니다.무적으로 보였던 알파고가 4번째 대국에서 패배, 페이스북이나 구글포토도 가끔 엉뚱한 사람을 태그하거나 엉뚱한 사물로 분류하기도 합니다.무조건 데이터가 많다고 해결되는 문제는 아닙니다.기계의 학습이 완벽해지는 시점이 있으며 이를 넘으면 오히려 정확성이 떨어집니다.다음은 '악용의 가능성'인데요. 예를 들면 영화 <아이로봇>처럼 틀린 정보를 기계에 학습시켜 옳지 않은 정보를 기계가 옳다고 생각하게 만든다면 영화처럼 비극이 일어나지 말라는 법은 없습니다.기하급수적인 데이터와 알고리즘의 발전으로 이러한 한계를넘어서다 보면 딥러닝이 적용될 수 있는 분야는 무궁무진하다 생각합니다 ICT 트렌드 '딥러닝'에 대해 알아보았는데요,딥러닝의 한계를 넘어서 인류에 좋은 방향으로 사용되길 바라는 4조 AdvanCT의 손영주였습니다 \""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 최근 알파고 기사가 계속 나오길래 잠깐 기사를 보다가... 알파고가 일부 소스코드를 공개했다고 합니다. 진짜 공개했는지는 모르겠고 replication 버전만 공개되어있습니다. Rochester-NRT/AlphaGoAlphaGo - A replication of DeepMind\\'s 2016 Nature publication, \"Mastering the game of Go with deep neural networks and tree searc...github.com메인으로 들어가면 다음과 같은 화면이 나옵니다.지금시간 기준으로 21시간전에 소스코드를 업데이트 하였네요... 파이썬으로 구성되어 있네요. 대세는 오픈소스! 저 링크를 따라가보면 또 다른 오픈소스가 나옵니다. http://pachi.or.cz/ 바둑 알고리즘 오픈 소스입니다. 메인에 있는 소스코드들 중에 중요한 내용이 있나 확인해 봤는데 특별히 없네요. training 폴더안의 소스코드는 빈통이고요. models 폴더의 메인 스켈레톤도 빈통이예요 ㅜㅜ 몇몇개는 오픈소스에서 따온거 같고...하지만 몇몇 의미있는 코드들도 있습니다. deep_polcy.py 부분인데요...소스 코드를 살펴보니 딥러닝을 위해 Keras 라이브러리를 사용하고 모델 두개 중 Sequential 모델을 사용하였네요.딥러닝에 크게 관심이 없었는데 라이브러리를 보니까 멋져요 !이렇게 쉽게 딥러닝을 할 수 있는 라이브러리가 있다니!!! Keras Documentationkeras.io ..... 그외에 공개 내용중엔 특별한게 없는거 같네요.알파고 테스트 소스에 바둑판 배열은 있네요... 남은 3판은 누가 이길까요? 개인적으로는 알파고의 패턴을 잡아내서 이세돌씨가 이겼으면 하는 생각입니다. '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[3]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [work]",
   "language": "python",
   "name": "Python [work]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
