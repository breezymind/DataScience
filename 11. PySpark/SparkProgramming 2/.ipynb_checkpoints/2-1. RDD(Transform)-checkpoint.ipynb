{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RDD(Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 RDD 생성\n",
    " - 1. 드라이버 프로그램의 Collection 객체를 ㅇ용.\n",
    "  - python의 경우 LIST를 활용.\n",
    " - 2. 파일과 같은 외부 데이터를 이용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\"])\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#pySpark ', '', '## packpub.com ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.textFile(\"../README.md\")\n",
    "rdd1.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 RDD 기본 액션\n",
    " - Transformation & Action으로 나눌 수 있다.\n",
    " - 두 연산을 구분하는 기준이 바로 연산의 수행결과가 RDD 인지 아닌지.\n",
    "  - RDD로 나오면 Transformation 아니면 Action이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4.1 collect \n",
    " - 모든 원소를 모아서 배열로 돌려준다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1,10))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4.2 Count \n",
    " - 전체 요소의 개수를 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Transformation \n",
    " - 기존 RDD를 활용하여 새로운 RDD를 생성하는 연산. \n",
    " - 각 요소의 타입을 문자열에서 숫자로 바꾸거나, 불필요한 요소를 제외하거나 기존 요소의 값에 특정 값을 더하는 등의 작업이 모두 포함 된다. \n",
    " - 맵(map) 연산 : 요소 간의 사상을 정의한 함수를 RDD에 속하는 모든 요소에 적용하여 새로운 RDD 생성\n",
    " - 그룹화 연산 : 특정 조건에 따라 요소를 그룹화 하거나 특정함수를 적용.\n",
    " - 집합 연산 : RDD에 포함된 요소를 하나의 집합으로 간주할 때 서로 다른 RDD간에 합, 교집합을 계산\n",
    " - 파티션 연산 : 파티션 개수를 조정\n",
    " - 필터와 정렬 연산 : 특정 조건을 만족하는 요소만 선택하거나 각 요소를 정해진 기준에 따라 정렬. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.1 Map\n",
    " - 함수를 RDD에 속하는 모든 요소에 적용한 뒤 그 결과로 구성된 새로운 RDD를 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(range(1,10))\n",
    "rdd2 = rdd1.map(lambda v:v+1)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.2 flatMap\n",
    " - map()과 비슷한 동작을 한다. \n",
    " - flat한 형태로 모든 값들을 하나로 쭉 이어서 시퀀스형태로 출력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([\"apple,oragne\",\"grape,apple,mango\",\"blueberry,totamo,orange\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'oragne'], ['grape', 'apple', 'mango'], ['blueberry', 'totamo', 'orange']]\n"
     ]
    }
   ],
   "source": [
    "print(rdd1.map(lambda v:v.split(\",\")).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'oragne', 'grape', 'apple', 'mango', 'blueberry', 'totamo', 'orange']\n"
     ]
    }
   ],
   "source": [
    "rdd2 = rdd1.flatMap(lambda v:v.split(\",\"))\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.3 mapPartitions\n",
    " - map(), flatMap()의 경우 RDD의 각 요소를 하나씩 처리 \n",
    " - mapPartitions는 파티션 단위로 처리 : 인자로 전달받은 함수를 파티션 단위로 적용, 그 결과로 구성된 새로운 RDD를 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def increase(numbers):\n",
    "    print(\"DB 연결\")\n",
    "    return(i+1 for i in numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 여기서 DB연결이라는 표현이 안나오는 이유는 Jupyter notebook이라서. \n",
    " - 해당 부분이 4번 DB 연결이라고 나온다. 즉, 4개의 파티션으로 구성 되어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(range(1,10))\n",
    "rdd2 = rdd1.mapPartitions(increase)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 개의 파티션으루 구성 \n"
     ]
    }
   ],
   "source": [
    "print(\"%s 개의 파티션으루 구성 \" % len(rdd1.glom().collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition size : 4\n"
     ]
    }
   ],
   "source": [
    "print(\"partition size : %d\" % rdd1.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.4 mapParitionWithIndex (Python은 없다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.5 mapValues\n",
    " - RDD요소가 Key-Value 형태로 구성되어있을 때사용. 키를 기준으로 작은 그룹들을 만들고 해당 그룹들에 속한 값을 대상으로 연산을 수행(합계, 평균 등). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1), ('c', 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\"]).map(lambda v:(v,1))\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('b', 2), ('c', 2)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd1.mapValues(lambda i:i+1)\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.6 flatMapValues(Python은 없다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그룹과 관련된 연산 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.7 zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 2), ('c', 3)]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\"])\n",
    "rdd2 = sc.parallelize(range(1,4))\n",
    "result = rdd1.zip(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.8 zipPartitions(python은 없다)\n",
    " - 파티션별로 zip 연산을 수행하고 특정 함수를 적용해 그결과로 구성된 새로운 RDD를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.9 groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', <pyspark.resultiterable.ResultIterable at 0x7f176c5516d8>),\n",
       " ('odd', <pyspark.resultiterable.ResultIterable at 0x7f176c551860>)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(range(1,11))\n",
    "rdd2 = rdd1.groupBy(lambda v: \"even\" if  v % 2 ==0 else \"odd\")\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even [2, 4, 6, 8, 10]\n",
      "odd [1, 3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "for x in rdd2.collect():\n",
    "    print(x[0], list(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.10 groupByKey \n",
    " - Key별로 Groupby 를 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b [1, 1]\n",
      "c [1, 1]\n",
      "a [1]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\",\"b\",\"c\"]).map(lambda v: (v,1))\n",
    "rdd2 = rdd1.groupByKey()\n",
    "for x in rdd2.collect():\n",
    "    print(x[0],list(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 2), ('c', 2), ('a', 1)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.reduceByKey(lambda v1, v2: v1+v2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.11 cogroup \n",
    " - Key-Value 일 경우 사용 가능. \n",
    " - 같은 키를 갖는 요소를 찾아서 같은 요소를 시퀀스로 구성된 튜플로 만들고 새로운 RDD로 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 ['v1', 'v3'] ['v4']\n",
      "k2 ['v2'] []\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([(\"k1\",\"v1\"),(\"k2\",\"v2\"),(\"k1\",\"v3\")])\n",
    "rdd2 = sc.parallelize([(\"k1\",\"v4\")])\n",
    "result = rdd1.cogroup(rdd2)\n",
    "for x in result.collect():\n",
    "    print(x[0],list(x[1][0]),list(x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 집합과 관련된 연산들 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.12 distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,2,3,1,2,3,1,2,3])\n",
    "result = rdd1.distinct()\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.13 cartesian \n",
    " - 카테시안 곱을 구하고 새로운 RDD로 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c'), (3, 'a'), (3, 'b'), (3, 'c')]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,2,3])\n",
    "rdd2 = sc.parallelize([\"a\",\"b\",\"c\"])\n",
    "result = rdd1.cartesian(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.14 subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\",\"d\",\"e\"])\n",
    "rdd2 = sc.parallelize([\"d\",\"e\"])\n",
    "result = rdd1.subtract(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.15 union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f']\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\"])\n",
    "rdd2 = sc.parallelize([\"d\",\"e\",\"f\"])\n",
    "result = rdd1.union(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.16 intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c']\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"a\",\"b\",\"c\"])\n",
    "rdd2 = sc.parallelize([\"a\",\"a\",\"c\",\"c\"])\n",
    "result = rdd1.intersection(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.17 Join (inner join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', (1, 2)), ('c', (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\",\"d\",\"e\"]).map(lambda v:(v,1))\n",
    "rdd2 = sc.parallelize([\"b\",\"c\"]).map(lambda v:(v,2))\n",
    "result = rdd1.join(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.18 leftOuterJoin. rightOuterJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left : [('a', (1, None)), ('b', (1, 2)), ('c', (1, 2))]\n",
      "Right : [('b', (1, 2)), ('c', (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\",\"c\"]).map(lambda x: (x,1))\n",
    "rdd2 = sc.parallelize([\"b\",\"c\"]).map(lambda v:(v,2))\n",
    "result1 = rdd1.leftOuterJoin(rdd2)\n",
    "result2 = rdd1.rightOuterJoin(rdd2)\n",
    "print(\"Left : %s\" % result1.collect())\n",
    "print(\"Right : %s\" % result2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1.5.19 subtractByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtract : [('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\",\"b\"]).map(lambda v:(v,1))\n",
    "rdd2 = sc.parallelize([\"b\"]).map(lambda v:(v,1))\n",
    "result = rdd1.subtractByKey(rdd2)\n",
    "print(\"subtract : %s\" % result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [집계와 연관된 연산들]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.20 reduceByKey\n",
    " - RDD의 구성요소가 키와 값의 쌍으로 구성된 경우 사용.\n",
    " - 같은 키를 가진 값들을 하나로 병합해 Key-Value로 구성. \n",
    " - 병학을 위해 두 개의 값을 하나로 합치는 함수를 인자로 전달받는다 \n",
    "  - 이때 함수가 수행하는 연산은 경합법칙과 쇼괗넙ㅂ칙이 성립됨을 보장해야한다. \n",
    "  - 여러 파티션으로 분산돼 항상 같은 순서로 연산이 수행됨을 보장 할 수 없다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 1), ('b', 1)]\n",
      "[('b', 2), ('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([\"a\",\"b\",\"b\"]).map(lambda v:(v,1))\n",
    "print(rdd.collect())\n",
    "result = rdd.reduceByKey(lambda v1, v2 : v1 + v2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.21 foldByKey\n",
    " - 전반적인 동작은 reduceByKey와 비슷하게 동작하여 RDD를 생성한다.\n",
    " - 병한 연산의 초기값을 메서드의 인자로 전달해서 병합 시 사용할 수 있다는 점에서 차이가 있다. \n",
    " - 예)\n",
    "  - 병학에 사용하는 함수가 두 개의 정숫값을 더하는 함수였다면 0을 사용하고 두 문자열을 연결해서 새로운 문자열을 만드는 함수 였다면 공백 문자 \"\"을 초깃값으로 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 2), ('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([\"a\",\"b\",\"b\"]).map(lambda v:(v,1))\n",
    "result = rdd.foldByKey(0, lambda v1,v2 : v1 + v2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a1', '@v1'), ('b1', '@v2@v3')]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a1\",\"v1\"),(\"b1\",\"v2\"),(\"b1\",\"v3\")])\n",
    "result = rdd.foldByKey(\"@\", lambda v1,v2 : v1 + v2) # 내가 원하는 구분자를 줄수 있다. \n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.22 combineByKey \n",
    " - 위의 두 함수와 같은 기능을 수행하지만, 수행과정에서 값의 타입을 바뀔 수 있다는 점의 차이가 있다. \n",
    " - 가장 많이 등장하는 평균의 예제이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Record:\n",
    "    def __init__(self, amount, number=1):\n",
    "        self.amount = amount\n",
    "        self.number = number\n",
    "        \n",
    "    def addAmt(self, amount):\n",
    "        return Record(self.amount + amount, self.number + 1)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        amount = self.amount + other.amount\n",
    "        number = self.number + other.number \n",
    "        return Record(amount, number)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"avg:\" + str(self.amount / self.number)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Record(%r, %r)' % (self.amount, self.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combineBy\n",
    "def createCombiner(v):\n",
    "    return Record(v)\n",
    "\n",
    "\n",
    "# combineBy\n",
    "def mergeValue(c, v):\n",
    "    return c.addAmt(v)\n",
    "\n",
    "\n",
    "# combineBy\n",
    "def mergeCombiners(c1, c2):\n",
    "    return c1 + c2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"Math\", 100), (\"Eng\", 80), (\"Math\", 50), (\"Eng\", 70), (\"Eng\", 90)])\n",
    "result = rdd.combineByKey(lambda v: createCombiner(v), lambda c, v: mergeValue(c, v),\n",
    "                                  lambda c1, c2: mergeCombiners(c1, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Math', result.collectAsMap()['Math'], 'Eng', result.collectAsMap()['Eng'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipe 및 파티션과 관련된 연산 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.24 pipe\n",
    " - 데이터를 처리하는 과정에서 외부 프로세스를 활용할 수 있다. \n",
    " - 세 개의 숫자로 구성된 문자열을 리눅스의 cut 유틸리티를 이용해 분리한 뒤 첫번째와 세번째 숫자를 뽑아내는 예제입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,3', '4,6', '7,9']\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([\"1,2,3\",\"4,5,6\",\"7,8,9\"])\n",
    "result = rdd.pipe(\"cut -f 1,3 -d ,\")\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.25 coalesce와 repartition \n",
    " - RDD를 생성한 뒤 filter()연산을 비롯한 다양한 트랜스 포메이션을 수행하다보면 최초에 설정된 파티션 개수가 적합하지 않은 경우가 발생한다. \n",
    " - 위의 함수를 통해 조정이 가능하다. \n",
    " - repartition 은 늘리고 줄이는 것이 가능.\n",
    " - coalesce는 줄이는 것만 가능. \n",
    " - 두 개의 성능 차이가 있다. \n",
    "  - repartition은 셔플을 기반으로 동작, coalesce는 강제로 셔플을 수행하지 않을 경우 사용하지 않는다. \n",
    "  - 늘릴때는 repartition, 줄일때는 coalesce를 이용하는 것이 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize(list(range(1,11)),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd2 = rdd1.coalesce(5)\n",
    "rdd3 = rdd2.repartition(110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition size : 10\n",
      "partition size : 5\n",
      "partition size : 110\n"
     ]
    }
   ],
   "source": [
    "print(\"partition size : %d\" % rdd1.getNumPartitions())\n",
    "print(\"partition size : %d\" % rdd2.getNumPartitions())\n",
    "print(\"partition size : %d\" % rdd3.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.26 repartitionAndSortWithinPartitions\n",
    " - 모든 데이터를 특정 기준에 따라 여러 개의 파티션으로 분리하고 각 파티션 단위로 정렬을 수행한 뒤 이 결과로 새로운 RDD를 생성. \n",
    " - Key - Value 형태로 존재해야하며,각 데이터가 어떤 파티션에 속할지 결정하기 위한 파티셔너를 설정해야한다. \n",
    " - 10개의 무작위 숫자를 위의 함수를 이용하여 3개의 파티션으로 분리해보는 예제. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86, 61, 70, 78, 4, 88, 37, 85, 74, 18]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [random.randrange(1,100) for i in range(0,10)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(86, '-'), (61, '-'), (70, '-'), (78, '-'), (4, '-'), (88, '-'), (37, '-'), (85, '-'), (74, '-'), (18, '-')]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(data).map(lambda v:(v,\"-\"))\n",
    "print(rdd1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd2 = rdd1.repartitionAndSortWithinPartitions(3, lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 partition : [(18, '-'), (78, '-')]\n",
      "2 번째 partition : [(4, '-'), (37, '-'), (61, '-'), (70, '-'), (85, '-'), (88, '-')]\n",
      "3 번째 partition : [(74, '-'), (86, '-')]\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,len(rdd2.glom().collect()) + 1):\n",
    "    print(\"{number} 번째 partition : {lists}\".format(number=x, lists=rdd2.glom().collect()[x-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.27 partitionBy \n",
    " - Key - Value 구성\n",
    " - org.apache.spark.Partitioner 클래스의 인스턴스를 인자로 전달. \n",
    " - Partitioner는 각 요소의 키를 특정 파티션에 할당하는 역할을 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1 : 5, rdd2 : 3\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([(\"apple\",1),(\"mouse\",1),(\"monitor\",5)],5)\n",
    "rdd2 = rdd1.partitionBy(3)\n",
    "print(\"rdd1 : %d, rdd2 : %d\" %(rdd1.getNumPartitions(), rdd2.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필터와 정렬 연산 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.28 filer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(range(1,6))\n",
    "rdd2 = rdd1.filter(lambda v: v > 2)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.29 sortByKey\n",
    " - Key를 기준으로 정렬. \n",
    " - 소팅이 완료된 후에는 파티션 내부의 요소는 소팅 순서상 인접한 요소로 재구성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('q', 1), ('z', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"q\",1),(\"z\",1),(\"a\",1)])\n",
    "result = rdd.sortByKey()\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.30 keys, values\n",
    " - RDD의 구성요소가 Key-Value 쌍으로 구성된 경우에만 사용 가능. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'z', 'a']\n",
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(rdd.keys().collect())\n",
    "print(rdd.values().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5.31 sample\n",
    " - 샘픔을 추출해 새로운 RDD로 생성. \n",
    " - sample(withReplacement:Boolean, fraction:Double, seed:Long=Utils.random.nextLong)\n",
    "  - withReplacement : 복원추출 수행 여부 \n",
    "  - fraction : 복원 추출일때와 비복원 추출일때가 달라진다. \n",
    "  - 복원 : 각 요소가 나타나는 횟수에 대한 기대값, 즉 각 요소의 평균 발생 횟수를 나타낸다. 반드시 0 이상\n",
    "  - 비복원 : 각 요소가 샘플에 포함될 확률을 의미하며, 0과 1사이 값으로 지정. \n",
    " - sample은 크기를 지정해놓고 추출하는 것이 아님을 알고 있어야 한다.(pySpark 수정 해야될듯.)\n",
    "  - 정확한 크기를 정해놓고 샘플을 추출하고자 한다면 다음에 나올 takeSample을 이용해야한다. \n",
    " - seed : 일정한 값이 나올 수 있도록 조정하는 (제어의 목적) 값. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 6, 10, 12]\n",
      "[1, 2, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1,101))\n",
    "result1 = rdd.sample(False,0.5,100)\n",
    "result2 = rdd.sample(True,1.5,100)\n",
    "print(result1.take(5))\n",
    "print(result2.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
