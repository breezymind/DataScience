{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('train.txt', unpack=True, dtype='float32')\n",
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 설명\n",
    " - [biasTerm????, 공부시간, 수업참여횟수, 합격유무]\n",
    " - [1., 2., 1., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  1.,  0.],\n",
       "       [ 1.,  3.,  2.,  0.],\n",
       "       [ 1.,  3.,  5.,  0.],\n",
       "       [ 1.,  5.,  5.,  1.],\n",
       "       [ 1.,  7.,  5.,  1.],\n",
       "       [ 1.,  2.,  5.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1,len(x_data)],-1.0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = tf.matmul(W,X)\n",
    "hypothesis = tf.div(1.,1.+tf.exp(-h)) # CostFunction of Logistic Regression Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.Variable(0.1)  # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)  # goal is minimize cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Starting, initialize the variables. We will 'run' this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.894237 [[-0.02964249 -0.4294281   0.22271553]]\n",
      "20 0.629368 [[-0.23305741 -0.11990341  0.30537596]]\n",
      "40 0.599837 [[-0.45894271 -0.0364297   0.27419928]]\n",
      "60 0.576248 [[-0.66991657  0.01532542  0.27219215]]\n",
      "80 0.556039 [[-0.8676188   0.05045069  0.28384593]]\n",
      "100 0.538314 [[-1.05332661  0.07681758  0.30143097]]\n",
      "120 0.522628 [[-1.22811651  0.09836514  0.32124308]]\n",
      "140 0.50868 [[-1.39293623  0.1170508   0.34155455]]\n",
      "160 0.49623 [[-1.54863548  0.13385887  0.3615877 ]]\n",
      "180 0.485081 [[-1.6959821   0.14929825  0.38101193]]\n",
      "200 0.475058 [[-1.83566844  0.1636501   0.39971134]]\n",
      "220 0.466016 [[-1.96832108  0.17707966  0.4176653 ]]\n",
      "240 0.457835 [[-2.09450507  0.18969683  0.43489337]]\n",
      "260 0.450409 [[-2.21473074  0.20158133  0.45143446]]\n",
      "280 0.443646 [[-2.329458    0.21279974  0.46732911]]\n",
      "300 0.437467 [[-2.43910217  0.22340304  0.48262268]]\n",
      "320 0.431807 [[-2.54403901  0.23343891  0.49735665]]\n",
      "340 0.426608 [[-2.64460802  0.24294932  0.51156658]]\n",
      "360 0.42182 [[-2.74111772  0.25197339  0.52528667]]\n",
      "380 0.417399 [[-2.83384657  0.26054513  0.53854913]]\n",
      "400 0.413309 [[-2.92304921  0.26869678  0.55138278]]\n",
      "420 0.409516 [[-3.00895691  0.27645719  0.563811  ]]\n",
      "440 0.405989 [[-3.09178019  0.28385308  0.57586062]]\n",
      "460 0.402704 [[-3.17171121  0.29090804  0.58755267]]\n",
      "480 0.399638 [[-3.24892688  0.29764506  0.59890693]]\n",
      "500 0.396771 [[-3.32358909  0.30408412  0.60994172]]\n",
      "520 0.394086 [[-3.39584613  0.31024432  0.62067389]]\n",
      "540 0.391567 [[-3.46583438  0.31614304  0.63111901]]\n",
      "560 0.389199 [[-3.53367996  0.32179633  0.64129144]]\n",
      "580 0.386971 [[-3.59949923  0.32721883  0.65120459]]\n",
      "600 0.38487 [[-3.6633997   0.33242425  0.66087079]]\n",
      "620 0.382888 [[-3.72548079  0.33742502  0.67030209]]\n",
      "640 0.381013 [[-3.78583527  0.34223267  0.67950881]]\n",
      "660 0.379239 [[-3.84454894  0.34685817  0.68850124]]\n",
      "680 0.377559 [[-3.90170169  0.35131171  0.69728887]]\n",
      "700 0.375964 [[-3.95736837  0.35560194  0.7058804 ]]\n",
      "720 0.37445 [[-4.01161766  0.35973844  0.71428448]]\n",
      "740 0.373009 [[-4.06451559  0.36372823  0.72250807]]\n",
      "760 0.371639 [[-4.11612177  0.36757955  0.73055941]]\n",
      "780 0.370333 [[-4.16649437  0.37129909  0.73844481]]\n",
      "800 0.369087 [[-4.2156868   0.37489346  0.746171  ]]\n",
      "820 0.367897 [[-4.26374674  0.37836838  0.75374538]]\n",
      "840 0.366762 [[-4.31072283  0.38172981  0.76117128]]\n",
      "860 0.365675 [[-4.35666084  0.38498321  0.76845455]]\n",
      "880 0.364635 [[-4.40160036  0.3881335   0.77560121]]\n",
      "900 0.363639 [[-4.44558191  0.39118627  0.78261584]]\n",
      "920 0.362684 [[-4.48864222  0.39414495  0.78950286]]\n",
      "940 0.361769 [[-4.53081656  0.39701426  0.79626715]]\n",
      "960 0.360889 [[-4.57213879  0.3997975   0.80291253]]\n",
      "980 0.360045 [[-4.6126399   0.40249905  0.80944335]]\n",
      "1000 0.359233 [[-4.65234852  0.40512204  0.81586301]]\n",
      "1020 0.358452 [[-4.69129419  0.40766951  0.82217556]]\n",
      "1040 0.3577 [[-4.72950411  0.41014537  0.82838416]]\n",
      "1060 0.356976 [[-4.76700354  0.41255209  0.83449173]]\n",
      "1080 0.356278 [[-4.8038168   0.41489235  0.84050113]]\n",
      "1100 0.355604 [[-4.83996582  0.4171688   0.84641582]]\n",
      "1120 0.354955 [[-4.87547255  0.41938448  0.85223883]]\n",
      "1140 0.354328 [[-4.91035938  0.42154169  0.85797244]]\n",
      "1160 0.353722 [[-4.9446454   0.4236421   0.86361951]]\n",
      "1180 0.353137 [[-4.97835302  0.42568833  0.86918318]]\n",
      "1200 0.352571 [[-5.01149368  0.42768219  0.87466496]]\n",
      "1220 0.352023 [[-5.04408789  0.42962542  0.88006699]]\n",
      "1240 0.351494 [[-5.0761528   0.4315199   0.88539189]]\n",
      "1260 0.350981 [[-5.10770416  0.433368    0.89064229]]\n",
      "1280 0.350484 [[-5.13875675  0.43517107  0.89581925]]\n",
      "1300 0.350003 [[-5.16932678  0.43693063  0.90092522]]\n",
      "1320 0.349535 [[-5.19942522  0.43864799  0.90596181]]\n",
      "1340 0.349082 [[-5.22906733  0.44032443  0.91093087]]\n",
      "1360 0.348643 [[-5.2582655   0.4419618   0.91583478]]\n",
      "1380 0.348216 [[-5.28703117  0.44356123  0.92067426]]\n",
      "1400 0.347802 [[-5.31537771  0.44512436  0.92545116]]\n",
      "1420 0.347397 [[-5.34331512  0.44665235  0.93016905]]\n",
      "1440 0.347006 [[-5.37085485  0.44814467  0.93482608]]\n",
      "1460 0.346626 [[-5.39800596  0.44960415  0.93942463]]\n",
      "1480 0.346257 [[-5.42478228  0.45103222  0.94396633]]\n",
      "1500 0.345897 [[-5.45119143  0.45242953  0.94845265]]\n",
      "1520 0.345548 [[-5.47724247  0.45379698  0.95288473]]\n",
      "1540 0.345207 [[-5.50294542  0.45513493  0.95726371]]\n",
      "1560 0.344875 [[-5.52830696  0.45644483  0.9615916 ]]\n",
      "1580 0.344552 [[-5.5533371   0.45772755  0.96586895]]\n",
      "1600 0.344238 [[-5.57804346  0.45898378  0.97009689]]\n",
      "1620 0.343931 [[-5.60243416  0.46021453  0.9742766 ]]\n",
      "1640 0.343632 [[-5.62651634  0.46142033  0.97840905]]\n",
      "1660 0.34334 [[-5.65029669  0.46260154  0.98249531]]\n",
      "1680 0.343056 [[-5.67378283  0.46375918  0.98653638]]\n",
      "1700 0.342778 [[-5.69698143  0.46489388  0.99053323]]\n",
      "1720 0.342507 [[-5.71989965  0.46600637  0.99448699]]\n",
      "1740 0.342242 [[-5.7425437   0.46709722  0.99839836]]\n",
      "1760 0.341984 [[-5.7649188   0.46816736  1.0022682 ]]\n",
      "1780 0.341732 [[-5.78703213  0.469217    1.00609744]]\n",
      "1800 0.341486 [[-5.80888748  0.47024661  1.0098865 ]]\n",
      "1820 0.341245 [[-5.83049297  0.4712573   1.01363671]]\n",
      "1840 0.341009 [[-5.85185289  0.47224906  1.01734841]]\n",
      "1860 0.340779 [[-5.87297201  0.47322264  1.02102256]]\n",
      "1880 0.340554 [[-5.89385605  0.47417817  1.02465987]]\n",
      "1900 0.340334 [[-5.9145093   0.47511655  1.02826142]]\n",
      "1920 0.340119 [[-5.934937    0.47603825  1.03182733]]\n",
      "1940 0.339908 [[-5.95514393  0.47694352  1.03535855]]\n",
      "1960 0.339702 [[-5.9751339   0.477833    1.03885579]]\n",
      "1980 0.3395 [[-5.99491119  0.47870654  1.04231942]]\n",
      "2000 0.339303 [[-6.01448059  0.47956505  1.04574978]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "- 학습시간 + 수업시간 => 합격 유무\n",
    "- hypothesis 를 수행하면 된다.\n",
    " - feed_dict={X: [[1], [2], [2]]} [1] 합격 유무의 값 [2] 공부시간 [2] 수업시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "[[False]]\n",
      "[[ True]]\n",
      "[[False  True]]\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------')\n",
    "print(sess.run(hypothesis, feed_dict={X: [[1], [2], [2]]}) > 0.5)\n",
    "print(sess.run(hypothesis, feed_dict={X: [[1], [5], [5]]}) > 0.5)\n",
    "print(sess.run(hypothesis, feed_dict={X: [[1, 1], [4, 0], [2, 10]]}) > 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
