{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Learning Rate\n",
    " - Using Softmax Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('05train.txt', unpack=True, dtype='float32')\n",
    "x_data = np.transpose(xy[0:3])\n",
    "y_data = np.transpose(xy[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.zeros([3, 3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W)) # W,X 가 아니라 X,W인 이유는 Transpose를 했기때문에. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - learning_rate 크기를 조절하면서 테스트 해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning_rate = 10  # Cost 가 널뛰기 null 출력이된다.\n",
    "#learning_rate = 0.001  # Cost 가 거의 줄지 않는다.\n",
    "#learning_rate = 0.01  \n",
    "learning_rate = 0.1  \n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.06781 [[-0.00833327  0.00416668  0.00416668]\n",
      " [ 0.01666674  0.02916669 -0.04583302]\n",
      " [ 0.01666675  0.04166665 -0.05833297]]\n",
      "200 0.699683 [[-1.57376003 -0.36409676  1.93788362]\n",
      " [ 0.09681746 -0.09231772 -0.00437415]\n",
      " [ 0.24919677  0.23827817 -0.48734969]]\n",
      "400 0.59458 [[-2.54306674 -0.43171379  2.9748354 ]\n",
      " [ 0.13072962 -0.04832886 -0.08215404]\n",
      " [ 0.40742886  0.22865921 -0.63584149]]\n",
      "600 0.535831 [[-3.31518102 -0.39112973  3.70639396]\n",
      " [ 0.1399519  -0.02451963 -0.11506222]\n",
      " [ 0.54855651  0.21309519 -0.7612828 ]]\n",
      "800 0.494315 [[-3.98389435 -0.31140164  4.29540634]\n",
      " [ 0.14195155 -0.00918721 -0.1322732 ]\n",
      " [ 0.67504013  0.19524136 -0.86979216]]\n",
      "1000 0.461918 [[ -4.58330011e+00  -2.18485668e-01   4.80192327e+00]\n",
      " [  1.41662374e-01   1.74681633e-03  -1.42792076e-01]\n",
      " [  7.89558887e-01   1.77215129e-01  -9.66157854e-01]]\n",
      "1200 0.435344 [[-5.13015604 -0.12338698  5.25370932]\n",
      " [ 0.14069138  0.01004168 -0.14999084]\n",
      " [ 0.89424205  0.16000019 -1.05350411]]\n",
      "1400 0.412893 [[-5.6345911  -0.03100367  5.66579199]\n",
      " [ 0.13961178  0.01658915 -0.15533745]\n",
      " [ 0.99072587  0.14400907 -1.1338743 ]]\n",
      "1600 0.393535 [[-6.10358572  0.05652753  6.04728508]\n",
      " [ 0.13862401  0.0219015  -0.15953778]\n",
      " [ 1.08028889  0.12936941 -1.20867682]]\n",
      "1800 0.376596 [[-6.54233789  0.13839217  6.40420151]\n",
      " [ 0.1377843   0.02629201 -0.16296612]\n",
      " [ 1.16394186  0.1160811  -1.27891934]]\n",
      "2000 0.361592 [[-6.95491695  0.21442337  6.74077082]\n",
      " [ 0.13709328  0.0299692  -0.16583981]\n",
      " [ 1.24249578  0.10407317 -1.34535038]]\n",
      "a : [[  8.78134191e-01   1.21488109e-01   3.77682911e-04]] [0]\n",
      "b : [[ 0.04476507  0.44394737  0.51128757]] [2]\n",
      "c : [[  1.52344467e-06   1.77790457e-03   9.98220503e-01]] [2]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "    a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7]]})\n",
    "    print (\"a :\", a, sess.run(tf.arg_max(a, 1)))\n",
    "\n",
    "    b = sess.run(hypothesis, feed_dict={X: [[1, 3, 4]]})\n",
    "    print (\"b :\", b, sess.run(tf.arg_max(b, 1)))\n",
    "\n",
    "    c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0]]})\n",
    "    print(\"c :\", c, sess.run(tf.arg_max(c, 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
