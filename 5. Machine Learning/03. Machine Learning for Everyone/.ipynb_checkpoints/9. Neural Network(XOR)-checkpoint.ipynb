{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network 1: XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('07train.txt', unpack= True)\n",
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1,len(x_data)],-1.0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hypothesis\n",
    "h = tf.matmul(W,X)\n",
    "hypothesis = tf.div(1.,1.+tf.exp(-h))\n",
    "\n",
    "#cost function\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimize \n",
    "a = tf.Variable(0.01) # learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.730594 [[ 0.89144653 -0.3110007 ]]\n",
      "200 0.718176 [[ 0.73556656 -0.33078527]]\n",
      "400 0.710574 [[ 0.61259198 -0.33163002]]\n",
      "600 0.705715 [[ 0.51485693 -0.32041195]]\n",
      "800 0.702453 [[ 0.43636063 -0.30205098]]\n",
      "[array([[ 0.49999809,  0.43044424,  0.59214967,  0.52318865]], dtype=float32), array([[ 0.,  0.,  1.,  1.]], dtype=float32), array([[ True, False,  True, False]], dtype=bool), 0.5]\n",
      "Accuracy : 0.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1000):\n",
    "        sess.run(train,feed_dict={X:x_data,Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step,sess.run(cost, feed_dict={X:x_data,Y:y_data}), sess.run(W))\n",
    "    #test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy],feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy :\",accuracy.eval({X:x_data,Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  1.]]\n",
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('07train.txt', unpack= True)\n",
    "x_data = np.transpose(xy[0:-1]) # 그냥 T로 해도 무관하다.\n",
    "y_data = np.reshape(xy[-1],(4,1)) # T로 해도 무관하다.\n",
    "\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2,2],-1.0,1.0)) # W1 은 2 x 2 \n",
    "W2 = tf.Variable(tf.random_uniform([2,1],-1.0,1.0)) # W2 는 2 X 1\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "L2 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2,W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.706673 [[-0.57628304 -0.80752927]\n",
      " [ 0.78786755  0.6393373 ]] [[ 0.11008612]\n",
      " [-0.78606141]]\n",
      "1000 0.690113 [[-0.69285113 -0.67859644]\n",
      " [ 0.72962332  0.90172321]] [[ 0.37175646]\n",
      " [-0.6819883 ]]\n",
      "2000 0.659352 [[-1.16083717 -1.2792629 ]\n",
      " [ 0.91882885  1.68050694]] [[ 1.01787519]\n",
      " [-1.27146041]]\n",
      "3000 0.311704 [[-3.17863941 -3.33933496]\n",
      " [ 2.88076091  3.60145283]] [[ 3.87371731]\n",
      " [-3.6566453 ]]\n",
      "4000 0.101457 [[-4.5485034  -4.61063957]\n",
      " [ 4.27897787  4.81617212]] [[ 6.37586975]\n",
      " [-5.86819315]]\n",
      "5000 0.0538696 [[-5.1095252  -5.15615463]\n",
      " [ 4.84866285  5.35889626]] [[ 7.61145735]\n",
      " [-7.05345154]]\n",
      "6000 0.0357304 [[-5.43099403 -5.47353029]\n",
      " [ 5.17402887  5.67877817]] [[ 8.38922501]\n",
      " [-7.81793737]]\n",
      "7000 0.0264803 [[-5.64981937 -5.69099188]\n",
      " [ 5.39496326  5.8991189 ]] [[ 8.95111656]\n",
      " [-8.37567997]]\n",
      "8000 0.020941 [[-5.81335258 -5.8540659 ]\n",
      " [ 5.55976439  6.06480885]] [[ 9.38939571]\n",
      " [-8.81286049]]\n",
      "[array([[ 0.02035927],\n",
      "       [ 0.98133063],\n",
      "       [ 0.97328591],\n",
      "       [ 0.01712324]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 'wide' neural network to solve XOR problem.\n",
    " - 위의 식은 1개의 layer에 2개의 노드만 존재.\n",
    " - 아래 식은 10개의 노드를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.696061 [[ 0.77456301 -0.48697069 -0.79885447 -0.5950067  -0.24585538 -0.11151248\n",
      "   0.96470636  0.59188402  0.46099636 -0.52361101]\n",
      " [ 0.88131416  0.35992622 -0.79917061  0.06534496  0.47518432 -0.09021433\n",
      "   0.37483916 -0.17001189 -0.24022606 -0.67154294]] [[-0.04022731]\n",
      " [ 0.15905026]\n",
      " [-0.48526028]\n",
      " [-0.00326672]\n",
      " [ 0.21676567]\n",
      " [ 0.85250682]\n",
      " [ 0.20781513]\n",
      " [-0.3516489 ]\n",
      " [ 0.30496633]\n",
      " [-0.78694308]]\n",
      "1000 0.651832 [[ 0.77410066 -0.55577266 -1.57609379 -0.61037874 -0.28601658 -0.27588239\n",
      "   1.01678634  0.77786857  0.35235262 -1.29183412]\n",
      " [ 0.88063914  0.29358286 -1.53386986  0.05483     0.41053838 -0.37663597\n",
      "   0.49211732 -0.09047327 -0.37439167 -1.29582608]] [[ 0.0361503 ]\n",
      " [ 0.17718995]\n",
      " [-1.23789036]\n",
      " [ 0.13720672]\n",
      " [ 0.06801979]\n",
      " [ 0.97272485]\n",
      " [ 0.13491561]\n",
      " [-0.56958252]\n",
      " [ 0.27930254]\n",
      " [-1.15142202]]\n",
      "2000 0.483382 [[ 0.74046201 -0.81340808 -3.06410623 -0.82491833 -0.32115689 -0.56050038\n",
      "   1.02751744  1.20046878  0.11870658 -2.55744076]\n",
      " [ 0.87130833  0.0759313  -2.98251677 -0.12415393  0.36533371 -1.00729799\n",
      "   0.51140869  0.04187185 -0.79803497 -2.48974204]] [[-0.32239941]\n",
      " [ 0.58729476]\n",
      " [-3.05789971]\n",
      " [ 0.69341981]\n",
      " [ 0.0463077 ]\n",
      " [ 1.83023286]\n",
      " [-0.19536152]\n",
      " [-1.04618752]\n",
      " [ 0.72772473]\n",
      " [-2.39435554]]\n",
      "3000 0.206521 [[ 0.66807455 -1.21715188 -4.35415173 -1.15991533 -0.34197515 -1.4828136\n",
      "   1.05243385  1.739452    0.09834407 -3.64333367]\n",
      " [ 0.98857856 -0.14886157 -4.23829412 -0.39855811  0.33987495 -2.0518415\n",
      "   0.48648944  0.12572348 -1.55494058 -3.53411412]] [[-1.14798248]\n",
      " [ 1.20399475]\n",
      " [-5.06503057]\n",
      " [ 1.41193593]\n",
      " [-0.0255026 ]\n",
      " [ 3.7162025 ]\n",
      " [-0.8597675 ]\n",
      " [-1.91521204]\n",
      " [ 1.59680355]\n",
      " [-3.87436628]]\n",
      "4000 0.080154 [[ 0.66072381 -1.37339306 -4.9886694  -1.25132275 -0.31794572 -2.39911509\n",
      "   1.0777483   1.99046695  0.33070016 -4.24675655]\n",
      " [ 1.18525636 -0.18758173 -4.84927511 -0.54707873  0.37336394 -2.80068636\n",
      "   0.52313727  0.14591014 -2.06666088 -4.11057043]] [[-1.68983853]\n",
      " [ 1.41500795]\n",
      " [-6.36941481]\n",
      " [ 1.68487823]\n",
      " [-0.16294499]\n",
      " [ 5.22222662]\n",
      " [-1.2647512 ]\n",
      " [-2.4196372 ]\n",
      " [ 2.08734846]\n",
      " [-4.95329094]]\n",
      "5000 0.0428494 [[ 0.68410718 -1.44217706 -5.2952137  -1.28081262 -0.29311514 -2.89697504\n",
      "   1.09184206  2.11145711  0.51753873 -4.55754471]\n",
      " [ 1.29923677 -0.18200134 -5.15502644 -0.62509137  0.40795994 -3.20235443\n",
      "   0.54934287  0.13785966 -2.35354233 -4.4189167 ]] [[-1.97205532]\n",
      " [ 1.48792493]\n",
      " [-7.10337877]\n",
      " [ 1.79480755]\n",
      " [-0.25488192]\n",
      " [ 6.1025691 ]\n",
      " [-1.47005701]\n",
      " [-2.67022061]\n",
      " [ 2.33858204]\n",
      " [-5.59285021]]\n",
      "6000 0.0278595 [[ 0.71444362 -1.48476923 -5.47929573 -1.29842961 -0.27355871 -3.20051122\n",
      "   1.10262465  2.18905687  0.66154033 -4.74922371]\n",
      " [ 1.36852717 -0.17051683 -5.34302902 -0.67575008  0.43490094 -3.45098853\n",
      "   0.56694216  0.12484069 -2.53960133 -4.61389351]] [[-2.1482625 ]\n",
      " [ 1.52502036]\n",
      " [-7.57925749]\n",
      " [ 1.85732245]\n",
      " [-0.31812289]\n",
      " [ 6.67819166]\n",
      " [-1.59704673]\n",
      " [-2.82465005]\n",
      " [ 2.50122738]\n",
      " [-6.0169878 ]]\n",
      "7000 0.0201979 [[ 0.7448535  -1.51551712 -5.6063776  -1.31172407 -0.25796467 -3.40960717\n",
      "   1.11166787  2.24625635  0.77765346 -4.88344097]\n",
      " [ 1.41596079 -0.15912665 -5.47455406 -0.71326852  0.45629376 -3.62492275\n",
      "   0.58021939  0.11145492 -2.67442513 -4.75233126]] [[-2.27375817]\n",
      " [ 1.54833078]\n",
      " [-7.92331934]\n",
      " [ 1.89997995]\n",
      " [-0.36555442]\n",
      " [ 7.09572887]\n",
      " [-1.68677604]\n",
      " [-2.93362951]\n",
      " [ 2.62238836]\n",
      " [-6.32753134]]\n",
      "8000 0.0156551 [[ 0.77366048 -1.53955543 -5.7017417  -1.32270706 -0.24515279 -3.5656004\n",
      "   1.11951506  2.29169583  0.87467152 -4.98505592]\n",
      " [ 1.45125616 -0.14876178 -5.5740571  -0.74314785  0.47388673 -3.75634217\n",
      "   0.59101069  0.09856775 -2.77906084 -4.85802603]] [[-2.37053728]\n",
      " [ 1.56479895]\n",
      " [-8.18985462]\n",
      " [ 1.93212104]\n",
      " [-0.40331051]\n",
      " [ 7.41969395]\n",
      " [-1.75541377]\n",
      " [-3.01692724]\n",
      " [ 2.71977353]\n",
      " [-6.57009363]]\n",
      "[array([[ 0.01163491],\n",
      "       [ 0.98550332],\n",
      "       [ 0.9843716 ],\n",
      "       [ 0.02035286]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('07train.txt', unpack= True)\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 'Deep' neural network to solve XOR problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.701768 [[ 0.16835859 -0.92337316 -0.42157048  0.97754902 -0.06309025]\n",
      " [ 0.70236516 -0.43839204 -0.53003985 -0.42422858  0.92067373]] [[-0.68873584  0.60137308  0.16320528  0.39678356]\n",
      " [ 0.87818176  0.01208374 -0.88203037  0.92998332]\n",
      " [ 0.88057435 -0.84993207  0.96204716  0.31987014]\n",
      " [-0.77234721 -0.50768209  0.06943167  0.72321022]\n",
      " [ 0.73062056 -0.55624038 -0.81566727  0.09564757]]\n",
      "1000 0.693411 [[ 0.11608291 -0.80341762 -0.45520112  0.92525971  0.12888812]\n",
      " [ 0.68962127 -0.24886326 -0.52172178 -0.41553217  0.92118776]] [[-0.68551153  0.57741421  0.15146606  0.41152474]\n",
      " [ 0.87660277  0.02597154 -0.82351452  0.92992872]\n",
      " [ 0.88262755 -0.84183574  0.99530303  0.32345551]\n",
      " [-0.76801842 -0.49198344  0.0596128   0.71994013]\n",
      " [ 0.73137307 -0.57562238 -0.81476873  0.10703145]]\n",
      "2000 0.692283 [[ 0.07807797 -0.74109662 -0.50676763  0.87831134  0.38271081]\n",
      " [ 0.68336385 -0.14463721 -0.53097081 -0.42136103  0.99043131]] [[-0.68759042  0.57297879  0.15221986  0.41287977]\n",
      " [ 0.87675923  0.02584103 -0.78536743  0.93346536]\n",
      " [ 0.88243771 -0.82433516  1.0405699   0.31950957]\n",
      " [-0.76664555 -0.46732929  0.0528578   0.71342856]\n",
      " [ 0.73202592 -0.60159796 -0.84743065  0.11959192]]\n",
      "3000 0.688979 [[ 0.04317353 -0.69652629 -0.59059197  0.83621532  0.78750539]\n",
      " [ 0.68172657 -0.07817372 -0.56861383 -0.43634135  1.19453871]] [[-0.69408786  0.58014441  0.15103617  0.40810007]\n",
      " [ 0.87675422  0.02321542 -0.74905998  0.93754321]\n",
      " [ 0.8801865  -0.79708099  1.10907364  0.31112504]\n",
      " [-0.76576364 -0.43766928  0.03370148  0.70813179]\n",
      " [ 0.74282467 -0.67426538 -0.9959498   0.1583005 ]]\n",
      "4000 0.67216 [[ 0.00509635 -0.65840125 -0.7547223   0.79833513  1.4996922 ]\n",
      " [ 0.69601053 -0.03437172 -0.68202049 -0.45112896  1.69878268]] [[-0.721609    0.622823    0.17757554  0.3916257 ]\n",
      " [ 0.8730033   0.03240454 -0.65813327  0.93930572]\n",
      " [ 0.86856043 -0.74015707  1.28946507  0.29486436]\n",
      " [-0.77109027 -0.37955317  0.02828417  0.69889218]\n",
      " [ 0.81297326 -0.8765074  -1.46547067  0.2583198 ]]\n",
      "5000 0.565554 [[ 0.03651657 -0.75135416 -1.13560939  0.81085062  2.86584258]\n",
      " [ 0.88079    -0.09871914 -1.03370309 -0.40091452  2.91424799]] [[-0.91068476  0.86060429  0.32269162  0.31886101]\n",
      " [ 0.88848019  0.02557028 -0.45303059  0.95113128]\n",
      " [ 0.88133311 -0.6904822   1.76376629  0.29111388]\n",
      " [-0.86246014 -0.17973132  0.12893286  0.65674812]\n",
      " [ 1.09279406 -1.35682201 -2.82567263  0.44018042]]\n",
      "6000 0.295967 [[ 0.20356767 -1.33970201 -1.37925029  1.46588981  4.24055958]\n",
      " [ 1.81580234 -0.40692154 -1.24238944 -0.00518835  4.27334404]] [[-1.77313066  1.86602879  0.46119606  0.02267911]\n",
      " [ 1.4804846  -0.56390911 -0.39093548  1.06601226]\n",
      " [ 1.62594771 -1.41498137  2.05824304  0.44655436]\n",
      " [-1.46679699  0.65201628  0.29423937  0.4334102 ]\n",
      " [ 1.67696595 -1.86922133 -4.39815187  0.51608044]]\n",
      "7000 0.0730162 [[ 0.16473573 -1.69035757 -1.79511738  2.10297275  4.99450731]\n",
      " [ 2.43588066 -0.50351024 -1.6609199  -0.19707918  5.04519796]] [[-2.62169671  2.56999588  0.32833421 -0.23935921]\n",
      " [ 1.91319227 -0.85484475 -0.21125993  1.10093677]\n",
      " [ 2.44922805 -1.99402595  2.23733449  0.55283701]\n",
      " [-2.1033709   1.47982836  0.27227682  0.19394064]\n",
      " [ 2.35222554 -2.91309309 -5.44153643  0.57891655]]\n",
      "8000 0.0304551 [[ 0.08328173 -1.76528287 -2.02683043  2.39675355  5.30412674]\n",
      " [ 2.64528489 -0.56733519 -1.92416668 -0.45041442  5.35626698]] [[-2.9422164   2.77687621  0.22705284 -0.33444178]\n",
      " [ 2.02885628 -0.81906158 -0.12370664  1.10832179]\n",
      " [ 2.78981304 -2.1417315   2.30124569  0.60950392]\n",
      " [-2.33994341  1.84965014  0.22678268  0.09737785]\n",
      " [ 2.64036012 -3.55474591 -5.85026884  0.64031219]]\n",
      "9000 0.0173194 [[ 0.00997113 -1.79547703 -2.16249895  2.57526135  5.46517181]\n",
      " [ 2.7668283  -0.61290163 -2.07766008 -0.63905919  5.51686954]] [[-3.10263062  2.87964654  0.17545131 -0.38978404]\n",
      " [ 2.08058405 -0.79273248 -0.08135208  1.11569238]\n",
      " [ 2.97241616 -2.24328351  2.32679629  0.65216941]\n",
      " [-2.4693501   2.06710887  0.20698106  0.03741926]\n",
      " [ 2.79310179 -3.92316246 -6.0453248   0.67540592]]\n",
      "10000 0.0115535 [[-0.05347197 -1.81137002 -2.2533834   2.69806957  5.56648254]\n",
      " [ 2.85271263 -0.64585328 -2.18001676 -0.7810002   5.61711788]] [[-3.20041132  2.94747853  0.14448404 -0.42885897]\n",
      " [ 2.10765338 -0.78096271 -0.05587467  1.12227118]\n",
      " [ 3.08588147 -2.32679129  2.34031439  0.68563938]\n",
      " [-2.5561018   2.21643209  0.19729097 -0.00641038]\n",
      " [ 2.89470363 -4.16123962 -6.16216755  0.69796914]]\n",
      "11000 0.00845465 [[-0.10879383 -1.82086444 -2.31978726  2.78934836  5.6377573 ]\n",
      " [ 2.91892314 -0.67089057 -2.25473452 -0.89210123  5.68714046]] [[-3.26752138  2.99846816  0.12358814 -0.45902333]\n",
      " [ 2.12265277 -0.77702928 -0.03858398  1.1281004 ]\n",
      " [ 3.1632781  -2.39747739  2.34855866  0.71305877]\n",
      " [-2.62088752  2.32796097  0.19191058 -0.04089682]\n",
      " [ 2.97083092 -4.32943773 -6.24200487  0.71406263]]\n",
      "12000 0.00656539 [[-0.15765005 -1.826967   -2.37122416  2.8608768   5.69157982]\n",
      " [ 2.97263288 -0.69079655 -2.31271887 -0.98212218  5.73963976]] [[-3.31728649  3.03959584  0.10837173 -0.4835844 ]\n",
      " [ 2.13099146 -0.77732188 -0.0259819   1.13334525]\n",
      " [ 3.21955371 -2.45847154  2.35396791  0.7363205 ]\n",
      " [-2.67248631  2.41577125  0.18861282 -0.06926116]\n",
      " [ 3.03189445 -4.45575094 -6.30113697  0.72635472]]\n",
      "13000 0.00531214 [[-0.20127937 -1.83108592 -2.41273952  2.9190731   5.73419476]\n",
      " [ 3.01767588 -0.70718837 -2.35966182 -1.05707848  5.78094101]] [[-3.35620332  3.07421422  0.09670453 -0.50431192]\n",
      " [ 2.13536739 -0.77999377 -0.01635607  1.13813794]\n",
      " [ 3.26238179 -2.51193714  2.35766602  0.75656325]\n",
      " [-2.71533346  2.48745728  0.18643457 -0.09331243]\n",
      " [ 3.08299899 -4.55474472 -6.34730625  0.73616606]]\n",
      "14000 0.00442888 [[-0.24062309 -1.83396399 -2.44730091  2.96778917  5.76910734]\n",
      " [ 3.05636883 -0.72106761 -2.39887428 -1.12086546  5.81458807]] [[-3.38784289  3.1041913   0.08741038 -0.5222559 ]\n",
      " [ 2.13728118 -0.78406233 -0.00876173  1.14257109]\n",
      " [ 3.2961545  -2.55946255  2.36024427  0.77453727]\n",
      " [-2.75195622  2.54757619  0.18489747 -0.11416362]\n",
      " [ 3.12703395 -4.63483572 -6.38474321  0.74425352]]\n",
      "15000 0.00377712 [[-0.27639347 -1.83603215 -2.47675896  3.00946927  5.79845381]\n",
      " [ 3.09022188 -0.73308718 -2.43242025 -1.17608786  5.84272718]] [[ -3.41433382e+00   3.13068962e+00   7.97924101e-02  -5.38093567e-01]\n",
      " [  2.13761497e+00  -7.88949728e-01  -2.62365350e-03   1.14672327e+00]\n",
      " [  3.32354140e+00  -2.60217810e+00   2.36205244e+00   7.90739894e-01]\n",
      " [ -2.78392601e+00   2.59904552e+00   1.83749929e-01  -1.32552966e-01]\n",
      " [  3.16575813e+00  -4.70121574e+00  -6.41595268e+00   7.51073241e-01]]\n",
      "16000 0.00327765 [[-0.30912131 -1.83756292 -2.50234318  3.04574156  5.82360268]\n",
      " [ 3.12025642 -0.74368846 -2.46165752 -1.22453821  5.86673164]] [[ -3.43702984e+00   3.15448165e+00   7.34153166e-02  -5.52288115e-01]\n",
      " [  2.13691401e+00  -7.94292927e-01   2.43606046e-03   1.15062547e+00]\n",
      " [  3.34623814e+00  -2.64089441e+00   2.36331248e+00   8.05504799e-01]\n",
      " [ -2.81228876e+00   2.64384460e+00   1.82857379e-01  -1.48998126e-01]\n",
      " [  3.20030951e+00  -4.75724125e+00  -6.44252062e+00   7.56906390e-01]]\n",
      "17000 0.00288519 [[-0.33924943 -1.83872139 -2.52487564  3.07773757  5.84549618]\n",
      " [ 3.14719987 -0.75316471 -2.48749733 -1.26754689  5.88754082]] [[-3.45681381  3.17606735  0.06798038 -0.56515592]\n",
      " [ 2.13552356 -0.79989606  0.00666701  1.15432179]\n",
      " [ 3.3654182  -2.67627549  2.36415625  0.81908816]\n",
      " [-2.837744    2.68332911  0.1821326  -0.16386132]\n",
      " [ 3.23150492 -4.80527592 -6.46550751  0.76196462]]\n",
      "18000 0.00256987 [[-0.36713094 -1.8396101  -2.54497075  3.10629177  5.86480474]\n",
      " [ 3.17159462 -0.76173729 -2.51061034 -1.30609429  5.90582132]] [[-3.4743154   3.19582796  0.06327963 -0.57693368]\n",
      " [ 2.13371181 -0.80561447  0.01024822  1.15783823]\n",
      " [ 3.38189769 -2.7088275   2.36470628  0.83168238]\n",
      " [-2.86081171  2.71851468  0.18152203 -0.17741583]\n",
      " [ 3.25993657 -4.84698868 -6.48568392  0.76639825]]\n",
      "19000 0.00231152 [[-0.39304918 -1.84030151 -2.5630753   3.13201857  5.88201427]\n",
      " [ 3.19385695 -0.76957124 -2.53149676 -1.34092653  5.9220624 ]] [[-3.48998523  3.21405315  0.05916408 -0.58779955]\n",
      " [ 2.13161492 -0.81137532  0.01331131  1.16120517]\n",
      " [ 3.39626217 -2.73894119  2.36501169  0.8434338 ]\n",
      " [-2.88188553  2.75016284  0.18099228 -0.18987149]\n",
      " [ 3.2860465  -4.88360405 -6.50359631  0.77031845]]\n",
      "20000 0.00209662 [[-0.41723368 -1.84086621 -2.57952976  3.15539193  5.89749146]\n",
      " [ 3.21430993 -0.77678955 -2.55052137 -1.37262762  5.93661928]] [[-3.50415444  3.23096728  0.05552299 -0.5978905 ]\n",
      " [ 2.12937403 -0.81709701  0.01595451  1.16442668]\n",
      " [ 3.40893364 -2.76693606  2.36515212  0.8544575 ]\n",
      " [-2.90126705  2.77885962  0.18052241 -0.20139252]\n",
      " [ 3.31017208 -4.91604376 -6.51962185  0.7738111 ]]\n",
      "[array([[ 0.0012272 ],\n",
      "       [ 0.99791336],\n",
      "       [ 0.99786127],\n",
      "       [ 0.00292439]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('07train.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0)) # 3개의 층으로  in 2 out 5\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0)) # in 5 out 4 \n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0)) # in 4 out 1\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\") # 5개의 노드 Bias : 5개\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\") # 4개의 노드 Bias : 4개\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\") # 1개의 노드 Bias : 1개\n",
    "\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)  # L2 = X * W1 + b1\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2) # L3 = L2 * W2 + b2\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3) # hypothesis = L3 * W3 + b3\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
