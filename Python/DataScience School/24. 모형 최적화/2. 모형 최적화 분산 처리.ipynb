{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형 최적화 분산 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipyparallel\n",
    "\n",
    "* http://ipyparallel.readthedocs.org/en/latest/index.html\n",
    "\n",
    "\n",
    "* Engine <-> Client\n",
    " * Engine: 실제 계산이 실행되는 프로세스\n",
    " * Client: 엔진을 제어하기 위한 인터페이스\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ conda install ipyparallel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine 가동/중지\n",
    "\n",
    "* 가동\n",
    "```\n",
    "$ ipcluster start -n 4\n",
    "```\n",
    "\n",
    "* 중지\n",
    " * Control-C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "c = Client()\n",
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DirectView [0, 1]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dview = c[:]\n",
    "dview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map / Reduce\n",
    "\n",
    "* `map(function, data)`: data 각각에 function을 실행하여 결과 출력\n",
    "* `reduce(function, data)`: function을 실행할 때 마다 결과의 수가 감소. 최종적으로 하나의 수가 남는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fahrenheit(T):\n",
    "    return 9 / 5 * T + 32\n",
    "\n",
    "temp = np.arange(0, 110, 10)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.0, 50.0, 68.0, 86.0, 104.0, 122.0, 140.0, 158.0, 176.0, 194.0, 212.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = map(fahrenheit, temp)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prime(primes, n):\n",
    "    for p in primes:\n",
    "        if n % p == 0:\n",
    "            return primes\n",
    "    primes.append(n)\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(create_prime, np.arange(2, 100), [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Map \n",
    "\n",
    "* map/reduce 연산을 engine process들에게 맏겨서 동시 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pyprimes(kmax):\n",
    "    p = np.zeros(1000)\n",
    "    result = []\n",
    "    if kmax > 1000:\n",
    "        kmax = 1000\n",
    "    k = 0\n",
    "    n = 2\n",
    "    while k < kmax:\n",
    "        i = 0\n",
    "        while i < k and n % p[i] != 0:\n",
    "            i = i + 1\n",
    "        if i == k:\n",
    "            p[k] = n\n",
    "            k = k + 1\n",
    "            result.append(n)\n",
    "        n = n + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.5 s, sys: 0 ns, total: 40.5 s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%time result = map(pyprimes, range(700, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%time parallel_result = dview.map_sync(pyprimes, range(700, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_result == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async_result = dview.map_async(pyprimes, range(700, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_result.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5189, 5197, 5209, 5227, 5231, 5233, 5237, 5261, 5273, 5279]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_result.get()[0][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모형 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형을 분산처리하기 위해서는 sklearn.externals 서브패키지의 `joblib.dump` 명령과 `joblib.load` 명령 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipyparalle 을 사용한 분산 모형 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "news = fetch_20newsgroups(subset=\"all\")\n",
    "n_samples = 3000\n",
    "X_train = news.data[:n_samples]\n",
    "y_train = news.target[:n_samples]\n",
    "\n",
    "model = Pipeline([\n",
    "        ('vect', TfidfVectorizer(stop_words=\"english\", token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\")),\n",
    "        ('svc', SVC()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/dockeruser/notebooks/ml/news_cv_000.pkl',\n",
       " '/home/dockeruser/notebooks/ml/news_cv_001.pkl',\n",
       " '/home/dockeruser/notebooks/ml/news_cv_002.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "\n",
    "def persist_cv_splits(X, y, K=3, name=\"data\", suffix=\"_cv_%03d.pkl\"):\n",
    "    cv_split_filenames = []\n",
    "    cv = KFold(n_samples, K, shuffle=True, random_state=0)\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        cv_fold = ([X[k] for k in train], y[train], \n",
    "                   [X[k] for k in test], y[test])\n",
    "        cv_split_filename = name + suffix % i\n",
    "        cv_split_filename = os.path.abspath(cv_split_filename)\n",
    "        joblib.dump(cv_fold, cv_split_filename)\n",
    "        cv_split_filenames.append(cv_split_filename)\n",
    "    return cv_split_filenames\n",
    "\n",
    "cv_filenames = persist_cv_splits(X_train, y_train, name=\"news\")\n",
    "cv_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_evaluation(cv_split_filename, model, params):\n",
    "    from sklearn.externals import joblib\n",
    "    X_train_, y_train_, X_test_, y_test_ = joblib.load(cv_split_filename, mmap_mode=\"c\")\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train_, y_train_)\n",
    "    test_scores = model.score(X_test_, y_test_)\n",
    "    return test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import ParameterGrid\n",
    "def parallel_grid_search(lb_view, model, cv_split_filenames, param_grid):\n",
    "    all_tasks = []\n",
    "    all_parameters = list(ParameterGrid(param_grid))\n",
    "    for i, params in enumerate(all_parameters):\n",
    "        task_for_params = []\n",
    "        for j, cv_split_filename in enumerate(cv_split_filenames):\n",
    "            t = lb_view.apply(compute_evaluation, cv_split_filename, model, params)\n",
    "            task_for_params.append(t)\n",
    "        all_tasks.append(task_for_params)\n",
    "    return all_parameters, all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def print_progress(tasks):\n",
    "    progress = np.mean([task.ready() for task_group in tasks for task in task_group])\n",
    "    print(\"{0}:{1}%\".format(datetime.datetime.now(), progress * 100.0))\n",
    "    return int(progress * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "client = Client()\n",
    "print(client.ids)\n",
    "lb_view = client.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {\n",
    "    \"svc__gamma\": np.logspace(-2, 1, 4),\n",
    "    \"svc__C\": np.logspace(-1, 1, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_parameters, all_tasks = parallel_grid_search(lb_view, model, cv_filenames, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = datetime.datetime.now()\n",
    "while True:\n",
    "    progress = print_progress(all_tasks)\n",
    "    if progress >= 100:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "print(\"finish\")\n",
    "end_time = datetime.datetime.now()\n",
    "print((end_time - start_time).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}