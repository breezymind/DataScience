{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic_Deep_Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 우리가 이미 알고 있는 것.\n",
    " - 1. Regression : $ y = ax + b $ <- Hypothesis (식)\n",
    " - 2. Cost => Minimize \n",
    "![img3](data/3.png) \n",
    "![img1](data/1.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost \n",
    " - $H(x) = Wx$ 간단하게 표현\n",
    " - $Cost(W) = \\sum_{1}^{m}({Wx}^{i}-{y}^{i})^2$\n",
    " - W 값을 변경해 가면서 Cost값이 가장 낮은 곳을 찾는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent (경사하강법)\n",
    " - 위의 Cost값을 최소한으로 하는 W를 찾아내는 방법을 Gradient Descent라 한다. \n",
    "![img2](data/7.PNG)\n",
    "![img2](data/4.png)\n",
    "![img2](data/5.png)\n",
    "![img2](data/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망의 특징 \n",
    " - 신경망의 경우 활성화 되고 안되고 즉, 결과값이 0 또는 1값을 가지게 된다.\n",
    "  - 최종 Output의 경우 적용 되는 부분\n",
    "  - X라는 값으로 Y로 출력 \n",
    "  - X라는 값이 입력될 때 가중치 W가 적용되고 각 값에 대해서 Bias (B)가 가해 진다. \n",
    "  - 즉, $W*X + b$\n",
    "![img1](img/1.PNG)\n",
    "![img9](data/8.PNG)\n",
    "![img9](data/9.PNG)\n",
    "\n",
    "## 위의 기본 컨셉을 함수로 표현가능하다고 생각하다는 것에서 시작\n",
    "![img2](img/2.PNG)\n",
    "\n",
    "- 위의 함수 즉, 뉴랄을 가지고는 and 또는 or 문제는 해결이 가능하다. \n",
    " - 하지만, xor 문제는 단순한 선형 직선으로 풀 수 없는 문제로 발견. Neural Net의 발전이 멈추는 계기가 되었다.\n",
    " - 위의 문제를 해결하기 위해서 아래와 같은 그림으로 Multi Layer Perceptron으로 해결이 가능하며, 이 가중치를 학습하는 방법이 Back Propagation이다. \n",
    "\n",
    "\n",
    " - 이러한 값을 조절해주는 것이 $Step \\ Function$ (계단 함수라고 한다.)\n",
    "## 계단 함수 \n",
    "![img9](data/10.PNG)\n",
    "\n",
    "### 시그모이드 \n",
    "![img9](data/11.PNG)\n",
    "\n",
    "### 쌍탄젠트 \n",
    "![img9](data/12.PNG)\n",
    "\n",
    "### Relu \n",
    "![img9](data/13.PNG)\n",
    "\n",
    "\n",
    "#### ReLu의 경우 0~ 무한대 값을 가진다.\n",
    " - 그러므로 중간 Hidden layer에는 사용할 수 있지만 결과값의 출력하는 부분에서는 사용 할 수 없다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img3](img/3.PNG)\n",
    "\n",
    "## XOR 문제 \n",
    "![img4](img/4.PNG)\n",
    "![img5](img/5.PNG)\n",
    "![img6](img/6.PNG)\n",
    "![img7](img/7.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackPropagation\n",
    "![img13](img/13.PNG)\n",
    "\n",
    "### Cost Minimize \n",
    " - Gradient Descent 를 이용하여 Cost 를 감소 시켜야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img14](img/14.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미분 특징 \n",
    " - <a href=\"https://youtu.be/oZyvmtqLmLo\">Sung Kim교수의 미분 강의 </a>\n",
    " \n",
    "![img15](img/15.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img16](img/16.PNG)\n",
    "\n",
    "#### 위의 미분 결과값에 의해 가중치들을 조절할 수가 있다. \n",
    " - 내가 원하는 값보다 크게 나왔다면 - 영향이 있는 놈을 높이고 + 영향이 있는 놈을 낮추면 된다. \n",
    " \n",
    "### But Back Propagation에서 Sigmoid를 사용했을 경우 단점이 발생 \n",
    " - backpropagation 이 엄청난 레이어로 수성되면 작동이 잘 안됐다 그 이유가 값들이 0.몇 이러한 형태로만 출력되서 뒤로 가면 갈수록 앞의 값이 전달이 잘 안되서 학습이 어려웠다.\n",
    " - 이러한 문제점을 해결하기 위해 나온 것이 ReLu 라는 Step Function (이미지는 집에 있는 것 쓰기.)\n",
    "\n",
    "### ReLu \n",
    " - 0 이상의 값이 입력 됐을 경우 x -> x로 값이 출력.\n",
    " - 0 ~ 1값만 취급하던 Sigmoid에 비해 값이 크게 적용 되므로 값의 전달이 깊고 넓게 적용 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 학교 DeepLearning 복습 \n",
    "## MNIST \n",
    " - 손글씨로 된 그림 데이터 맞추기 \n",
    " - 0 ~ 9 까지 숫자\n",
    " - train, test Set 으로 나누어져 있음 \n",
    " - Train : 60000개, Test : 10000개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train \n",
    "  - (60000, 28, 28)\n",
    "  - 60000 : 데이터 셋 갯수\n",
    "  - 28 : width(가로 길이)\n",
    "  - 28 : height(세로 길이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    " - 10000개 데이터 \n",
    " - 위와 동일하게 28 x 28 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train, width, height = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Python 문법에서 _ <- 는 필요 없는 부분을 버리는 역할을 한다.\n",
    "  - 왜? 이러한 문법을 현재 사용하는가. \n",
    "  - 이미 위에서 test부분에서 width, height를 가져 왔기 때문에 패스하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_test, _, _ = x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20ff31adc50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20ff2de1240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[4,], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[4,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 \n",
    "#### 입력 (Input Layer)\n",
    " - 입력 부분에서 현재 나와있는 형태 \n",
    " - 데이터 모양을 28 * 28 형태로 넣을 수가 없으므로 \n",
    " - 28 / 28 / 28 / 28 / 28 ~~~~~~~~~~~~~~~ 28개 형태로 붙여서 한줄로 만들어서 입력 으로 만든다. \n",
    " - 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([0,1,0,1,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.array([[0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0],\n",
    "    [1],\n",
    "    [0],\n",
    "    [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)## 이러한 형태로 matrix 곱을 해주기 위해서  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55,\n",
       "        148, 210, 253, 253, 113,  87, 148,  55,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 232,\n",
       "        252, 253, 189, 210, 252, 252, 253, 168,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  57, 242, 252,\n",
       "        190,  65,   5,  12, 182, 252, 253, 116,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 183,\n",
       "         14,   0,   0,  92, 252, 252, 225,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 132, 253, 252, 146,  14,\n",
       "          0,   0,   0, 215, 252, 252,  79,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 126, 253, 247, 176,   9,   0,\n",
       "          0,   8,  78, 245, 253, 129,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  16, 232, 252, 176,   0,   0,   0,\n",
       "         36, 201, 252, 252, 169,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  22, 252, 252,  30,  22, 119, 197,\n",
       "        241, 253, 252, 251,  77,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  16, 231, 252, 253, 252, 252, 252,\n",
       "        226, 227, 252, 231,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  55, 235, 253, 217, 138,  42,\n",
       "         24, 192, 252, 143,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         62, 255, 253, 109,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        106, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         45, 255, 253,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 218, 252,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  96, 252, 189,  42,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  14, 184, 252, 170,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  14, 147, 252,  42,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[4,] # 이러한 형태로는 Neural Net을 사용할 수 없다. 그렇기에 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 60000개의 데이터를 28 * 28 = 784 개 데이터로 쭉 길에 풀어서 넣어야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_train = x_train.reshape(n_train, width*height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_train = input_train / 255.0  # 0~255의 크기로 데이터가 존재하는데 해당 데이터를 크게 할 경우 학습에 어려움이 있다. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트용 데이터도 동일하게 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_test = x_test.reshape(n_test, width*height)\n",
    "input_test.astype('float32')\n",
    "input_test = input_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 출력\n",
    " - 0이라는 문자가 있다. 왼쪽 반을 지우면 1이된다 하지만 또 반을 지운다고해서 2가 되지는 않는다.\n",
    " - 숫자는 범주형 데이터이다. (그림은)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_train = keras.utils.to_categorical(y_train,10) # 0~9까지를 카테고리로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train # one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 간단한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax \n",
    " - What's the SoftMax Function \n",
    " - 우리는 Logistic Regression을 알고 있다. (A or B / 1 or 0) 과 같이 2개의 값을 구별할 때 사용하는 Step function \n",
    " - 이러한 내용을 Muliti Categorial Label 을 구별할 때는 단독으로는 사용할 수 없다. \n",
    " \n",
    "![img17](img/17.PNG)\n",
    "![img18](img/18.PNG)\n",
    "![img19](img/19.PNG)\n",
    "![img20](img/20.PNG)\n",
    "![img21](img/21.PNG)\n",
    "![img22](img/22.PNG)\n",
    "![img23](img/23.PNG)\n",
    "![img24](img/24.PNG)\n",
    "![img25](img/25.PNG)\n",
    "![img26](img/26.PNG)\n",
    "![img27](img/27.PNG)\n",
    "![img28](img/28.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(392, activation='tanh', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation : tanh graph\n",
    "![img9](data/12.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3930      \n",
      "=================================================================\n",
      "Total params: 311,650\n",
      "Trainable params: 311,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # dense_1 에는 784 * 392 + 392 bias가 있다. 라는 param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - loss : 우리 모델이 얼마나 부정확하냐 \n",
    "  - mean_squared_error : MSE  −1/𝑁 ∑(𝑦−𝑦 ̂ )^2 \n",
    "  - cross entropy : 내가 뭔가를 맞출때 높은 확률로 맞춘거를 좋아해, 낮은 확률로 맞춘 것은 loss가 커진다. 배팅을 크게 했는데 못맞추면 loss 또한 커진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트레이닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128 # 한번에 들어가는 데이터 크기 \n",
    "epochs = 1 # 반복횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 4s - loss: 0.3328 - acc: 0.9016 - val_loss: 0.2330 - val_acc: 0.9312\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_train, output_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(input_test, output_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.90156666673024499],\n",
       " 'loss': [0.33278176914850871],\n",
       " 'val_acc': [0.93120000000000003],\n",
       " 'val_loss': [0.23297160456180571]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23297160540521145, 0.93120000000000003]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(input_test, output_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comming up Next!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN \n",
    " - 고양이의 시신경을 관찰 \n",
    " - 그림을 볼때 전체 누런이 활성화 되는 것이 아니라 일부만 활성화가되고 다른 그림을 보야주면 또 다른 뉴런이 활성화가 되는 형태를 보임 \n",
    " - 즉, 이 시신경들이 전체를 보는 것이 아니라 일부를 보고 나중에 조합하는 것이 아닌가 하는것이 cnn 의 개념"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
