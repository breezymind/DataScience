{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "## The holdout method\n",
    " - 데이터가 적을 경우 사용 => 데이터가 많다면 운에 맡겨서 나온 것이라고 봐도 무방하다.\n",
    " - 현재 수업 중에 테스트하는 6:4 비율 활용이 이에 해당한다. \n",
    " <img src=\"photo/12.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation(KFCV)\n",
    "<img src=\"photo/13.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(randomForest)\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb <- read.delim(\"../1022_Decision Tree_2/Hshopping.txt\", stringsAsFactors=FALSE)\n",
    "colnames(cb) <- c(\"ID\",\"SEX\",\"AGE\",\"AMT\",\"STAR\",\"REFUND\") # Jupyter note Font Error using Korean\n",
    "cb$REFUND <- factor(cb$REFUND)\n",
    "\n",
    "set.seed(1)\n",
    "flds <- createFolds(cb$REFUND, k=5, list=T, returnTrain=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 5\n",
      " $ Fold1: int [1:99] 5 7 12 14 18 19 21 25 30 32 ...\n",
      " $ Fold2: int [1:101] 11 33 39 41 45 80 85 86 90 94 ...\n",
      " $ Fold3: int [1:100] 10 15 16 22 24 31 34 35 36 48 ...\n",
      " $ Fold4: int [1:100] 2 3 4 8 9 13 20 23 26 29 ...\n",
      " $ Fold5: int [1:100] 1 6 17 27 28 43 46 47 53 54 ...\n"
     ]
    }
   ],
   "source": [
    "str(flds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 5 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment <- function(train, test, m) {\n",
    "    rf <- randomForest(REFUND ~ .-ID, data=train, ntree=50)\n",
    "    rf_pred <- predict(rf, test, type=\"response\")\n",
    "    m$acc = c(m$acc, confusionMatrix(rf_pred, test$REFUND)$overall[1])\n",
    "    rf_pred_prob <- predict(rf, test, type=\"prob\")\n",
    "    rf_pred <- prediction(rf_pred_prob[,2], cb.test$REFUND)\n",
    "    m$auc = c(m$auc, performance(rf_pred, \"auc\")@y.values[[1]])\n",
    "    return(m)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measure = list()\n",
    "for(i in 1:5){\n",
    "    inTest <- flds[[i]]\n",
    "    cb.test <- cb[inTest,]\n",
    "    cb.train <- cb[-inTest,]\n",
    "    \n",
    "    measure = experiment(cb.train,cb.test,measure)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$acc</dt>\n",
       "\t\t<dd><dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.888888888888889</dd>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.871287128712871</dd>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.92</dd>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.91</dd>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.91</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$auc</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>0.967030360531309</li>\n",
       "\t<li>0.957653985507246</li>\n",
       "\t<li>0.960729312762973</li>\n",
       "\t<li>0.958859280037401</li>\n",
       "\t<li>0.98153342683497</li>\n",
       "</ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$acc] \\begin{description*}\n",
       "\\item[Accuracy] 0.888888888888889\n",
       "\\item[Accuracy] 0.871287128712871\n",
       "\\item[Accuracy] 0.92\n",
       "\\item[Accuracy] 0.91\n",
       "\\item[Accuracy] 0.91\n",
       "\\end{description*}\n",
       "\n",
       "\\item[\\$auc] \\begin{enumerate*}\n",
       "\\item 0.967030360531309\n",
       "\\item 0.957653985507246\n",
       "\\item 0.960729312762973\n",
       "\\item 0.958859280037401\n",
       "\\item 0.98153342683497\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$acc\n",
       ":   Accuracy\n",
       ":   0.888888888888889Accuracy\n",
       ":   0.871287128712871Accuracy\n",
       ":   0.92Accuracy\n",
       ":   0.91Accuracy\n",
       ":   0.91\n",
       "\n",
       "\n",
       "$auc\n",
       ":   1. 0.967030360531309\n",
       "2. 0.957653985507246\n",
       "3. 0.960729312762973\n",
       "4. 0.958859280037401\n",
       "5. 0.98153342683497\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$acc\n",
       " Accuracy  Accuracy  Accuracy  Accuracy  Accuracy \n",
       "0.8888889 0.8712871 0.9200000 0.9100000 0.9100000 \n",
       "\n",
       "$auc\n",
       "[1] 0.9670304 0.9576540 0.9607293 0.9588593 0.9815334\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.900035203520352"
      ],
      "text/latex": [
       "0.900035203520352"
      ],
      "text/markdown": [
       "0.900035203520352"
      ],
      "text/plain": [
       "[1] 0.9000352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0196715503407551"
      ],
      "text/latex": [
       "0.0196715503407551"
      ],
      "text/markdown": [
       "0.0196715503407551"
      ],
      "text/plain": [
       "[1] 0.01967155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(measure$acc); sd(measure$acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.96516127313478"
      ],
      "text/latex": [
       "0.96516127313478"
      ],
      "text/markdown": [
       "0.96516127313478"
      ],
      "text/plain": [
       "[1] 0.9651613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.00983943166216546"
      ],
      "text/latex": [
       "0.00983943166216546"
      ],
      "text/markdown": [
       "0.00983943166216546"
      ],
      "text/plain": [
       "[1] 0.009839432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(measure$auc); sd(measure$auc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
